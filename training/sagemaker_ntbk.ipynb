{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T14:48:22.884049Z",
     "start_time": "2025-08-18T14:48:22.624546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import io\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import boto3\n",
    "from torch.backends.opt_einsum import strategy\n",
    "from torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook import batched_powerSGD_hook\n",
    "\n",
    "# 2) Hard‑code (or read from env var) the execution‑role ARN you created\n",
    "role = \"arn:aws:iam::371087393859:role/defaultrole\"\n",
    "bucket = \"ir-sagemaker\"\n",
    "session = boto3.Session(profile_name=\"lprofile\", region_name=\"us-east-1\")\n",
    "\n",
    "sm_session = sagemaker.Session(boto_session=session, default_bucket=bucket)"
   ],
   "id": "6f0f99a1aa518973",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T14:48:23.732777Z",
     "start_time": "2025-08-18T14:48:23.571721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sm_session.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sm_session.boto_region_name}\")\n"
   ],
   "id": "2bb382bdca8243f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::371087393859:role/defaultrole\n",
      "sagemaker bucket: ir-sagemaker\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T14:48:26.492535Z",
     "start_time": "2025-08-18T14:48:26.489452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "print(sys.version)"
   ],
   "id": "f1e67dc7e9146bbc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T14:48:27.530862Z",
     "start_time": "2025-08-18T14:48:27.527218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "bucket = sm_session.default_bucket()\n",
    "prefix = \"modernbert\"\n",
    "\n",
    "train_uri = f\"s3://{bucket}/{prefix}/train/train.jsonl\"\n",
    "val_uri   = f\"s3://{bucket}/{prefix}/val/val.jsonl\"\n",
    "test_uri  = f\"s3://{bucket}/{prefix}/test/test.jsonl\"\n",
    "target_set_uri  = f\"s3://{bucket}/{prefix}/target/target_set.jsonl\""
   ],
   "id": "da15a52c29c320e1",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T22:36:34.413090Z",
     "start_time": "2025-08-07T22:36:30.665746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_uri = S3Uploader.upload(\"modernbert/data/train/train.jsonl\", f\"s3://{bucket}/{prefix}/train\")\n",
    "val_uri = S3Uploader.upload(\"modernbert/data/val/val.jsonl\",   f\"s3://{bucket}/{prefix}/val\")\n",
    "test_uri = S3Uploader.upload(\"modernbert/data/test/test.jsonl\", f\"s3://{bucket}/{prefix}/test\")\n",
    "target_set_uri = S3Uploader.upload(\"modernbert/data/target/target_set.jsonl\", f\"s3://{bucket}/{prefix}/target_set\")"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:23:56.856955Z",
     "start_time": "2025-08-13T17:23:56.834197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "metric_definitions=[\n",
    "    {'Name': 'loss', 'Regex': \"'loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'learning_rate', 'Regex': \"'learning_rate': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_loss', 'Regex': \"'eval_loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_accuracy', 'Regex': \"'eval_accuracy': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_f1', 'Regex': \"'eval_f1': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_precision', 'Regex': \"'eval_precision': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_recall', 'Regex': \"'eval_recall': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_runtime', 'Regex': \"'eval_runtime': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_samples_per_second', 'Regex': \"'eval_samples_per_second': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'epoch', 'Regex': \"'epoch': ([0-9]+(.|e\\-)[0-9]+),?\"}]\n",
    "\n",
    "hyper = {\"learning_rate\":3e-5,\n",
    "         \"num_train_epochs\":1,\n",
    "         \"max_steps\":2,\n",
    "         \"temperature\":0.05,\n",
    "         \"deepspeed\": \"ds_zero3.json\"}\n",
    "\n",
    "est = HuggingFace(\n",
    "    entry_point=\"train_sm.py\",\n",
    "    source_dir=\"modernbert\",\n",
    "    role=role,\n",
    "    instance_type=\"ml.g5.12xlarge\",\n",
    "    instance_count=1,\n",
    "    distribution={\"mpi\": {\"enabled\": True}},\n",
    "    transformers_version=\"4.49.0\", pytorch_version=\"2.5.1\", py_version=\"py311\",\n",
    "    hyperparameters=hyper,\n",
    "    metric_definitions=metric_definitions,\n",
    "    environment={\n",
    "        \"PYTORCH_CUDA_ALLOC_CONF\": \"expandable_segments:True\",\n",
    "        \"NCCL_DEBUG\": \"INFO\"\n",
    "    },\n",
    "    output_path=f\"s3://{bucket}/{prefix}/outputs\"\n",
    ")"
   ],
   "id": "f2ea6d1b5bdecbf2",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:39:10.631204Z",
     "start_time": "2025-08-13T17:23:57.448985Z"
    }
   },
   "cell_type": "code",
   "source": "est.fit({\"train\": train_uri, \"val\": val_uri, \"test\": test_uri})",
   "id": "f43f69a1cd6ff444",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-pytorch-training-2025-08-13-17-23-57-467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-13 17:23:59 Starting - Starting the training job\n",
      "2025-08-13 17:23:59 Pending - Training job waiting for capacity......\n",
      "2025-08-13 17:24:45 Pending - Preparing the instances for training...\n",
      "2025-08-13 17:25:16 Downloading - Downloading the training image...........................\n",
      "2025-08-13 17:29:49 Training - Training image download completed. Training in progress....\u001B[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001B[0m\n",
      "\u001B[34mbash: no job control in this shell\u001B[0m\n",
      "\u001B[34mCUDA compat package should be installed for NVIDIA driver smaller than 550.163.01\u001B[0m\n",
      "\u001B[34mCurrent installed NVIDIA driver version is 570.172.08\u001B[0m\n",
      "\u001B[34mSkipping CUDA compat setup as newer NVIDIA driver is installed\u001B[0m\n",
      "\u001B[34m2025-08-13 17:30:30,042 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001B[0m\n",
      "\u001B[34m2025-08-13 17:30:30,080 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001B[0m\n",
      "\u001B[34m2025-08-13 17:30:30,089 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001B[0m\n",
      "\u001B[34m2025-08-13 17:30:30,091 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001B[0m\n",
      "\u001B[34m2025-08-13 17:30:31,645 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: torch==2.5.1 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (2.5.1+cu124)\u001B[0m\n",
      "\u001B[34mCollecting deepspeed==0.17.1 (from -r requirements.txt (line 2))\u001B[0m\n",
      "\u001B[34mDownloading deepspeed-0.17.1.tar.gz (1.5 MB)\u001B[0m\n",
      "\u001B[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 68.5 MB/s eta 0:00:00\u001B[0m\n",
      "\u001B[34mPreparing metadata (setup.py): started\u001B[0m\n",
      "\u001B[34mPreparing metadata (setup.py): finished with status 'done'\u001B[0m\n",
      "\u001B[34mCollecting transformers==4.54.0 (from -r requirements.txt (line 3))\u001B[0m\n",
      "\u001B[34mDownloading transformers-4.54.0-py3-none-any.whl.metadata (41 kB)\u001B[0m\n",
      "\u001B[34mCollecting flash-attn==2.7.4.post1 (from -r requirements.txt (line 6))\u001B[0m\n",
      "\u001B[34mDownloading flash_attn-2.7.4.post1.tar.gz (6.0 MB)\u001B[0m\n",
      "\u001B[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.0/6.0 MB 122.7 MB/s eta 0:00:00\u001B[0m\n",
      "\u001B[34mPreparing metadata (setup.py): started\u001B[0m\n",
      "\u001B[34mPreparing metadata (setup.py): finished with status 'done'\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: triton>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (3.1.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (1.11.1.3)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (24.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (3.18.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (4.14.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (3.5)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (3.1.6)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (2024.12.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (1.13.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: einops in /opt/conda/lib/python3.11/site-packages (from deepspeed==0.17.1->-r requirements.txt (line 2)) (0.8.1)\u001B[0m\n",
      "\u001B[34mCollecting hjson (from deepspeed==0.17.1->-r requirements.txt (line 2))\u001B[0m\n",
      "\u001B[34mDownloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: msgpack in /opt/conda/lib/python3.11/site-packages (from deepspeed==0.17.1->-r requirements.txt (line 2)) (1.1.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from deepspeed==0.17.1->-r requirements.txt (line 2)) (1.26.4)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from deepspeed==0.17.1->-r requirements.txt (line 2)) (7.0.0)\u001B[0m\n",
      "\u001B[34mCollecting py-cpuinfo (from deepspeed==0.17.1->-r requirements.txt (line 2))\u001B[0m\n",
      "\u001B[34mDownloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pydantic>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from deepspeed==0.17.1->-r requirements.txt (line 2)) (2.11.7)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from deepspeed==0.17.1->-r requirements.txt (line 2)) (4.66.5)\u001B[0m\n",
      "\u001B[34mCollecting nvidia-ml-py (from deepspeed==0.17.1->-r requirements.txt (line 2))\u001B[0m\n",
      "\u001B[34mDownloading nvidia_ml_py-13.580.65-py3-none-any.whl.metadata (9.6 kB)\u001B[0m\n",
      "\u001B[34mCollecting huggingface-hub<1.0,>=0.34.0 (from transformers==4.54.0->-r requirements.txt (line 3))\u001B[0m\n",
      "\u001B[34mDownloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers==4.54.0->-r requirements.txt (line 3)) (6.0.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers==4.54.0->-r requirements.txt (line 3)) (2024.11.6)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers==4.54.0->-r requirements.txt (line 3)) (2.32.4)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers==4.54.0->-r requirements.txt (line 3)) (0.21.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from transformers==4.54.0->-r requirements.txt (line 3)) (0.5.3)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch==2.5.1->-r requirements.txt (line 1)) (1.3.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.54.0->-r requirements.txt (line 3)) (1.1.5)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic>=2.0.0->deepspeed==0.17.1->-r requirements.txt (line 2)) (0.7.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pydantic-core==2.33.2 in /opt/conda/lib/python3.11/site-packages (from pydantic>=2.0.0->deepspeed==0.17.1->-r requirements.txt (line 2)) (2.33.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic>=2.0.0->deepspeed==0.17.1->-r requirements.txt (line 2)) (0.4.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch==2.5.1->-r requirements.txt (line 1)) (3.0.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.54.0->-r requirements.txt (line 3)) (3.4.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.54.0->-r requirements.txt (line 3)) (3.10)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.54.0->-r requirements.txt (line 3)) (2.5.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.54.0->-r requirements.txt (line 3)) (2025.7.14)\u001B[0m\n",
      "\u001B[34mDownloading transformers-4.54.0-py3-none-any.whl (11.2 MB)\u001B[0m\n",
      "\u001B[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.2/11.2 MB 170.0 MB/s eta 0:00:00\u001B[0m\n",
      "\u001B[34mDownloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\u001B[0m\n",
      "\u001B[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 561.5/561.5 kB 51.7 MB/s eta 0:00:00\u001B[0m\n",
      "\u001B[34mDownloading hjson-3.1.0-py3-none-any.whl (54 kB)\u001B[0m\n",
      "\u001B[34mDownloading nvidia_ml_py-13.580.65-py3-none-any.whl (48 kB)\u001B[0m\n",
      "\u001B[34mDownloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\u001B[0m\n",
      "\u001B[34mBuilding wheels for collected packages: deepspeed, flash-attn\u001B[0m\n",
      "\u001B[34mDEPRECATION: Building 'deepspeed' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'deepspeed'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001B[0m\n",
      "\u001B[34mBuilding wheel for deepspeed (setup.py): started\u001B[0m\n",
      "\u001B[34mBuilding wheel for deepspeed (setup.py): finished with status 'done'\u001B[0m\n",
      "\u001B[34mCreated wheel for deepspeed: filename=deepspeed-0.17.1-py3-none-any.whl size=1690870 sha256=2e334967b2f453ea48fc439d1abe5f31ced3684f2290af67bb63926b479924b9\u001B[0m\n",
      "\u001B[34mStored in directory: /root/.cache/pip/wheels/34/86/36/22db26525829160fd1c4add33d8a834ec046b90abf45cd363b\u001B[0m\n",
      "\u001B[34mDEPRECATION: Building 'flash-attn' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'flash-attn'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001B[0m\n",
      "\u001B[34mBuilding wheel for flash-attn (setup.py): started\u001B[0m\n",
      "\u001B[34mBuilding wheel for flash-attn (setup.py): finished with status 'done'\u001B[0m\n",
      "\u001B[34mCreated wheel for flash-attn: filename=flash_attn-2.7.4.post1-cp311-cp311-linux_x86_64.whl size=187815463 sha256=d944fc7d2f962bce83fc4708c2fc0c21eaf8255962a0b350ae919362a51b7ef2\u001B[0m\n",
      "\u001B[34mStored in directory: /root/.cache/pip/wheels/3d/88/d8/284b89f56af7d5bf366b10d6b8e251ac8a7c7bf3f04203fb4f\u001B[0m\n",
      "\u001B[34mSuccessfully built deepspeed flash-attn\u001B[0m\n",
      "\u001B[34mInstalling collected packages: py-cpuinfo, nvidia-ml-py, hjson, huggingface-hub, flash-attn, deepspeed, transformers\u001B[0m\n",
      "\u001B[34mAttempting uninstall: huggingface-hub\u001B[0m\n",
      "\u001B[34mFound existing installation: huggingface-hub 0.29.1\u001B[0m\n",
      "\u001B[34mUninstalling huggingface-hub-0.29.1:\u001B[0m\n",
      "\u001B[34mSuccessfully uninstalled huggingface-hub-0.29.1\u001B[0m\n",
      "\u001B[34mAttempting uninstall: flash-attn\u001B[0m\n",
      "\u001B[34mFound existing installation: flash-attn 2.7.3\u001B[0m\n",
      "\u001B[34mUninstalling flash-attn-2.7.3:\u001B[0m\n",
      "\u001B[34mSuccessfully uninstalled flash-attn-2.7.3\u001B[0m\n",
      "\u001B[34mAttempting uninstall: transformers\u001B[0m\n",
      "\u001B[34mFound existing installation: transformers 4.49.0\u001B[0m\n",
      "\u001B[34mUninstalling transformers-4.49.0:\u001B[0m\n",
      "\u001B[34mSuccessfully uninstalled transformers-4.49.0\u001B[0m\n",
      "\u001B[34mSuccessfully installed deepspeed-0.17.1 flash-attn-2.7.4.post1 hjson-3.1.0 huggingface-hub-0.34.4 nvidia-ml-py-13.580.65 py-cpuinfo-9.0.0 transformers-4.54.0\u001B[0m\n",
      "\u001B[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001B[0m\n",
      "\u001B[34m[notice] A new release of pip is available: 25.1.1 -> 25.2\u001B[0m\n",
      "\u001B[34m[notice] To update, run: pip install --upgrade pip\u001B[0m\n",
      "\u001B[34m2025-08-13 17:30:59,210 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001B[0m\n",
      "\u001B[34m2025-08-13 17:30:59,210 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001B[0m\n",
      "\u001B[34m2025-08-13 17:30:59,272 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001B[0m\n",
      "\u001B[34m2025-08-13 17:30:59,322 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001B[0m\n",
      "\u001B[34m2025-08-13 17:30:59,332 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001B[0m\n",
      "\u001B[34m2025-08-13 17:30:59,332 sagemaker-training-toolkit INFO     Creating SSH daemon.\u001B[0m\n",
      "\u001B[34m2025-08-13 17:30:59,332 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\u001B[0m\n",
      "\u001B[34m2025-08-13 17:30:59,332 sagemaker-training-toolkit INFO     Env Hosts: ['algo-1'] Hosts: ['algo-1:4'] process_per_hosts: 4 num_processes: 4\u001B[0m\n",
      "\u001B[34m2025-08-13 17:30:59,333 sagemaker-training-toolkit INFO     Network interface name: eth0\u001B[0m\n",
      "\u001B[34m2025-08-13 17:30:59,373 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001B[0m\n",
      "\u001B[34m2025-08-13 17:30:59,422 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001B[0m\n",
      "\u001B[34m2025-08-13 17:30:59,432 sagemaker-training-toolkit INFO     Invoking user script\u001B[0m\n",
      "\u001B[34mTraining Env:\u001B[0m\n",
      "\u001B[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_mpi_custom_mpi_options\": \"\",\n",
      "        \"sagemaker_mpi_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"val\": \"/opt/ml/input/data/val\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.12xlarge\",\n",
      "    \"distribution_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"distribution_instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"deepspeed\": \"ds_zero3.json\",\n",
      "        \"learning_rate\": 3e-05,\n",
      "        \"max_steps\": 2,\n",
      "        \"num_train_epochs\": 1,\n",
      "        \"temperature\": 0.05\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"val\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.12xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-pytorch-training-2025-08-13-17-23-57-467\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://ir-sagemaker/huggingface-pytorch-training-2025-08-13-17-23-57-467/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_sm\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 48,\n",
      "    \"num_gpus\": 4,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.12xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.12xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"topology\": null\n",
      "    },\n",
      "    \"user_entry_point\": \"train_sm.py\"\u001B[0m\n",
      "\u001B[34m}\u001B[0m\n",
      "\u001B[34mEnvironment variables:\u001B[0m\n",
      "\u001B[34mSM_HOSTS=[\"algo-1\"]\u001B[0m\n",
      "\u001B[34mSM_NETWORK_INTERFACE_NAME=eth0\u001B[0m\n",
      "\u001B[34mSM_HPS={\"deepspeed\":\"ds_zero3.json\",\"learning_rate\":3e-05,\"max_steps\":2,\"num_train_epochs\":1,\"temperature\":0.05}\u001B[0m\n",
      "\u001B[34mSM_USER_ENTRY_POINT=train_sm.py\u001B[0m\n",
      "\u001B[34mSM_FRAMEWORK_PARAMS={\"sagemaker_mpi_custom_mpi_options\":\"\",\"sagemaker_mpi_enabled\":true}\u001B[0m\n",
      "\u001B[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.12xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null}\u001B[0m\n",
      "\u001B[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001B[0m\n",
      "\u001B[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001B[0m\n",
      "\u001B[34mSM_CHANNELS=[\"test\",\"train\",\"val\"]\u001B[0m\n",
      "\u001B[34mSM_CURRENT_HOST=algo-1\u001B[0m\n",
      "\u001B[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.12xlarge\u001B[0m\n",
      "\u001B[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001B[0m\n",
      "\u001B[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001B[0m\n",
      "\u001B[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001B[0m\n",
      "\u001B[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}}\u001B[0m\n",
      "\u001B[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001B[0m\n",
      "\u001B[34mSM_IS_HETERO=false\u001B[0m\n",
      "\u001B[34mSM_MODULE_NAME=train_sm\u001B[0m\n",
      "\u001B[34mSM_LOG_LEVEL=20\u001B[0m\n",
      "\u001B[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001B[0m\n",
      "\u001B[34mSM_INPUT_DIR=/opt/ml/input\u001B[0m\n",
      "\u001B[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001B[0m\n",
      "\u001B[34mSM_OUTPUT_DIR=/opt/ml/output\u001B[0m\n",
      "\u001B[34mSM_NUM_CPUS=48\u001B[0m\n",
      "\u001B[34mSM_NUM_GPUS=4\u001B[0m\n",
      "\u001B[34mSM_NUM_NEURONS=0\u001B[0m\n",
      "\u001B[34mSM_MODEL_DIR=/opt/ml/model\u001B[0m\n",
      "\u001B[34mSM_MODULE_DIR=s3://ir-sagemaker/huggingface-pytorch-training-2025-08-13-17-23-57-467/source/sourcedir.tar.gz\u001B[0m\n",
      "\u001B[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_mpi_custom_mpi_options\":\"\",\"sagemaker_mpi_enabled\":true},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"val\":\"/opt/ml/input/data/val\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.12xlarge\",\"distribution_hosts\":[\"algo-1\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"deepspeed\":\"ds_zero3.json\",\"learning_rate\":3e-05,\"max_steps\":2,\"num_train_epochs\":1,\"temperature\":0.05},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":true,\"job_name\":\"huggingface-pytorch-training-2025-08-13-17-23-57-467\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://ir-sagemaker/huggingface-pytorch-training-2025-08-13-17-23-57-467/source/sourcedir.tar.gz\",\"module_name\":\"train_sm\",\"network_interface_name\":\"eth0\",\"num_cpus\":48,\"num_gpus\":4,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.12xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"user_entry_point\":\"train_sm.py\"}\u001B[0m\n",
      "\u001B[34mSM_USER_ARGS=[\"--deepspeed\",\"ds_zero3.json\",\"--learning_rate\",\"3e-05\",\"--max_steps\",\"2\",\"--num_train_epochs\",\"1\",\"--temperature\",\"0.05\"]\u001B[0m\n",
      "\u001B[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001B[0m\n",
      "\u001B[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001B[0m\n",
      "\u001B[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001B[0m\n",
      "\u001B[34mSM_CHANNEL_VAL=/opt/ml/input/data/val\u001B[0m\n",
      "\u001B[34mSM_HP_DEEPSPEED=ds_zero3.json\u001B[0m\n",
      "\u001B[34mSM_HP_LEARNING_RATE=3e-05\u001B[0m\n",
      "\u001B[34mSM_HP_MAX_STEPS=2\u001B[0m\n",
      "\u001B[34mSM_HP_NUM_TRAIN_EPOCHS=1\u001B[0m\n",
      "\u001B[34mSM_HP_TEMPERATURE=0.05\u001B[0m\n",
      "\u001B[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python311.zip:/opt/conda/lib/python3.11:/opt/conda/lib/python3.11/lib-dynload:/opt/conda/lib/python3.11/site-packages\u001B[0m\n",
      "\u001B[34mInvoking script with the following command:\u001B[0m\n",
      "\u001B[34mmpirun --host algo-1:4 -np 4 --allow-run-as-root --display-map --tag-output -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -bind-to none -map-by slot -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -x NCCL_MIN_NRINGS=4 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x LD_PRELOAD=/opt/conda/lib/python3.11/site-packages/gethostname.cpython-311-x86_64-linux-gnu.so -x SM_HOSTS -x SM_NETWORK_INTERFACE_NAME -x SM_HPS -x SM_USER_ENTRY_POINT -x SM_FRAMEWORK_PARAMS -x SM_RESOURCE_CONFIG -x SM_INPUT_DATA_CONFIG -x SM_OUTPUT_DATA_DIR -x SM_CHANNELS -x SM_CURRENT_HOST -x SM_CURRENT_INSTANCE_TYPE -x SM_CURRENT_INSTANCE_GROUP -x SM_CURRENT_INSTANCE_GROUP_HOSTS -x SM_INSTANCE_GROUPS -x SM_INSTANCE_GROUPS_DICT -x SM_DISTRIBUTION_INSTANCE_GROUPS -x SM_IS_HETERO -x SM_MODULE_NAME -x SM_LOG_LEVEL -x SM_FRAMEWORK_MODULE -x SM_INPUT_DIR -x SM_INPUT_CONFIG_DIR -x SM_OUTPUT_DIR -x SM_NUM_CPUS -x SM_NUM_GPUS -x SM_NUM_NEURONS -x SM_MODEL_DIR -x SM_MODULE_DIR -x SM_TRAINING_ENV -x SM_USER_ARGS -x SM_OUTPUT_INTERMEDIATE_DIR -x SM_CHANNEL_TEST -x SM_CHANNEL_TRAIN -x SM_CHANNEL_VAL -x SM_HP_DEEPSPEED -x SM_HP_LEARNING_RATE -x SM_HP_MAX_STEPS -x SM_HP_NUM_TRAIN_EPOCHS -x SM_HP_TEMPERATURE -x PYTHONPATH /opt/conda/bin/python3.11 -m mpi4py train_sm.py --deepspeed ds_zero3.json --learning_rate 3e-05 --max_steps 2 --num_train_epochs 1 --temperature 0.05\u001B[0m\n",
      "\u001B[34m2025-08-13 17:30:59,472 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001B[0m\n",
      "\u001B[34m2025-08-13 17:30:59,482 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001B[0m\n",
      "\u001B[34m2025-08-13 17:30:59,482 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001B[0m\n",
      "\u001B[34m2025-08-13 17:30:59,483 sagemaker-training-toolkit INFO     smdistributed.dataparallel not found or using an older version without custom exceptions.SM training toolkit will track user script error only\u001B[0m\n",
      "\u001B[34mData for JOB [41269,1] offset 0 Total slots allocated 4\n",
      " ========================   JOB MAP   ========================\n",
      " Data for node: algo-1#011Num slots: 4#011Max slots: 0#011Num procs: 4\n",
      " #011Process OMPI jobid: [41269,1] App: 0 Process rank: 0 Bound: N/A\n",
      " #011Process OMPI jobid: [41269,1] App: 0 Process rank: 1 Bound: N/A\n",
      " #011Process OMPI jobid: [41269,1] App: 0 Process rank: 2 Bound: N/A\n",
      " #011Process OMPI jobid: [41269,1] App: 0 Process rank: 3 Bound: N/A\n",
      " =============================================================\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:[2025-08-13 17:31:02,907] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:[2025-08-13 17:31:02,908] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:[2025-08-13 17:31:02,911] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:[2025-08-13 17:31:02,913] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:df: /root/.triton/autotune: No such file or directory\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:df: /root/.triton/autotune: No such file or directory\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:[2025-08-13 17:31:05,016] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:[2025-08-13 17:31:05,016] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:[2025-08-13 17:31:05,019] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:[2025-08-13 17:31:05,021] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:#015Downloading builder script: 0.00B [00:00, ?B/s]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:#015Downloading builder script: 4.20kB [00:00, 17.7MB/s]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:#015Downloading builder script: 0.00B [00:00, ?B/s]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:#015Downloading builder script: 4.20kB [00:00, 20.0MB/s]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:#015Downloading builder script: 0.00B [00:00, ?B/s]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:#015Downloading builder script: 4.20kB [00:00, 18.6MB/s]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:#015Downloading builder script: 0.00B [00:00, ?B/s]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:#015Downloading builder script: 7.56kB [00:00, 31.2MB/s]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015Downloading builder script: 0.00B [00:00, ?B/s]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015Downloading builder script: 4.20kB [00:00, 20.5MB/s]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:#015Downloading builder script: 0.00B [00:00, ?B/s]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:#015Downloading builder script: 7.38kB [00:00, 25.4MB/s]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:#015Downloading builder script: 0.00B [00:00, ?B/s]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:#015Downloading builder script: 7.38kB [00:00, 29.8MB/s]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:#015Downloading builder script: 0.00B [00:00, ?B/s]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:#015Downloading builder script: 6.79kB [00:00, 22.6MB/s]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:/opt/conda/lib/python3.11/site-packages/accelerate/state.py:247: UserWarning: OMP_NUM_THREADS/MKL_NUM_THREADS unset, we set it at 6 to improve oob performance.\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:  warnings.warn(\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:/opt/conda/lib/python3.11/site-packages/accelerate/state.py:247: UserWarning: OMP_NUM_THREADS/MKL_NUM_THREADS unset, we set it at 6 to improve oob performance.\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:  warnings.warn(\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:/opt/conda/lib/python3.11/site-packages/accelerate/state.py:247: UserWarning: OMP_NUM_THREADS/MKL_NUM_THREADS unset, we set it at 6 to improve oob performance.\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:  warnings.warn(\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:/opt/conda/lib/python3.11/site-packages/accelerate/state.py:247: UserWarning: OMP_NUM_THREADS/MKL_NUM_THREADS unset, we set it at 6 to improve oob performance.\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:  warnings.warn(\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Parameter Offload - Persistent parameters statistics: param_count = 184, numel = 66231680\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  0%|          | 0/115 [00:00<?, ?it/s]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0813 17:31:21.072000 473 site-packages/torch/_dynamo/convert_frame.py:844] [3/8] torch._dynamo hit config.cache_size_limit (8)\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0813 17:31:21.072000 473 site-packages/torch/_dynamo/convert_frame.py:844] [3/8]    function: 'post_sub_module_forward_function' (/opt/conda/lib/python3.11/site-packages/deepspeed/runtime/zero/parameter_offload.py:477)\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0813 17:31:21.072000 473 site-packages/torch/_dynamo/convert_frame.py:844] [3/8]    last reason: 3/0: ___check_type_id(L['sub_module'], 94129246945216)           \u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0813 17:31:21.072000 473 site-packages/torch/_dynamo/convert_frame.py:844] [3/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0813 17:31:21.072000 473 site-packages/torch/_dynamo/convert_frame.py:844] [3/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0813 17:31:21.073000 473 site-packages/torch/_dynamo/convert_frame.py:844] [11/8] torch._dynamo hit config.cache_size_limit (8)\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0813 17:31:21.073000 473 site-packages/torch/_dynamo/convert_frame.py:844] [11/8]    function: '_pre_backward_module_hook' (/opt/conda/lib/python3.11/site-packages/deepspeed/runtime/zero/parameter_offload.py:348)\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0813 17:31:21.073000 473 site-packages/torch/_dynamo/convert_frame.py:844] [11/8]    last reason: 11/0: ___check_type_id(L['module'], 94129246945216)               \u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0813 17:31:21.073000 473 site-packages/torch/_dynamo/convert_frame.py:844] [11/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0813 17:31:21.073000 473 site-packages/torch/_dynamo/convert_frame.py:844] [11/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0813 17:31:21.076000 472 site-packages/torch/_dynamo/convert_frame.py:844] [3/8] torch._dynamo hit config.cache_size_limit (8)\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0813 17:31:21.076000 472 site-packages/torch/_dynamo/convert_frame.py:844] [3/8]    function: 'post_sub_module_forward_function' (/opt/conda/lib/python3.11/site-packages/deepspeed/runtime/zero/parameter_offload.py:477)\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0813 17:31:21.076000 472 site-packages/torch/_dynamo/convert_frame.py:844] [3/8]    last reason: 3/0: ___check_type_id(L['sub_module'], 94165007931792)           \u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0813 17:31:21.076000 472 site-packages/torch/_dynamo/convert_frame.py:844] [3/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0813 17:31:21.076000 472 site-packages/torch/_dynamo/convert_frame.py:844] [3/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0813 17:31:21.076000 474 site-packages/torch/_dynamo/convert_frame.py:844] [3/8] torch._dynamo hit config.cache_size_limit (8)\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0813 17:31:21.076000 474 site-packages/torch/_dynamo/convert_frame.py:844] [3/8]    function: 'post_sub_module_forward_function' (/opt/conda/lib/python3.11/site-packages/deepspeed/runtime/zero/parameter_offload.py:477)\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0813 17:31:21.076000 474 site-packages/torch/_dynamo/convert_frame.py:844] [3/8]    last reason: 3/0: ___check_type_id(L['sub_module'], 94768620522160)           \u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0813 17:31:21.076000 474 site-packages/torch/_dynamo/convert_frame.py:844] [3/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0813 17:31:21.076000 474 site-packages/torch/_dynamo/convert_frame.py:844] [3/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0813 17:31:21.077000 472 site-packages/torch/_dynamo/convert_frame.py:844] [11/8] torch._dynamo hit config.cache_size_limit (8)\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0813 17:31:21.077000 472 site-packages/torch/_dynamo/convert_frame.py:844] [11/8]    function: '_pre_backward_module_hook' (/opt/conda/lib/python3.11/site-packages/deepspeed/runtime/zero/parameter_offload.py:348)\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0813 17:31:21.077000 472 site-packages/torch/_dynamo/convert_frame.py:844] [11/8]    last reason: 11/0: ___check_type_id(L['module'], 94165007931792)               \u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0813 17:31:21.077000 472 site-packages/torch/_dynamo/convert_frame.py:844] [11/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0813 17:31:21.077000 472 site-packages/torch/_dynamo/convert_frame.py:844] [11/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0813 17:31:21.077000 474 site-packages/torch/_dynamo/convert_frame.py:844] [11/8] torch._dynamo hit config.cache_size_limit (8)\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0813 17:31:21.077000 474 site-packages/torch/_dynamo/convert_frame.py:844] [11/8]    function: '_pre_backward_module_hook' (/opt/conda/lib/python3.11/site-packages/deepspeed/runtime/zero/parameter_offload.py:348)\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0813 17:31:21.077000 474 site-packages/torch/_dynamo/convert_frame.py:844] [11/8]    last reason: 11/0: ___check_type_id(L['module'], 94768620522160)               \u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0813 17:31:21.077000 474 site-packages/torch/_dynamo/convert_frame.py:844] [11/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0813 17:31:21.077000 474 site-packages/torch/_dynamo/convert_frame.py:844] [11/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0813 17:31:21.302000 471 site-packages/torch/_dynamo/convert_frame.py:844] [3/8] torch._dynamo hit config.cache_size_limit (8)\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0813 17:31:21.302000 471 site-packages/torch/_dynamo/convert_frame.py:844] [3/8]    function: 'post_sub_module_forward_function' (/opt/conda/lib/python3.11/site-packages/deepspeed/runtime/zero/parameter_offload.py:477)\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0813 17:31:21.302000 471 site-packages/torch/_dynamo/convert_frame.py:844] [3/8]    last reason: 3/0: ___check_type_id(L['sub_module'], 94809288044352)           \u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0813 17:31:21.302000 471 site-packages/torch/_dynamo/convert_frame.py:844] [3/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0813 17:31:21.302000 471 site-packages/torch/_dynamo/convert_frame.py:844] [3/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0813 17:31:21.303000 471 site-packages/torch/_dynamo/convert_frame.py:844] [11/8] torch._dynamo hit config.cache_size_limit (8)\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0813 17:31:21.303000 471 site-packages/torch/_dynamo/convert_frame.py:844] [11/8]    function: '_pre_backward_module_hook' (/opt/conda/lib/python3.11/site-packages/deepspeed/runtime/zero/parameter_offload.py:348)\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0813 17:31:21.303000 471 site-packages/torch/_dynamo/convert_frame.py:844] [11/8]    last reason: 11/0: ___check_type_id(L['module'], 94809288044352)               \u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0813 17:31:21.303000 471 site-packages/torch/_dynamo/convert_frame.py:844] [11/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0813 17:31:21.303000 471 site-packages/torch/_dynamo/convert_frame.py:844] [11/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0813 17:31:22.881000 473 site-packages/torch/_dynamo/convert_frame.py:844] [2/8] torch._dynamo hit config.cache_size_limit (8)\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0813 17:31:22.881000 473 site-packages/torch/_dynamo/convert_frame.py:844] [2/8]    function: '_post_forward_module_hook' (/opt/conda/lib/python3.11/site-packages/deepspeed/runtime/zero/parameter_offload.py:300)\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0813 17:31:22.881000 473 site-packages/torch/_dynamo/convert_frame.py:844] [2/8]    last reason: 2/0: ___check_type_id(L['module'], 94129246945216)               \u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0813 17:31:22.881000 473 site-packages/torch/_dynamo/convert_frame.py:844] [2/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0813 17:31:22.881000 473 site-packages/torch/_dynamo/convert_frame.py:844] [2/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0813 17:31:22.884000 472 site-packages/torch/_dynamo/convert_frame.py:844] [2/8] torch._dynamo hit config.cache_size_limit (8)\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0813 17:31:22.884000 472 site-packages/torch/_dynamo/convert_frame.py:844] [2/8]    function: '_post_forward_module_hook' (/opt/conda/lib/python3.11/site-packages/deepspeed/runtime/zero/parameter_offload.py:300)\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0813 17:31:22.884000 472 site-packages/torch/_dynamo/convert_frame.py:844] [2/8]    last reason: 2/0: ___check_type_id(L['module'], 94165007931792)               \u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0813 17:31:22.884000 472 site-packages/torch/_dynamo/convert_frame.py:844] [2/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0813 17:31:22.884000 472 site-packages/torch/_dynamo/convert_frame.py:844] [2/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0813 17:31:22.890000 474 site-packages/torch/_dynamo/convert_frame.py:844] [2/8] torch._dynamo hit config.cache_size_limit (8)\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0813 17:31:22.890000 474 site-packages/torch/_dynamo/convert_frame.py:844] [2/8]    function: '_post_forward_module_hook' (/opt/conda/lib/python3.11/site-packages/deepspeed/runtime/zero/parameter_offload.py:300)\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0813 17:31:22.890000 474 site-packages/torch/_dynamo/convert_frame.py:844] [2/8]    last reason: 2/0: ___check_type_id(L['module'], 94768620522160)               \u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0813 17:31:22.890000 474 site-packages/torch/_dynamo/convert_frame.py:844] [2/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0813 17:31:22.890000 474 site-packages/torch/_dynamo/convert_frame.py:844] [2/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0813 17:31:22.892000 471 site-packages/torch/_dynamo/convert_frame.py:844] [2/8] torch._dynamo hit config.cache_size_limit (8)\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0813 17:31:22.892000 471 site-packages/torch/_dynamo/convert_frame.py:844] [2/8]    function: '_post_forward_module_hook' (/opt/conda/lib/python3.11/site-packages/deepspeed/runtime/zero/parameter_offload.py:300)\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0813 17:31:22.892000 471 site-packages/torch/_dynamo/convert_frame.py:844] [2/8]    last reason: 2/0: ___check_type_id(L['module'], 94809288044352)               \u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0813 17:31:22.892000 471 site-packages/torch/_dynamo/convert_frame.py:844] [2/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0813 17:31:22.892000 471 site-packages/torch/_dynamo/convert_frame.py:844] [2/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  1%|          | 1/115 [00:12<24:12, 12.74s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  2%|▏         | 2/115 [00:15<13:12,  7.02s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  3%|▎         | 3/115 [00:18<09:40,  5.18s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  3%|▎         | 4/115 [00:21<08:01,  4.33s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  4%|▍         | 5/115 [00:24<07:03,  3.85s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  5%|▌         | 6/115 [00:27<06:32,  3.60s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  6%|▌         | 7/115 [00:30<06:09,  3.42s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  7%|▋         | 8/115 [00:33<05:52,  3.29s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  8%|▊         | 9/115 [00:36<05:39,  3.20s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  9%|▊         | 10/115 [00:39<05:28,  3.13s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 10%|▉         | 11/115 [00:42<05:21,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 10%|█         | 12/115 [00:45<05:16,  3.07s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 11%|█▏        | 13/115 [00:49<05:15,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 12%|█▏        | 14/115 [00:52<05:10,  3.07s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 13%|█▎        | 15/115 [00:55<05:06,  3.07s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 14%|█▍        | 16/115 [00:58<05:03,  3.07s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 15%|█▍        | 17/115 [01:01<05:01,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 16%|█▌        | 18/115 [01:04<04:56,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 17%|█▋        | 19/115 [01:07<04:53,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 17%|█▋        | 20/115 [01:10<04:51,  3.07s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 18%|█▊        | 21/115 [01:13<04:47,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 19%|█▉        | 22/115 [01:16<04:44,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 20%|██        | 23/115 [01:19<04:41,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 21%|██        | 24/115 [01:22<04:37,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 22%|██▏       | 25/115 [01:25<04:34,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 23%|██▎       | 26/115 [01:28<04:30,  3.04s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 23%|██▎       | 27/115 [01:31<04:27,  3.04s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 24%|██▍       | 28/115 [01:34<04:25,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 25%|██▌       | 29/115 [01:37<04:22,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 26%|██▌       | 30/115 [01:40<04:19,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 27%|██▋       | 31/115 [01:44<04:16,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 28%|██▊       | 32/115 [01:47<04:14,  3.07s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 29%|██▊       | 33/115 [01:50<04:11,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 30%|██▉       | 34/115 [01:53<04:07,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 30%|███       | 35/115 [01:56<04:04,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 31%|███▏      | 36/115 [01:59<04:01,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 32%|███▏      | 37/115 [02:02<03:58,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 33%|███▎      | 38/115 [02:05<03:55,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 34%|███▍      | 39/115 [02:08<03:52,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 35%|███▍      | 40/115 [02:11<03:49,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 36%|███▌      | 41/115 [02:14<03:47,  3.07s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 37%|███▋      | 42/115 [02:17<03:42,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 37%|███▋      | 43/115 [02:20<03:39,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 38%|███▊      | 44/115 [02:23<03:36,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 39%|███▉      | 45/115 [02:26<03:33,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 40%|████      | 46/115 [02:29<03:30,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 41%|████      | 47/115 [02:32<03:27,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 42%|████▏     | 48/115 [02:36<03:24,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 43%|████▎     | 49/115 [02:39<03:21,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 43%|████▎     | 50/115 [02:42<03:18,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:{'loss': 3.26, 'grad_norm': 20.77930637932234, 'learning_rate': 1.7217391304347826e-05, 'epoch': 0.43}\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 43%|████▎     | 50/115 [02:42<03:18,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 44%|████▍     | 51/115 [02:45<03:14,  3.04s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 45%|████▌     | 52/115 [02:48<03:11,  3.04s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 46%|████▌     | 53/115 [02:51<03:09,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 47%|████▋     | 54/115 [02:54<03:05,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 48%|████▊     | 55/115 [02:57<03:04,  3.07s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 49%|████▊     | 56/115 [03:00<02:59,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 50%|████▉     | 57/115 [03:03<02:56,  3.04s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 50%|█████     | 58/115 [03:06<02:53,  3.04s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 51%|█████▏    | 59/115 [03:09<02:50,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 52%|█████▏    | 60/115 [03:12<02:47,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 53%|█████▎    | 61/115 [03:15<02:45,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 54%|█████▍    | 62/115 [03:18<02:42,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 55%|█████▍    | 63/115 [03:21<02:38,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 56%|█████▌    | 64/115 [03:24<02:35,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 57%|█████▋    | 65/115 [03:27<02:32,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 57%|█████▋    | 66/115 [03:31<02:30,  3.07s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 58%|█████▊    | 67/115 [03:34<02:28,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 59%|█████▉    | 68/115 [03:37<02:24,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 60%|██████    | 69/115 [03:40<02:22,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 61%|██████    | 70/115 [03:43<02:18,  3.07s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 62%|██████▏   | 71/115 [03:46<02:14,  3.07s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 63%|██████▎   | 72/115 [03:49<02:11,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 63%|██████▎   | 73/115 [03:52<02:08,  3.07s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 64%|██████▍   | 74/115 [03:55<02:05,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 65%|██████▌   | 75/115 [03:58<02:02,  3.07s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 66%|██████▌   | 76/115 [04:01<01:59,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 67%|██████▋   | 77/115 [04:04<01:56,  3.07s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 68%|██████▊   | 78/115 [04:07<01:53,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 69%|██████▊   | 79/115 [04:10<01:49,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 70%|██████▉   | 80/115 [04:14<01:48,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 70%|███████   | 81/115 [04:17<01:45,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 71%|███████▏  | 82/115 [04:20<01:41,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 72%|███████▏  | 83/115 [04:23<01:38,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 73%|███████▎  | 84/115 [04:26<01:34,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 74%|███████▍  | 85/115 [04:29<01:31,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 75%|███████▍  | 86/115 [04:32<01:28,  3.04s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 76%|███████▌  | 87/115 [04:35<01:24,  3.03s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 77%|███████▋  | 88/115 [04:38<01:22,  3.04s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 77%|███████▋  | 89/115 [04:41<01:18,  3.03s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 78%|███████▊  | 90/115 [04:44<01:15,  3.03s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 79%|███████▉  | 91/115 [04:47<01:12,  3.03s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 80%|████████  | 92/115 [04:50<01:10,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 81%|████████  | 93/115 [04:53<01:07,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 82%|████████▏ | 94/115 [04:56<01:04,  3.07s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 83%|████████▎ | 95/115 [05:00<01:02,  3.13s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 83%|████████▎ | 96/115 [05:03<00:58,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 84%|████████▍ | 97/115 [05:06<00:55,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 85%|████████▌ | 98/115 [05:09<00:52,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 86%|████████▌ | 99/115 [05:12<00:49,  3.07s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 87%|████████▋ | 100/115 [05:15<00:45,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:{'loss': 2.5366, 'grad_norm': 6.543193416064348, 'learning_rate': 4.173913043478261e-06, 'epoch': 0.87}\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 87%|████████▋ | 100/115 [05:15<00:45,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 88%|████████▊ | 101/115 [05:18<00:42,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 89%|████████▊ | 102/115 [05:21<00:39,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 90%|████████▉ | 103/115 [05:24<00:36,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 90%|█████████ | 104/115 [05:27<00:33,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 91%|█████████▏| 105/115 [05:30<00:30,  3.04s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 92%|█████████▏| 106/115 [05:33<00:27,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 93%|█████████▎| 107/115 [05:36<00:24,  3.04s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 94%|█████████▍| 108/115 [05:39<00:21,  3.04s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 95%|█████████▍| 109/115 [05:42<00:18,  3.03s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 96%|█████████▌| 110/115 [05:45<00:15,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 97%|█████████▋| 111/115 [05:48<00:12,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 97%|█████████▋| 112/115 [05:51<00:09,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 98%|█████████▊| 113/115 [05:54<00:06,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 99%|█████████▉| 114/115 [05:57<00:03,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 115/115 [06:01<00:00,  3.04s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  0%|          | 0/15 [00:00<?, ?it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 13%|█▎        | 2/15 [00:01<00:08,  1.54it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 20%|██        | 3/15 [00:02<00:11,  1.09it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 27%|██▋       | 4/15 [00:03<00:11,  1.07s/it]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 33%|███▎      | 5/15 [00:05<00:11,  1.14s/it]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 40%|████      | 6/15 [00:06<00:10,  1.18s/it]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 47%|████▋     | 7/15 [00:07<00:09,  1.21s/it]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval[1,mpirank:3,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: [1,mpirank:1,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) [1,mpirank:2,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 53%|█████▎    | 8/15 [00:09<00:08,  1.23s/it]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval [1,mpirank:0,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 60%|██████    | 9/15 [00:10<00:07,  1.25s/it]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 67%|██████▋   | 10/15 [00:11<00:06,  1.27s/it]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 73%|███████▎  | 11/15 [00:12<00:05,  1.27s/it]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 80%|████████  | 12/15 [00:14<00:03,  1.27s/it]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 87%|████████▋ | 13/15 [00:15<00:02,  1.28s/it]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])[1,mpirank:3,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 93%|█████████▎| 14/15 [00:16<00:01,  1.27s/it]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits shape eval: torch.Size([8, 32]) Labels eval torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 15/15 [00:17<00:00,  1.27s/it]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015                                                 #015\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015                                               #015#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:{'eval_accuracy': 0.025, 'eval_precision': 0.0009590792838874682, 'eval_recall': 0.025, 'eval_f1': 0.0018472906403940886, 'epoch': 1.0}\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 115/115 [06:20<00:00,  3.04s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 15/15 [00:18<00:00,  1.27s/it]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015                                                 #015\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015                                               #015#033[A[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 115/115 [06:20<00:00,  3.04s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:{'eval_accuracy': 0.025, 'eval_precision': 0.0009590792838874682, 'eval_recall': 0.025, 'eval_f1': 0.0018472906403940886, 'eval_epoch': 1.0, 'eval_runtime': 19.1149, 'eval_samples_per_second': 25.268, 'eval_steps_per_second': 0.837, 'epoch': 1.0}\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 15/15 [00:18<00:00,  1.27s/it]#033[A[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015                                               #033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:{'train_runtime': 380.13, 'train_samples_per_second': 9.705, 'train_steps_per_second': 0.303, 'train_loss': 2.807133152173913, 'epoch': 1.0}\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 115/115 [06:20<00:00,  3.04s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 115/115 [06:20<00:00,  3.31s/it]\u001B[0m\n",
      "\u001B[34m2025-08-13 17:37:41,686 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001B[0m\n",
      "\u001B[34m2025-08-13 17:37:41,686 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001B[0m\n",
      "\u001B[34m2025-08-13 17:37:41,686 sagemaker-training-toolkit INFO     Begin writing status file from leader node to worker nodes (if any)\u001B[0m\n",
      "\u001B[34m2025-08-13 17:38:11,687 sagemaker-training-toolkit INFO     Finished writing status file from leader node to worker nodes (if any)\u001B[0m\n",
      "\u001B[34m2025-08-13 17:38:11,687 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001B[0m\n",
      "\n",
      "2025-08-13 17:38:17 Uploading - Uploading generated training model\n",
      "2025-08-13 17:38:35 Completed - Training job completed\n",
      "Training seconds: 808\n",
      "Billable seconds: 808\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T12:30:56.274476Z",
     "start_time": "2025-07-30T12:30:55.381591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sagemaker.analytics import TrainingJobAnalytics\n",
    "\n",
    "df = TrainingJobAnalytics(training_job_name='huggingface-pytorch-training-2025-07-30-03-59-45-613').dataframe()\n",
    "print(df)\n"
   ],
   "id": "1b65b20af226c80b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.analytics:Warning: No metrics called eval_loss found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    timestamp              metric_name      value\n",
      "0         0.0                     loss   3.360500\n",
      "1       180.0                     loss   2.731600\n",
      "2         0.0            learning_rate   1.721739\n",
      "3       180.0            learning_rate   4.173913\n",
      "4         0.0            eval_accuracy   0.031250\n",
      "5         0.0                  eval_f1   0.019156\n",
      "6         0.0           eval_precision   0.022735\n",
      "7         0.0              eval_recall   0.031250\n",
      "8         0.0             eval_runtime  21.798900\n",
      "9         0.0  eval_samples_per_second  22.157000\n",
      "10        0.0                    epoch   0.430000\n",
      "11      180.0                    epoch   0.870000\n",
      "12      240.0                    epoch   1.000000\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Model Evaluation",
   "id": "638a9ec4cfac0973"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T14:48:38.152784Z",
     "start_time": "2025-08-18T14:48:37.663420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import faiss\n",
    "import uuid\n",
    "import sagemaker\n",
    "import torch\n",
    "\n",
    "print(\"numpy version:\", np.__version__)\n",
    "print(\"tqdm version:\", tqdm.__version__)\n",
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"faiss version:\", faiss.__version__)"
   ],
   "id": "abce49817bc1469",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.26.4\n",
      "tqdm version: 4.67.1\n",
      "torch version: 2.8.0+cu128\n",
      "faiss version: 1.9.0\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T14:48:50.833663Z",
     "start_time": "2025-08-18T14:48:44.972774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "model_data = f\"s3://{bucket}/{prefix}/outputs/huggingface-pytorch-training-2025-08-13-17-23-57-467/output/model.tar.gz\"\n",
    "run_id = uuid.uuid4().hex\n",
    "input_key = f\"{prefix}/target_set/target_set.jsonl\"\n",
    "output_key = f\"{prefix}/batch-output/{run_id}.jsonl\"\n",
    "\n",
    "body = s3.get_object(Bucket=bucket, Key=input_key)[\"Body\"].read().decode(\"utf-8\")\n",
    "j = 0\n",
    "out_buf = io.StringIO()\n",
    "for line in body.splitlines():\n",
    "    #if j == 1:\n",
    "    #    break\n",
    "    #j += 1\n",
    "    rec = json.loads(line)\n",
    "    doc_id = rec[\"doc_id\"]\n",
    "    for i, sent in enumerate(rec[\"case_text\"]):\n",
    "        #if i == 3:\n",
    "         #   break\n",
    "        out_buf.write(json.dumps({\"docid\": doc_id, \"sentid\": i, \"inputs\": sent}) + \"\\n\")\n",
    "        # print(j,i)\n",
    "\n",
    "s3.put_object(Bucket=bucket, Key=output_key, Body=out_buf.getvalue().encode(\"utf-8\"))\n",
    "sentences_set_uri = f\"s3://{bucket}/{output_key}\"\n",
    "print(sentences_set_uri)"
   ],
   "id": "c70984cad18e0172",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://ir-sagemaker/modernbert/batch-output/f84d458b9c8b4cff8b8db170fca64a6c.jsonl\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-08-18T14:49:08.727650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_prefix = f\"{prefix}/embedded-output/{run_id}\"\n",
    "print(sentences_set_uri)\n",
    "# create model class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    transformers_version=\"4.49.0\",\n",
    "    pytorch_version=\"2.6.0\",\n",
    "    py_version=\"py312\",\n",
    "    entry_point=\"inference.py\",\n",
    "    source_dir=\"code\",\n",
    "    env={\n",
    "        \"TOWER\": \"suffix\",\n",
    "        \"POOLING\": \"mean\",\n",
    "        \"NORMALIZE\": \"true\",\n",
    "        \"MAX_LEN\": \"512\",\n",
    "    }\n",
    ")\n",
    "\n",
    "transformer = huggingface_model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.g5.2xlarge\",\n",
    "    output_path=f\"s3://{bucket}/{output_prefix}\",\n",
    "    assemble_with=\"Line\",\n",
    "    accept=\"application/jsonlines\",\n",
    "    strategy=\"MultiRecord\",\n",
    "    max_payload=1,\n",
    "    max_concurrent_transforms=2,\n",
    "    env={\"TS_MAX_RESPONSE_SIZE\": \"100000000\",\n",
    "         \"TS_MAX_REQUEST_SIZE\":  \"100000000\",},\n",
    ")\n",
    "\n",
    "transformer.transform(\n",
    "    data=sentences_set_uri,\n",
    "    content_type=\"application/jsonlines\",\n",
    "    split_type=\"Line\",\n",
    "    input_filter=\"$.inputs\",\n",
    "    join_source=\"Input\",\n",
    ")\n",
    "transformer.wait()\n",
    "\n",
    "resp = s3.list_objects_v2(Bucket=bucket, Prefix=output_prefix)\n",
    "out_keys = [o[\"Key\"] for o in resp.get(\"Contents\", []) if o[\"Key\"].endswith(\".out\")]\n",
    "assert out_keys, f\"No output files under s3://{bucket}/{output_prefix}\"\n",
    "\n",
    "sent_embeddings = {}\n",
    "\n",
    "for k in out_keys:\n",
    "    obj = s3.get_object(Bucket=bucket, Key=k)\n",
    "    for raw in obj[\"Body\"].iter_lines():\n",
    "        if not raw:\n",
    "            continue\n",
    "        rec = json.loads(raw)\n",
    "\n",
    "        # after join_source=\"Input\", your metadata is intact and the prediction is here:\n",
    "        emb = rec[\"SageMakerOutput\"][\"embedding\"]     # shape depends on your model/inference.py\n",
    "\n",
    "        # Build a stable key (doc_id + sent_id)\n",
    "        key = f'{rec[\"docid\"]}:{rec[\"sentid\"]}'\n",
    "        sent_embeddings[key] = np.array(emb, dtype=\"float32\")"
   ],
   "id": "e291db22fb7c4178",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://ir-sagemaker/modernbert/batch-output/f84d458b9c8b4cff8b8db170fca64a6c.jsonl\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T23:52:25.947211Z",
     "start_time": "2025-08-17T23:52:25.539806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pprint\n",
    "\n",
    "sm = boto3.client(\"sagemaker\")\n",
    "\n",
    "job_name = \"huggingface-pytorch-inference-2025-08-17-20-24-43-053\"\n",
    "resp = sm.describe_transform_job(TransformJobName=job_name)\n",
    "\n",
    "# Print the bits that matter for JSONL + join\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "pp.pprint({\n",
    "    \"Status\": resp[\"TransformJobStatus\"],\n",
    "    \"FailureReason\": resp.get(\"FailureReason\"),\n",
    "    \"BatchStrategy\": resp.get(\"BatchStrategy\"),\n",
    "    \"MaxPayloadInMB\": resp.get(\"MaxPayloadInMB\"),\n",
    "    \"TransformInput\": {\n",
    "        \"ContentType\": resp[\"TransformInput\"].get(\"ContentType\"),\n",
    "        \"SplitType\": resp[\"TransformInput\"].get(\"SplitType\"),\n",
    "    },\n",
    "    \"TransformOutput\": {\n",
    "        \"Accept\": resp[\"TransformOutput\"].get(\"Accept\"),\n",
    "        \"AssembleWith\": resp[\"TransformOutput\"].get(\"AssembleWith\"),\n",
    "        \"S3OutputPath\": resp[\"TransformOutput\"][\"S3OutputPath\"],\n",
    "    },\n",
    "    \"DataProcessing\": resp.get(\"DataProcessing\"),  # includes JoinSource, OutputFilter\n",
    "})"
   ],
   "id": "13daf19bfd35b0bd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[38;2;255;0;0m╭─\u001B[0m\u001B[38;2;255;0;0m──────────────────────────────\u001B[0m\u001B[38;2;255;0;0m \u001B[0m\u001B[1;38;2;255;0;0mTraceback \u001B[0m\u001B[1;2;38;2;255;0;0m(most recent call last)\u001B[0m\u001B[38;2;255;0;0m \u001B[0m\u001B[38;2;255;0;0m───────────────────────────────\u001B[0m\u001B[38;2;255;0;0m─╮\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m in <module>:6                                                                                    \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m                                                                                                  \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m 3 \u001B[0msm = boto3.client(\u001B[33m\"\u001B[0m\u001B[33msagemaker\u001B[0m\u001B[33m\"\u001B[0m)                                                              \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m 4 \u001B[0m                                                                                            \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m 5 \u001B[0mjob_name = \u001B[33m\"\u001B[0m\u001B[33mhuggingface-pytorch-training-2025-08-13-17-23-57-467\u001B[0m\u001B[33m\"\u001B[0m                           \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m \u001B[31m❱ \u001B[0m 6 resp = \u001B[1;4msm.describe_transform_job(TransformJobName=job_name)\u001B[0m                                 \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m 7 \u001B[0m                                                                                            \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m 8 \u001B[0m\u001B[2m# Print the bits that matter for JSONL + join\u001B[0m                                               \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m 9 \u001B[0mpp = pprint.PrettyPrinter(indent=\u001B[94m2\u001B[0m)                                                         \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m                                                                                                  \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m \u001B[2m/home/lbrenap/miniconda3/envs/legalpacaenv/lib/python3.11/site-packages/botocore/\u001B[0m\u001B[1mclient.py\u001B[0m:601   \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m in _api_call                                                                                     \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m                                                                                                  \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m 598 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0m\u001B[33mf\u001B[0m\u001B[33m\"\u001B[0m\u001B[33m{\u001B[0mpy_operation_name\u001B[33m}\u001B[0m\u001B[33m() only accepts keyword arguments.\u001B[0m\u001B[33m\"\u001B[0m              \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m 599 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m)                                                                         \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m 600 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[2m# The \"self\" in this scope is referring to the BaseClient.\u001B[0m                    \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m \u001B[31m❱ \u001B[0m 601 \u001B[2m│   │   │   \u001B[0m\u001B[94mreturn\u001B[0m \u001B[1;4;96mself\u001B[0m\u001B[1;4m._make_api_call(operation_name, kwargs)\u001B[0m                            \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m 602 \u001B[0m\u001B[2m│   │   \u001B[0m                                                                                  \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m 603 \u001B[0m\u001B[2m│   │   \u001B[0m_api_call.\u001B[91m__name__\u001B[0m = \u001B[96mstr\u001B[0m(py_operation_name)                                       \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m 604 \u001B[0m                                                                                          \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m                                                                                                  \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m \u001B[2m/home/lbrenap/miniconda3/envs/legalpacaenv/lib/python3.11/site-packages/botocore/\u001B[0m\u001B[1mcontext.py\u001B[0m:123  \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m in wrapper                                                                                       \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m                                                                                                  \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m120 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mwith\u001B[0m start_as_current_context():                                               \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m121 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[94mif\u001B[0m hook:                                                                   \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m122 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0mhook()                                                                 \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m \u001B[31m❱ \u001B[0m123 \u001B[2m│   │   │   │   \u001B[0m\u001B[94mreturn\u001B[0m \u001B[1;4mfunc(*args, **kwargs)\u001B[0m                                               \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m124 \u001B[0m\u001B[2m│   │   \u001B[0m                                                                                   \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m125 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mreturn\u001B[0m wrapper                                                                     \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m126 \u001B[0m                                                                                           \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m                                                                                                  \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m \u001B[2m/home/lbrenap/miniconda3/envs/legalpacaenv/lib/python3.11/site-packages/botocore/\u001B[0m\u001B[1mclient.py\u001B[0m:1074  \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m in _make_api_call                                                                                \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m                                                                                                  \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m1071 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[33m'\u001B[0m\u001B[33merror_code_override\u001B[0m\u001B[33m'\u001B[0m                                                     \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m1072 \u001B[0m\u001B[2m│   │   │   \u001B[0m) \u001B[95mor\u001B[0m error_info.get(\u001B[33m\"\u001B[0m\u001B[33mCode\u001B[0m\u001B[33m\"\u001B[0m)                                                   \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m1073 \u001B[0m\u001B[2m│   │   │   \u001B[0merror_class = \u001B[96mself\u001B[0m.exceptions.from_code(error_code)                           \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m \u001B[31m❱ \u001B[0m1074 \u001B[2m│   │   │   \u001B[0m\u001B[1;4;94mraise\u001B[0m\u001B[1;4m error_class(parsed_response, operation_name)\u001B[0m                            \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m1075 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94melse\u001B[0m:                                                                             \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m1076 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mreturn\u001B[0m parsed_response                                                        \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m1077 \u001B[0m                                                                                          \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n",
       "\u001B[1;91mClientError: \u001B[0mAn error occurred \u001B[1m(\u001B[0mValidationException\u001B[1m)\u001B[0m when calling the DescribeTransformJob operation: Could not \n",
       "find requested job with name: huggingface-pytorch-training-\u001B[1;36m2025\u001B[0m-08-13-17-23-57-467\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">╭─────────────────────────────── </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Traceback </span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> in &lt;module&gt;:6                                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>sm = boto3.client(<span style=\"color: #808000; text-decoration-color: #808000\">\"sagemaker\"</span>)                                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>                                                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>job_name = <span style=\"color: #808000; text-decoration-color: #808000\">\"huggingface-pytorch-training-2025-08-13-17-23-57-467\"</span>                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 6 resp = <span style=\"font-weight: bold; text-decoration: underline\">sm.describe_transform_job(TransformJobName=job_name)</span>                                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span>                                                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 # Print the bits that matter for JSONL + join</span>                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span>pp = pprint.PrettyPrinter(indent=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>)                                                         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/lbrenap/miniconda3/envs/legalpacaenv/lib/python3.11/site-packages/botocore/</span><span style=\"font-weight: bold\">client.py</span>:601   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> in _api_call                                                                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 598 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"{</span>py_operation_name<span style=\"color: #808000; text-decoration-color: #808000\">}() only accepts keyword arguments.\"</span>              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 599 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>)                                                                         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 600 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># The \"self\" in this scope is referring to the BaseClient.</span>                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 601 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">self</span><span style=\"font-weight: bold; text-decoration: underline\">._make_api_call(operation_name, kwargs)</span>                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 602 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 603 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>_api_call.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span> = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>(py_operation_name)                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 604 </span>                                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/lbrenap/miniconda3/envs/legalpacaenv/lib/python3.11/site-packages/botocore/</span><span style=\"font-weight: bold\">context.py</span>:123  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> in wrapper                                                                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">120 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> start_as_current_context():                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> hook:                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">122 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>hook()                                                                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>123 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"font-weight: bold; text-decoration: underline\">func(*args, **kwargs)</span>                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">124 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">125 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> wrapper                                                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">126 </span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/lbrenap/miniconda3/envs/legalpacaenv/lib/python3.11/site-packages/botocore/</span><span style=\"font-weight: bold\">client.py</span>:1074  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> in _make_api_call                                                                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1071 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">'error_code_override'</span>                                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1072 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> error_info.get(<span style=\"color: #808000; text-decoration-color: #808000\">\"Code\"</span>)                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1073 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>error_class = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.exceptions.from_code(error_code)                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1074 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">raise</span><span style=\"font-weight: bold; text-decoration: underline\"> error_class(parsed_response, operation_name)</span>                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1075 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1076 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> parsed_response                                                        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1077 </span>                                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ClientError: </span>An error occurred <span style=\"font-weight: bold\">(</span>ValidationException<span style=\"font-weight: bold\">)</span> when calling the DescribeTransformJob operation: Could not \n",
       "find requested job with name: huggingface-pytorch-training-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-08-13-17-23-57-467\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T01:16:58.327730Z",
     "start_time": "2025-08-18T01:16:58.096984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resp = s3.list_objects_v2(Bucket=bucket, Prefix=output_prefix)\n",
    "out_keys = [o[\"Key\"] for o in resp.get(\"Contents\", []) if o[\"Key\"].endswith(\".out\")]\n",
    "assert out_keys, f\"No output files under s3://{bucket}/{output_prefix}\"\n",
    "\n",
    "sent_embeddings = {}\n",
    "\n",
    "for k in out_keys:\n",
    "    obj = s3.get_object(Bucket=bucket, Key=k)\n",
    "    for raw in obj[\"Body\"].iter_lines():\n",
    "        if not raw:\n",
    "            continue\n",
    "        rec = json.loads(raw)\n",
    "\n",
    "        # after join_source=\"Input\", your metadata is intact and the prediction is here:\n",
    "        emb = rec[\"embedding\"]\n",
    "\n",
    "        key = f'{rec[\"docid\"]}:{rec[\"sentid\"]}'\n",
    "        sent_embeddings[key] = np.array(emb, dtype=\"float32\")\n",
    "\n",
    "print(sent_embeddings)\n"
   ],
   "id": "2675315ccb19f68",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A2016_European_Commission_v_World_Duty_Free:0': array([ 2.96334340e-03, -4.57810657e-03, -6.03524968e-03,  7.31856190e-03,\n",
      "       -8.56655836e-03, -6.94716908e-03, -3.47589375e-03, -6.84461324e-03,\n",
      "       -5.52418455e-03,  2.63813697e-03,  4.52040089e-03,  7.85660371e-03,\n",
      "       -4.01485851e-03,  2.65545258e-03,  2.57724710e-03, -2.26619653e-03,\n",
      "        1.61755388e-03,  7.75666535e-03,  3.90741305e-04, -1.36289571e-03,\n",
      "        1.00031858e-02,  2.83362751e-04,  8.95528123e-03,  3.11931071e-04,\n",
      "       -3.84916062e-03, -4.70993016e-03, -4.46944311e-03,  2.82229879e-03,\n",
      "        8.38186964e-03,  4.94436268e-03,  3.38223227e-03,  1.13856858e-02,\n",
      "       -2.42447364e-03,  2.77312007e-03,  8.80937371e-03,  3.13100452e-03,\n",
      "       -2.38765636e-03,  1.15786744e-02,  4.72873123e-03, -7.73071684e-03,\n",
      "       -2.03685230e-03,  5.07178309e-04,  2.36486504e-03, -4.66394471e-03,\n",
      "       -2.40622554e-03,  4.10904037e-03,  9.32672527e-03,  3.80355702e-03,\n",
      "       -3.97333689e-03,  1.13462415e-02,  1.75045207e-04, -8.59947701e-04,\n",
      "        5.04052034e-03, -2.94161960e-03, -6.79671392e-03,  7.44117610e-03,\n",
      "        7.93814566e-03, -7.42796063e-03, -2.99245398e-03, -2.34300783e-03,\n",
      "        3.15222103e-04,  2.50913290e-04, -1.21976808e-03,  2.99262756e-04,\n",
      "        2.95959879e-03, -4.92067635e-03, -5.43726189e-03, -1.21289589e-01,\n",
      "       -4.51587286e-04,  9.72205773e-03,  2.55202851e-03,  2.41062301e-03,\n",
      "       -1.09989410e-02, -6.35418110e-03, -3.82652692e-03,  4.65572299e-03,\n",
      "       -2.47815624e-03,  2.50098016e-03, -1.54682749e-03,  6.13642950e-03,\n",
      "        1.69798994e-04,  1.06494119e-02,  1.30743785e-02,  7.28369365e-03,\n",
      "        6.27619540e-03,  1.08116306e-03,  5.76987024e-03,  7.27270590e-03,\n",
      "       -6.93108700e-03, -8.01566709e-03,  4.19603428e-03, -1.60061009e-03,\n",
      "        9.97423194e-03, -1.35464622e-02,  1.07267895e-03,  1.53977377e-03,\n",
      "        8.69133230e-03,  1.06849968e-02,  2.59233988e-03, -1.23712989e-02,\n",
      "       -2.32810460e-04,  9.61211603e-03,  2.84760189e-03,  6.07653102e-03,\n",
      "        2.04353919e-03, -2.33932538e-03, -3.03751207e-03,  1.34092607e-02,\n",
      "       -8.59550573e-03,  2.71187024e-03,  7.15037948e-03, -6.56462973e-03,\n",
      "        2.83494848e-03,  1.42579229e-05,  4.79485700e-03,  1.65746938e-02,\n",
      "       -1.44951488e-03,  9.82197095e-03, -6.98467018e-03,  7.71201914e-03,\n",
      "        6.09526597e-03,  6.51788316e-04, -3.90896434e-03,  6.76857168e-03,\n",
      "       -2.18555401e-03,  6.45548664e-03, -5.14290947e-03,  7.71926669e-03,\n",
      "       -6.84826635e-03,  1.02516101e-03,  1.20760151e-03, -2.66977143e-03,\n",
      "        2.86726063e-05, -2.67579965e-03, -6.93498878e-04, -3.29179503e-03,\n",
      "        4.86819277e-04, -5.53361548e-04, -5.01447078e-03,  8.42193980e-03,\n",
      "       -5.99112222e-03,  6.89922657e-04,  3.72339338e-02,  6.35312032e-03,\n",
      "        8.05386994e-03,  2.84068426e-03, -2.68877205e-03, -3.62205319e-03,\n",
      "        3.84919076e-05,  4.67398670e-03,  3.93287465e-03,  1.19647814e-03,\n",
      "        4.08903183e-03,  2.58432887e-03, -3.31309857e-03, -2.67421640e-03,\n",
      "       -2.27639521e-03, -6.07304415e-03, -4.50891326e-04, -1.51933404e-04,\n",
      "       -4.38091578e-03,  1.30589781e-02,  2.47801002e-03,  1.89070997e-03,\n",
      "       -3.39152711e-03, -7.01233838e-03,  5.81407221e-03, -1.55302801e-03,\n",
      "       -6.12749346e-03, -3.68653773e-03, -6.59564696e-03, -1.09334302e-03,\n",
      "       -3.93290678e-03,  4.32492141e-03,  1.96793652e-03,  1.21444911e-02,\n",
      "        1.27233360e-02,  9.39614419e-03,  4.02829610e-03,  2.67245471e-02,\n",
      "       -1.05548526e-04,  1.19368378e-02, -1.14719588e-02, -3.23515059e-03,\n",
      "        1.44368820e-02, -4.88548446e-03, -7.82467658e-04,  2.69722892e-03,\n",
      "        1.26198875e-02,  6.87192194e-04,  5.81309712e-03, -9.12354793e-04,\n",
      "       -7.91906659e-03,  1.14505114e-02, -1.79910020e-03,  6.28084596e-03,\n",
      "        8.45078845e-03,  5.87833161e-03,  1.84015589e-04,  3.57383676e-03,\n",
      "        6.02816232e-03, -5.00840833e-03, -1.55744411e-03, -9.12088726e-04,\n",
      "        3.75223253e-03,  1.49729557e-03, -4.66565136e-03, -1.04891288e-03,\n",
      "       -6.64689764e-03, -6.61314232e-03, -6.52025454e-03,  8.93163495e-03,\n",
      "        9.22383100e-04,  1.00334035e-03, -5.05562406e-03,  7.06475694e-03,\n",
      "        2.60944455e-03, -2.18684349e-04,  2.19761836e-03,  2.96948897e-03,\n",
      "        6.32745819e-03,  7.81384856e-03, -2.58141593e-03, -4.64370569e-05,\n",
      "       -4.45348118e-03, -2.89814081e-03, -6.95033511e-03,  5.47543075e-03,\n",
      "       -1.10991136e-03,  4.47794773e-05,  3.54402396e-03, -3.41951917e-03,\n",
      "        6.39039883e-03,  1.06587978e-02,  3.95652978e-03, -2.71022087e-03,\n",
      "       -3.55739117e-04,  1.09854080e-02, -4.27440600e-03,  1.03349844e-02,\n",
      "        6.05453330e-04, -2.67290394e-04, -2.97176768e-03, -7.00318580e-03,\n",
      "       -1.41791096e-02,  1.52230065e-03,  5.77234384e-03, -3.09585594e-04,\n",
      "        5.55643765e-03, -7.36338916e-05,  1.42876171e-02, -9.73012090e-01,\n",
      "       -6.35465980e-03,  4.66938782e-03, -1.04288973e-01,  6.64155977e-03,\n",
      "       -9.80186509e-04,  1.64456677e-03, -9.97940078e-03,  4.12118994e-03,\n",
      "       -7.68454280e-04,  1.46632816e-03,  5.94710512e-03,  5.45822643e-03,\n",
      "        1.17366426e-02, -1.11940235e-03,  4.16538771e-03, -6.16115751e-03,\n",
      "        4.22615698e-03,  3.42854159e-03, -2.31444923e-04,  1.48326776e-03,\n",
      "       -3.72948102e-03, -2.58548674e-03, -4.03698673e-03,  3.19182314e-03,\n",
      "        2.01651244e-03,  1.66396785e-03,  1.13702621e-02,  1.89176608e-05,\n",
      "        1.61717553e-02, -9.71102435e-03,  5.88230137e-03, -5.91983320e-03,\n",
      "        5.90097578e-03, -4.76414571e-03, -1.02522913e-02, -3.10965697e-03,\n",
      "       -5.72827761e-04,  1.05587103e-04, -4.10979381e-03, -2.86443013e-04,\n",
      "        6.88182795e-03, -4.63292655e-03, -2.75704684e-03,  4.29702085e-03,\n",
      "        1.42143725e-03,  5.82718244e-03, -3.01664881e-03, -7.39840837e-03,\n",
      "        2.46112864e-03,  5.26284566e-03,  2.59875134e-03,  6.87245233e-03,\n",
      "       -8.18681531e-03,  4.46947990e-03, -2.86305998e-03,  1.08606620e-02,\n",
      "        1.48414390e-03,  2.84745242e-03,  5.28799370e-04,  3.82102211e-04,\n",
      "        9.65391938e-03,  1.02677885e-02,  5.48654178e-04,  5.97493397e-03,\n",
      "       -6.32979302e-03, -2.37997621e-03,  8.26504268e-03,  1.88639737e-03,\n",
      "       -1.34329554e-02,  2.29509344e-04,  5.07951202e-03, -6.64676493e-03,\n",
      "       -3.34251928e-03, -5.32284891e-03,  2.15095561e-03,  2.54470925e-03,\n",
      "       -3.06742056e-03, -1.17695471e-02, -8.40669777e-03,  7.90906046e-03,\n",
      "        5.49784256e-03,  5.87775558e-03,  4.68715420e-03,  8.46250728e-03,\n",
      "       -4.73445607e-03,  6.69787405e-03,  1.70795864e-03, -4.65158140e-03,\n",
      "        3.27537511e-03, -1.35679822e-03, -7.10779009e-03, -4.35519218e-03,\n",
      "        3.66181810e-03,  6.12500869e-03, -9.53942712e-04,  3.73743265e-03,\n",
      "        6.01333391e-04,  5.12773462e-04, -1.30661589e-03, -5.80107467e-03,\n",
      "       -9.14382190e-03,  2.35088068e-04, -6.77763857e-03,  5.71481325e-03,\n",
      "        1.14775999e-02, -2.64833542e-03,  5.34031773e-03,  9.83965932e-04,\n",
      "        4.11184598e-03, -5.01794135e-03,  1.21973617e-05,  5.36340708e-03,\n",
      "        9.16551799e-03, -4.54154518e-03,  4.95270686e-03, -8.24009476e-04,\n",
      "        1.44560367e-03,  1.88644265e-03,  5.22221718e-03, -2.98011955e-03,\n",
      "        9.62754060e-03,  6.36662263e-03, -1.12322404e-03,  4.73988103e-03,\n",
      "       -8.16899119e-04,  2.68965639e-04, -5.41223795e-04, -2.53485306e-03,\n",
      "       -8.51627556e-04, -2.34349491e-03, -8.15498084e-03,  1.94416754e-03,\n",
      "        1.20926554e-04, -7.13156862e-03,  2.89902952e-03, -6.42351324e-06,\n",
      "        7.13674678e-03,  2.35988363e-03, -2.11465359e-03, -3.98891047e-03,\n",
      "        7.13331392e-03, -4.06334735e-03, -1.26171741e-03, -2.71191145e-03,\n",
      "        1.41813522e-02,  1.74290175e-03,  1.12599814e-02, -1.48043758e-03,\n",
      "        1.77697267e-03, -3.67041724e-03,  3.08223185e-03, -8.00363196e-04,\n",
      "       -3.14337783e-03,  2.32771365e-03,  4.15982911e-03,  4.43961704e-03,\n",
      "        8.55104881e-04, -6.36154145e-04, -5.18737873e-03, -9.02667642e-03,\n",
      "       -4.04904597e-03,  7.56414514e-03, -3.54654831e-03,  6.85824873e-03,\n",
      "       -7.41590327e-03,  6.94326777e-03, -2.52390583e-03, -1.39131618e-03,\n",
      "        2.96371104e-03,  5.09631261e-03,  2.53210147e-03,  1.63852854e-03,\n",
      "       -5.27280336e-03, -8.96846293e-04, -8.13688093e-04, -4.34401631e-03,\n",
      "        7.57820439e-03,  1.44295981e-02, -6.21687062e-03,  8.43736809e-03,\n",
      "        1.79012329e-03,  5.70563274e-03, -1.13940090e-02,  2.03823764e-03,\n",
      "       -3.25542269e-03,  4.43373248e-03,  3.14925169e-03,  4.26472258e-03,\n",
      "        1.18953444e-03,  6.24216301e-03,  1.01594031e-02,  3.58363753e-03,\n",
      "       -2.32646661e-03, -1.02030381e-03, -3.21830797e-04, -7.41882855e-03,\n",
      "        6.42496534e-03,  3.82689154e-03, -1.93469087e-03,  3.52340913e-03,\n",
      "        1.97721343e-03, -2.41041905e-03,  5.09751635e-03,  1.95070344e-04,\n",
      "        1.29733933e-03,  3.38101201e-03,  2.69871531e-03,  3.51352803e-03,\n",
      "        8.13935045e-03, -2.85672909e-03,  2.72128847e-03,  6.42080093e-03,\n",
      "       -6.58388203e-03,  6.88146101e-03, -1.18882302e-02, -4.88537969e-03,\n",
      "        1.12989387e-02, -5.87480515e-03, -2.76410836e-03,  1.01328604e-02,\n",
      "       -6.78637950e-03,  1.73867005e-03, -1.09774182e-02, -3.78487493e-05,\n",
      "       -1.65112899e-03, -4.94953245e-04,  3.43594031e-04,  6.25575706e-03,\n",
      "        5.68186864e-03,  6.39808830e-04, -1.27089275e-02, -1.01043759e-02,\n",
      "       -2.32071965e-04, -2.12684879e-03, -3.42969270e-03, -4.20472771e-03,\n",
      "        1.49126293e-03, -4.56049660e-04,  2.10942584e-03,  3.19975312e-03,\n",
      "       -1.16231479e-03, -1.58741989e-03, -2.00635032e-03,  5.20778820e-03,\n",
      "        6.32486632e-03,  9.20199556e-04,  9.42581100e-04, -1.40843913e-03,\n",
      "        1.27223060e-02,  6.95511233e-03,  8.68954882e-03, -7.83750601e-03,\n",
      "        1.21457325e-02, -1.26441452e-03,  3.68468667e-04,  6.03934051e-03,\n",
      "       -1.64024869e-03, -1.46870210e-03,  4.48483042e-03,  4.78874799e-03,\n",
      "        5.53022139e-03, -2.68126791e-03, -2.82637193e-04, -3.95794865e-03,\n",
      "        3.05137015e-03, -3.48274451e-04, -2.12806903e-04,  7.04013836e-03,\n",
      "       -4.38411208e-03, -7.31344975e-04,  4.81564272e-03, -1.61950639e-03,\n",
      "       -3.96974990e-03,  2.60053133e-03,  4.45351517e-03,  4.28831298e-03,\n",
      "       -3.76406964e-03,  1.35005102e-03, -8.93199537e-03,  2.38821609e-03,\n",
      "        3.99026973e-03, -6.76844968e-03,  8.13998003e-03, -4.92343353e-03,\n",
      "        8.88538361e-03,  5.29013574e-03,  1.82935758e-03,  1.63915439e-03,\n",
      "        1.68284809e-03, -1.76645641e-03,  9.72130243e-03,  1.03024486e-02,\n",
      "       -2.01643351e-03,  6.66213362e-03,  2.03331141e-03,  5.43930428e-03,\n",
      "        3.74352955e-03, -3.16001265e-03, -7.57685280e-04, -5.46093739e-04,\n",
      "        2.18069763e-03,  2.45325267e-04,  9.60690377e-05,  2.83115916e-03,\n",
      "        8.78896285e-03,  2.71889823e-03,  5.00669470e-03,  4.30708844e-03,\n",
      "        2.23343493e-03,  3.09536164e-03, -2.15907535e-03,  1.22612277e-02,\n",
      "        2.75678671e-04,  5.22886636e-03,  2.20246729e-03,  2.42786156e-03,\n",
      "        1.42840517e-03,  9.30779323e-04, -2.37544626e-03,  1.68271211e-03,\n",
      "        1.24268443e-03, -6.95305970e-03,  5.51195070e-03,  6.12377841e-03,\n",
      "       -4.08428907e-03, -7.07161101e-03,  1.22106047e-02,  3.93037125e-03,\n",
      "        5.43794711e-04, -8.59980658e-03, -3.31309484e-03,  1.87559482e-02,\n",
      "       -1.24586513e-03, -3.12705152e-03, -2.72939331e-03, -1.98190729e-03,\n",
      "        4.82508354e-03,  2.03570793e-03,  2.56649544e-03,  8.52410868e-03,\n",
      "        4.33083856e-03, -3.08507564e-03, -4.74670064e-03, -7.85939395e-04,\n",
      "        5.45993540e-03,  5.62013080e-03, -1.32993357e-02,  5.04698278e-03,\n",
      "        9.35052522e-03, -5.87046007e-03,  6.68423809e-03,  3.55534209e-03,\n",
      "       -6.65709889e-03,  2.99640209e-03,  3.93001847e-02,  2.05510692e-03,\n",
      "       -2.21002894e-03, -3.80327622e-03, -1.43467309e-03,  3.21450364e-03,\n",
      "       -2.38565379e-03,  1.73649564e-03, -3.93033680e-03, -4.74144705e-03,\n",
      "       -6.13857806e-03, -3.99014493e-03, -6.86199637e-03, -4.74015530e-03,\n",
      "        5.39779384e-03,  5.27546322e-03,  6.02656230e-03,  1.20726007e-03,\n",
      "       -1.26427005e-03,  4.23045782e-03,  8.44440248e-04, -6.64575677e-03,\n",
      "       -6.39733905e-03,  7.39628961e-03,  1.03384757e-03,  1.94186534e-04,\n",
      "        1.44539680e-03, -6.74596615e-03,  2.90018949e-03,  2.57889228e-03,\n",
      "        9.45703185e-04,  1.08612040e-02, -6.23146491e-03,  1.45301607e-03,\n",
      "        9.20780655e-03, -6.30060257e-03,  4.00917046e-03,  5.69988042e-03,\n",
      "        8.11638311e-03,  8.77106853e-04, -4.31167544e-04, -1.38823688e-03,\n",
      "       -1.29886798e-03, -6.92335423e-03, -3.29123368e-03, -1.37251606e-02,\n",
      "       -9.54782357e-04, -4.97981091e-04, -1.07354613e-03, -1.98882027e-03,\n",
      "       -8.36037914e-04, -1.02259982e-02,  2.01450937e-04,  3.86207853e-03,\n",
      "        7.61688594e-03,  1.13919359e-02, -5.58498316e-03, -8.86279158e-03,\n",
      "        4.07300796e-03,  1.57091971e-02,  5.94032276e-03,  5.85049484e-03,\n",
      "       -5.05049061e-03,  3.35801649e-03,  5.33579895e-03, -2.18235725e-03,\n",
      "        3.32798925e-03,  7.26815220e-03,  5.06066158e-03,  2.60174484e-03,\n",
      "        1.63153454e-03,  1.21095893e-03, -6.91542821e-03,  7.68616237e-03,\n",
      "       -1.17951175e-02, -5.88175934e-03, -3.56507557e-03, -5.51539008e-03,\n",
      "        5.07694276e-05, -1.97216403e-03, -2.32274504e-03,  6.74704424e-05,\n",
      "       -8.19733366e-03,  2.42148107e-03,  2.26475438e-03, -2.95279315e-03,\n",
      "        4.61512897e-03,  6.58058375e-03,  1.74163468e-03, -2.15835893e-03,\n",
      "       -2.05065776e-03, -4.70199762e-03, -4.81387426e-04,  2.22446077e-04,\n",
      "        5.88297518e-03, -3.40006594e-03, -3.52186617e-04, -5.54304430e-03,\n",
      "       -3.65611399e-03, -3.24053364e-03, -3.94921168e-04,  1.68820843e-03,\n",
      "       -8.02617869e-05,  3.09070293e-03, -2.41833739e-03,  3.33018648e-03,\n",
      "       -3.43106192e-04,  7.48174544e-03,  7.23209174e-04,  9.84143931e-04,\n",
      "        2.96920328e-03, -1.18216209e-03, -5.26784873e-03,  6.52165851e-03,\n",
      "       -7.54556106e-03,  1.33096753e-02,  7.13718124e-03,  2.07292294e-04,\n",
      "        4.32178564e-03,  1.77617301e-03,  1.50961066e-02, -4.12536028e-04,\n",
      "       -7.17763742e-03, -8.34056409e-04, -3.59829306e-03,  3.40664457e-03,\n",
      "       -1.69354863e-03,  1.60244759e-03,  2.53964623e-04, -1.33397877e-02,\n",
      "       -1.01748686e-02,  7.23734323e-04, -2.31542843e-04,  2.87593063e-03,\n",
      "       -4.55821399e-03, -2.58130208e-03, -3.89391650e-03, -8.66842456e-04,\n",
      "        7.71920662e-03, -5.14093367e-03,  1.03488341e-02,  5.26245823e-03,\n",
      "       -3.44143901e-03, -7.87462341e-04, -7.64425495e-04,  7.30774878e-03,\n",
      "       -6.31152478e-04, -6.25959644e-03, -8.49097874e-03, -1.67680241e-03,\n",
      "        3.49036145e-06, -9.26655997e-03, -4.73656412e-03,  7.05449842e-03,\n",
      "        2.15211720e-03, -5.38613787e-03, -6.70446642e-03,  4.90938872e-03,\n",
      "       -4.07905813e-04,  4.90460545e-03,  6.49423944e-03, -4.68581636e-03],\n",
      "      dtype=float32), 'A2016_European_Commission_v_World_Duty_Free:1': array([-2.64724367e-03,  2.75067054e-03, -1.93223320e-02, -3.23987240e-03,\n",
      "       -2.70716716e-02, -2.11530104e-02, -1.88072845e-02, -5.81970438e-03,\n",
      "       -1.16867013e-02,  4.64318926e-03, -1.50208073e-02,  9.14469548e-03,\n",
      "       -2.45661642e-02,  9.13143530e-03, -1.82186742e-03,  6.27958355e-03,\n",
      "       -5.65966731e-03,  8.45381990e-03,  5.61477616e-03, -2.58799153e-03,\n",
      "        7.27767358e-04, -1.31867416e-02,  1.70588605e-02, -1.06030311e-02,\n",
      "       -1.91317629e-02,  6.11887546e-03, -2.14826223e-02,  1.80352535e-02,\n",
      "        2.12103985e-02,  2.30748366e-04, -5.21944696e-03, -1.99479107e-02,\n",
      "       -1.09178014e-02, -9.95473471e-04,  7.93518871e-03, -1.75591409e-02,\n",
      "       -1.53684346e-02, -8.63982830e-04,  4.03725397e-04, -2.31412780e-02,\n",
      "        3.47332493e-03, -3.93062772e-04, -3.00474465e-03,  3.11673648e-04,\n",
      "       -4.36776038e-03, -7.00142607e-03,  3.07192113e-02,  5.03892964e-03,\n",
      "       -9.48243309e-03,  5.31512611e-02,  2.21446790e-02, -5.65240579e-03,\n",
      "        1.48122841e-02, -1.97782065e-03, -1.01450123e-02, -1.69581920e-02,\n",
      "        2.08495259e-02, -1.72922984e-02, -2.77798381e-02, -1.25915213e-02,\n",
      "       -2.03185063e-02, -5.41469408e-03,  5.24532935e-03,  1.31897698e-03,\n",
      "       -7.78503297e-03,  1.46244019e-02, -2.42224447e-02, -2.76407022e-02,\n",
      "       -8.04149546e-03,  1.15347253e-02,  4.47087036e-03,  2.59795338e-02,\n",
      "       -2.36178655e-02, -4.61409014e-04,  4.10640566e-03,  3.05991620e-02,\n",
      "        7.33803166e-03,  5.79604693e-03,  7.30668753e-03,  1.82140730e-02,\n",
      "       -1.14538996e-02,  2.83858832e-02,  4.36775647e-02,  3.57958153e-02,\n",
      "       -2.79228482e-03,  5.21108974e-03,  8.23171530e-03,  3.93775012e-03,\n",
      "       -1.91814881e-02, -2.01251693e-02, -2.84509471e-04, -9.94826574e-03,\n",
      "        3.40369120e-02, -1.86579283e-02,  1.15034161e-02, -5.81965363e-03,\n",
      "        5.36365733e-02,  8.74391757e-03,  1.15347235e-02, -1.10583520e-03,\n",
      "        5.76189021e-03,  8.18249490e-03,  7.98255205e-03,  1.17582278e-02,\n",
      "        1.55724240e-02, -3.82722472e-03, -2.51896698e-02,  1.93342436e-02,\n",
      "       -1.50235118e-02, -1.44680738e-02, -2.75998190e-03, -8.71552806e-03,\n",
      "       -5.71811572e-03,  1.73683669e-02, -1.68519076e-02,  2.73756161e-02,\n",
      "       -1.35321608e-02,  1.55180190e-02,  1.40651851e-03,  2.11234641e-04,\n",
      "       -1.07201375e-03, -1.72343440e-02, -1.36658931e-02,  3.42036411e-02,\n",
      "        6.46208413e-03,  3.17415297e-02, -1.21512730e-03,  2.05047093e-02,\n",
      "        8.18927586e-03,  7.33075710e-03, -4.34312690e-03,  1.12831295e-02,\n",
      "       -2.88216933e-03, -3.57671571e-03, -1.35862269e-02,  2.85874540e-03,\n",
      "        3.60942190e-03, -1.64502091e-03,  5.06225415e-03,  1.24640726e-02,\n",
      "        1.60407331e-02, -1.86384656e-02, -2.78686564e-02,  2.36511566e-02,\n",
      "       -1.42685678e-02,  2.77461298e-02,  2.28797402e-02,  1.54952426e-03,\n",
      "        1.81561597e-02,  7.19722547e-03,  2.31306683e-02,  7.45109236e-03,\n",
      "        5.66341355e-03,  3.12004681e-03,  2.94984244e-02, -6.82318490e-03,\n",
      "       -2.09318735e-02, -1.99146885e-02, -5.59218694e-03, -1.94012355e-02,\n",
      "       -7.44113931e-03,  4.50259969e-02,  3.96584859e-03, -1.15834968e-02,\n",
      "       -1.11521911e-02, -1.81590614e-03,  3.38253239e-03, -9.81405750e-03,\n",
      "       -1.22567629e-02, -1.23719301e-03, -1.77869052e-02, -7.84521340e-04,\n",
      "       -9.87144001e-03,  5.63327735e-03,  1.66832302e-02,  1.52015267e-02,\n",
      "        2.29603574e-02,  8.34117830e-03,  2.32393742e-02, -9.24419984e-03,\n",
      "        1.77897862e-03,  2.23273449e-02, -2.18545180e-02, -1.75918173e-02,\n",
      "        4.84796166e-02, -9.51029733e-03, -6.66803773e-03,  3.88331292e-03,\n",
      "        1.47846341e-02,  1.18447626e-02,  3.90665198e-04,  1.02181938e-02,\n",
      "        8.86584725e-03,  3.14839371e-03,  5.41434344e-03,  4.86569945e-03,\n",
      "       -5.26993303e-03,  9.48607363e-03, -5.69104962e-03,  9.42181796e-04,\n",
      "       -1.17544420e-02, -2.99091171e-02, -3.54409474e-03,  1.20127760e-02,\n",
      "       -9.42075346e-03,  3.44712846e-03, -1.33154285e-03,  7.52625288e-03,\n",
      "       -1.59519799e-02, -3.15034799e-02,  2.99875555e-03,  2.65064323e-03,\n",
      "       -2.69741402e-04, -3.17674838e-02,  6.54032361e-03,  3.57563272e-02,\n",
      "       -4.07200633e-03,  4.03645867e-03,  1.34532601e-02,  9.19550471e-03,\n",
      "        2.26847399e-02,  4.92461659e-02, -3.81728448e-02, -8.39981344e-03,\n",
      "       -8.53058603e-03,  8.74697510e-03, -2.98816860e-02, -9.13271215e-03,\n",
      "       -1.10729979e-02, -2.02392004e-02,  3.60799907e-03,  3.16850562e-03,\n",
      "        7.92807899e-03,  2.22563967e-02,  2.37829573e-02, -1.73857831e-03,\n",
      "       -1.38667896e-02,  1.20655866e-02, -2.76073739e-02,  9.63800866e-03,\n",
      "        3.97198275e-03, -1.93853732e-02,  2.26147193e-02, -6.77685859e-03,\n",
      "        4.55285609e-03, -4.00573108e-03,  7.76422024e-03, -1.56071968e-02,\n",
      "        7.02851498e-03,  3.32249515e-02,  2.63983514e-02, -8.48230362e-01,\n",
      "       -1.02305077e-02,  8.16273969e-03, -2.55974621e-01,  2.93361209e-02,\n",
      "       -3.30733210e-02, -1.37448916e-02, -5.96830714e-03,  4.08302946e-03,\n",
      "        9.04248562e-04,  1.84975248e-02,  1.74124762e-02, -5.83857007e-04,\n",
      "        3.39874662e-02, -1.16650462e-02,  1.81839298e-02, -1.43166985e-02,\n",
      "        1.22660873e-02,  2.08879858e-02, -1.84422340e-02, -1.19441317e-03,\n",
      "       -2.64279135e-02,  3.37052494e-02, -2.51128338e-02,  1.00756604e-02,\n",
      "        1.41852694e-02,  3.37422825e-03,  4.47171852e-02, -1.44123351e-02,\n",
      "        1.99591275e-02, -4.14302200e-02, -2.13643070e-03,  3.23073915e-03,\n",
      "        2.52067298e-02,  3.81320878e-03, -2.60588266e-02,  1.27946613e-02,\n",
      "        4.10337094e-03, -2.79627566e-04,  3.40467994e-03,  3.15756118e-03,\n",
      "        7.35305308e-04, -2.41371226e-02, -1.52969118e-02, -2.75276555e-03,\n",
      "        1.81700138e-03,  2.68457700e-02, -3.34095675e-03, -2.10509989e-02,\n",
      "        2.52092630e-03, -3.76869179e-03,  3.20156454e-03,  3.45643163e-02,\n",
      "        3.21077672e-03,  2.08988618e-02,  2.22729668e-02,  6.68626884e-03,\n",
      "        2.27595400e-03, -2.09955685e-03,  1.68622397e-02,  1.48909716e-02,\n",
      "        2.70618852e-02,  3.11488640e-02, -1.36735933e-02,  2.70030182e-02,\n",
      "       -3.87677364e-02, -1.38424886e-02,  8.10244679e-03, -6.97185053e-03,\n",
      "       -1.45213036e-02, -1.24655466e-03,  3.78328189e-02, -1.01069873e-02,\n",
      "       -1.74439244e-03,  3.07411159e-04, -1.93783129e-03, -9.13890451e-03,\n",
      "        1.19333975e-02, -2.46149320e-02, -1.80845875e-02,  7.73654459e-03,\n",
      "        8.66075046e-03,  1.25469677e-02,  8.87664407e-03,  8.52078199e-03,\n",
      "       -8.40284023e-03,  1.66397803e-02,  1.75362695e-02, -2.10557748e-02,\n",
      "        3.83068854e-03, -1.86425392e-02, -2.90147737e-02, -7.64062302e-03,\n",
      "        1.41960578e-02,  3.08645684e-02,  1.52876775e-03,  2.59959307e-02,\n",
      "       -1.47007015e-02,  4.47106222e-03,  7.01067038e-03, -1.87343527e-02,\n",
      "        8.09004996e-03, -2.24654286e-04, -3.70588042e-02, -4.42827959e-03,\n",
      "        1.65954437e-02,  7.76309753e-03,  1.68835726e-02, -2.43929457e-02,\n",
      "        2.44987048e-02, -2.97721196e-03, -1.06908130e-02,  2.43771970e-02,\n",
      "        2.08841488e-02, -1.44266048e-02,  1.99165121e-02,  6.95275189e-03,\n",
      "       -8.63867626e-03, -1.65585782e-02, -1.63865089e-02,  1.24459919e-02,\n",
      "        7.02793058e-03,  1.26382764e-02,  1.73940640e-02, -1.06131635e-03,\n",
      "       -2.16463488e-02,  2.11487772e-04, -5.48039388e-04,  2.48310925e-03,\n",
      "        4.83987574e-03, -1.71946157e-02, -5.77612082e-04,  1.33785531e-02,\n",
      "       -2.54278351e-02, -3.05380709e-02,  1.51930153e-02, -2.59251974e-04,\n",
      "        1.74300615e-02,  1.82072688e-02,  1.39004625e-02,  7.37259258e-03,\n",
      "        2.75943261e-02, -1.76081993e-02, -2.73926202e-02,  2.40784698e-06,\n",
      "        2.61758529e-02,  8.37825064e-04,  1.81221068e-02, -2.93264515e-03,\n",
      "        1.03490949e-02, -1.31041631e-02,  2.01120488e-02,  1.42705096e-02,\n",
      "        1.06831621e-02,  1.52911001e-03,  1.44446818e-02,  2.28811111e-02,\n",
      "       -2.91401462e-04,  2.07369961e-02, -2.35832809e-03, -2.21658796e-02,\n",
      "       -6.95599616e-03, -1.93877320e-03,  1.74005330e-02,  2.57901996e-02,\n",
      "       -7.33734388e-03,  1.38783001e-03,  7.15437345e-03,  8.89145397e-03,\n",
      "        1.21298507e-02, -1.24454508e-02,  3.02885920e-02, -6.08880818e-03,\n",
      "       -4.50593745e-03,  1.02338139e-02,  6.35867892e-03, -2.89383177e-02,\n",
      "       -7.03940587e-03,  4.49584313e-02, -1.89494435e-02, -1.24185048e-02,\n",
      "        2.38753036e-02,  1.18393209e-02, -3.55358757e-02,  9.49568953e-03,\n",
      "        2.85595423e-03,  1.83662474e-02,  1.01457592e-02,  3.37596647e-02,\n",
      "       -9.48718656e-03,  1.31505458e-02,  3.45863961e-02,  3.55735607e-02,\n",
      "       -8.77443980e-03, -1.43943774e-02, -1.55423209e-02, -2.07960904e-02,\n",
      "        1.81102753e-02,  2.55787987e-02,  5.40346187e-03,  2.18095654e-03,\n",
      "        1.15754306e-02,  5.53203048e-04,  1.66638345e-02, -1.74564663e-02,\n",
      "        2.18746737e-02, -9.40501969e-03, -9.87909175e-03,  4.19280631e-03,\n",
      "       -5.18879713e-03, -9.66163538e-03,  3.26849776e-03,  9.91700869e-03,\n",
      "       -3.20814289e-02,  5.36299497e-03, -3.97764891e-02,  1.75315216e-02,\n",
      "        4.74781170e-03, -2.09598877e-02, -1.82496675e-03,  4.86174636e-02,\n",
      "       -2.04769187e-02,  4.97688306e-03, -2.80014556e-02, -6.29535737e-03,\n",
      "       -1.49105070e-02, -2.02609356e-02,  8.29610787e-03,  7.85040483e-03,\n",
      "       -1.57525681e-03,  8.93591810e-03, -1.99473668e-02, -7.49063771e-03,\n",
      "       -1.59898475e-02,  2.32536513e-02,  8.29809404e-04, -1.12854317e-02,\n",
      "       -1.74006708e-02,  1.25111267e-02,  1.98784992e-02,  2.64852773e-03,\n",
      "       -3.57730389e-02,  1.14495289e-02,  5.22498880e-03,  1.53244138e-02,\n",
      "       -8.78720451e-03, -1.25445100e-02, -2.04381496e-02, -1.23445140e-02,\n",
      "        1.28696756e-02,  2.45903526e-02,  1.68528054e-02, -1.75269172e-02,\n",
      "        4.11245264e-02, -1.27984723e-02,  4.46042605e-03,  1.59410890e-02,\n",
      "        5.97821781e-03, -2.30716541e-03,  5.06786909e-03,  1.52162919e-02,\n",
      "        1.48466127e-02, -2.61739292e-03, -3.06522697e-02,  1.81154031e-02,\n",
      "       -2.48776050e-03,  5.20420633e-03,  4.55128681e-03,  1.78264100e-02,\n",
      "       -9.20453947e-03, -1.39313396e-02,  2.04317644e-02, -6.75509218e-03,\n",
      "       -1.20403189e-02,  2.38673072e-02, -6.31927699e-03, -5.05733676e-03,\n",
      "       -3.55018582e-03,  1.70604698e-02, -2.70184060e-03,  7.51315244e-03,\n",
      "        1.83276143e-02, -2.09934395e-02,  2.57335622e-02, -3.36940028e-02,\n",
      "        7.13016465e-03,  9.66589712e-03,  3.22948094e-03,  7.35413795e-03,\n",
      "        1.48019325e-02, -6.19265344e-03,  3.09318863e-02,  2.09943019e-02,\n",
      "        2.57765111e-02, -3.01964465e-03,  5.36464108e-03,  3.78094823e-03,\n",
      "       -2.49358155e-02, -7.87736732e-04, -1.11363279e-02,  2.61661950e-02,\n",
      "        1.94619279e-02,  2.01342022e-03,  1.21848527e-02, -8.71818885e-03,\n",
      "        1.39168007e-02,  5.52012539e-03,  2.08698157e-02,  1.96539871e-02,\n",
      "       -8.19844846e-03,  2.33187769e-02, -1.76811181e-02,  2.61449423e-02,\n",
      "        3.09144929e-02, -1.00345665e-03, -3.56754870e-03,  2.06751972e-02,\n",
      "        1.32556129e-02, -1.47024151e-02,  8.26264825e-03, -2.94470578e-03,\n",
      "        7.79102277e-03, -2.09681671e-02,  6.56070979e-03,  7.48168956e-03,\n",
      "       -2.31643766e-02, -4.49062139e-02,  3.32436413e-02,  9.27660614e-03,\n",
      "        5.37546910e-03, -1.19980341e-02, -3.01859761e-03,  2.02696379e-02,\n",
      "       -6.23446936e-03,  2.34131515e-03, -5.57869021e-03, -3.23398644e-03,\n",
      "        2.37075649e-02,  3.56010273e-02, -3.68070835e-03,  3.96540910e-02,\n",
      "        5.09872846e-03,  1.79762747e-02,  2.77730316e-04,  1.42110244e-03,\n",
      "        3.03683169e-02,  1.71178039e-02,  7.46429013e-03,  2.12957244e-02,\n",
      "        3.45652066e-02, -1.73580479e-02, -9.78995021e-03,  7.23158149e-03,\n",
      "       -1.83809940e-02, -3.20103727e-02, -4.68933024e-03,  9.13395826e-03,\n",
      "        3.65546695e-03,  1.23945228e-03, -1.65078770e-02,  9.87287238e-03,\n",
      "       -1.41144972e-02, -6.26106607e-03, -1.11128122e-03,  3.28896334e-03,\n",
      "       -1.79258105e-03, -1.61325261e-02, -1.56791043e-02, -1.26762362e-02,\n",
      "        1.27306534e-02,  9.63753555e-03,  1.60742495e-02, -2.31401320e-03,\n",
      "       -5.11310808e-03,  1.67334825e-02,  1.94166955e-02, -3.33732949e-03,\n",
      "       -8.39641970e-03,  1.37042943e-02, -1.78837683e-02, -3.11520742e-03,\n",
      "        1.26767317e-02, -1.24896737e-03, -2.23887200e-03,  7.38312257e-03,\n",
      "       -2.13713408e-03,  1.26022054e-02, -7.46361353e-03,  1.10838539e-03,\n",
      "        1.75772477e-02,  3.88541538e-03,  2.53962353e-03, -1.09828608e-02,\n",
      "        1.32516688e-02,  1.20880399e-02,  7.69250421e-03, -7.63855455e-03,\n",
      "       -1.66406352e-02, -2.77911145e-02, -9.20905452e-03, -8.56920052e-03,\n",
      "        2.17219088e-02, -6.70495583e-03,  5.50719583e-03, -4.51236311e-03,\n",
      "       -1.25305867e-02, -4.14037425e-03,  4.31946851e-03,  2.02331711e-02,\n",
      "        4.01804931e-02,  3.37083377e-02,  8.50974489e-03, -5.34510612e-03,\n",
      "       -1.27393962e-03,  2.05517020e-02,  6.60405774e-03,  8.25627428e-03,\n",
      "       -1.02452673e-02, -3.12711927e-03,  3.40831205e-02, -4.85301571e-04,\n",
      "       -1.30277791e-03, -1.31903123e-02, -2.05401750e-03,  1.29672722e-03,\n",
      "       -2.61238194e-03, -1.78233907e-02, -2.89614499e-02,  1.29329478e-02,\n",
      "       -2.58700233e-02, -4.64910083e-03, -6.35560835e-03, -3.67834382e-02,\n",
      "        1.37581341e-02,  4.23438707e-03, -9.65721812e-03,  5.51931327e-03,\n",
      "       -3.52608319e-03, -2.51778830e-02,  1.95795000e-02, -1.07023362e-02,\n",
      "        2.05785204e-02,  1.99939609e-02,  1.82659104e-02,  7.18902005e-03,\n",
      "        5.40885740e-05,  6.25535520e-03, -6.89062569e-03, -7.40727456e-03,\n",
      "       -5.34430938e-03, -4.44739731e-03,  2.59194169e-02, -2.75091059e-03,\n",
      "        1.40272034e-02, -2.12502070e-02,  2.26402399e-03, -1.60067901e-02,\n",
      "       -4.72021941e-03,  1.20690623e-02, -4.30521974e-03, -1.59590151e-02,\n",
      "       -1.39846997e-02,  2.19254512e-02, -2.58355308e-02, -1.45121990e-02,\n",
      "       -4.98008635e-03, -2.02944390e-02, -4.06919653e-03,  1.99525934e-02,\n",
      "        4.26148716e-03, -1.79565605e-02,  1.59557834e-02, -1.82624422e-02,\n",
      "        7.99792167e-03,  2.35906262e-02,  4.82507795e-03, -9.82941594e-03,\n",
      "       -6.71305647e-03,  1.29608009e-02, -1.92833878e-02,  2.48211473e-02,\n",
      "        2.52812598e-02,  2.84491736e-03, -1.24646192e-02, -2.24488471e-02,\n",
      "       -1.91910807e-02,  3.08826705e-03, -3.00643616e-03,  6.82120537e-03,\n",
      "       -1.69366561e-02,  3.52918543e-03, -1.44493850e-02, -1.36025911e-02,\n",
      "        2.72510536e-02,  1.63925271e-02,  8.33548699e-03, -2.68606190e-02,\n",
      "       -1.90826282e-02,  4.48268047e-03,  7.02899462e-03,  8.36245716e-03,\n",
      "       -4.07393649e-02, -6.68489886e-03,  2.56540347e-03, -1.40788406e-02,\n",
      "       -1.47612961e-02, -1.17329573e-02, -1.92527846e-02,  3.42646688e-02,\n",
      "       -6.44097198e-03,  1.58337839e-02, -4.12815763e-03, -6.69591734e-03,\n",
      "        1.23076588e-02, -2.17882227e-02,  4.53375466e-02,  7.14102236e-04],\n",
      "      dtype=float32), 'A2016_European_Commission_v_World_Duty_Free:2': array([-1.47883361e-02, -3.00256209e-03,  1.78061966e-02,  1.71349030e-02,\n",
      "       -1.19857714e-02, -1.04680015e-02, -2.44433396e-02, -2.57005566e-03,\n",
      "        3.04404506e-03, -1.44760037e-04, -5.38102398e-03,  6.11569546e-03,\n",
      "       -1.65502969e-02,  9.71011934e-04, -1.00326119e-02,  2.54861638e-03,\n",
      "       -9.05987155e-03,  2.04304010e-02,  1.21750720e-02, -1.61789451e-02,\n",
      "        8.44838843e-03, -1.08374301e-02,  1.40896887e-02,  2.85354769e-03,\n",
      "        4.64413082e-03, -4.39169176e-04, -1.15970531e-02,  9.74257756e-03,\n",
      "       -4.47868789e-03, -1.27248382e-02,  2.62308773e-03, -8.03512870e-04,\n",
      "        4.03475342e-03, -9.55353316e-04,  1.55957015e-02,  2.16921009e-02,\n",
      "        4.23915824e-03,  1.34503022e-02,  2.47158995e-03, -1.68996733e-02,\n",
      "        5.47283096e-03, -7.98964594e-03, -1.86286457e-02,  1.98131730e-03,\n",
      "        8.19481816e-03, -1.27449697e-02,  2.40069292e-02,  2.02304684e-02,\n",
      "       -1.66377518e-02,  2.58374456e-02,  1.16284406e-02, -1.37725743e-02,\n",
      "        1.60008352e-02, -3.78747541e-03,  2.34083273e-03, -3.09678540e-03,\n",
      "        1.25221824e-02, -2.21908018e-02, -2.69334614e-02,  3.05095199e-03,\n",
      "       -1.21013178e-02, -4.29513771e-03,  1.64585449e-02,  4.42297850e-03,\n",
      "       -1.75755229e-02, -6.63833460e-03, -7.37630995e-03,  1.58227105e-02,\n",
      "        6.94929995e-03,  1.20882792e-02, -9.22904443e-03,  7.86374975e-03,\n",
      "       -2.28603408e-02, -1.41792288e-02, -4.96026711e-04,  1.53439762e-02,\n",
      "        5.31515852e-03,  4.67995135e-03,  2.43882556e-03, -3.56223551e-03,\n",
      "       -2.03252286e-02,  2.91160922e-02,  2.18951087e-02,  6.46790490e-03,\n",
      "        1.83885358e-02, -8.00490659e-03,  6.75830664e-03,  6.36794185e-03,\n",
      "       -1.28590744e-02,  4.85385442e-03,  1.03313364e-02,  8.20212663e-05,\n",
      "        7.23882904e-03, -8.85474402e-03,  4.74001188e-03, -6.01927843e-03,\n",
      "        1.45576317e-02,  1.23895286e-02,  1.65807065e-02,  1.39551843e-03,\n",
      "        1.12911146e-02, -1.07696112e-02, -2.39544548e-04,  1.27787655e-02,\n",
      "       -8.04549269e-03,  7.75386440e-03, -2.97591724e-02,  3.14974673e-02,\n",
      "       -7.91833270e-03, -4.63502342e-03,  2.00148299e-03, -7.67606683e-03,\n",
      "       -5.51771466e-03,  7.07978243e-03,  5.59806172e-03,  2.18125172e-02,\n",
      "        1.63831878e-02, -1.65040568e-02,  3.72706214e-03,  5.67705778e-04,\n",
      "       -2.17941147e-03, -1.37629919e-02, -1.63733363e-02, -7.66955141e-04,\n",
      "        4.74923942e-03,  6.68373797e-03, -5.95132494e-03,  4.35233489e-03,\n",
      "        8.10924685e-05, -2.93816114e-03,  6.76388759e-03, -6.51493762e-03,\n",
      "        7.46875489e-03, -5.15967957e-04,  1.40249571e-02,  3.69673688e-03,\n",
      "        8.63246433e-03, -1.11240242e-03, -1.37410907e-03,  1.26987817e-02,\n",
      "       -2.48050806e-03,  4.73333197e-03, -2.96195317e-02,  7.25844083e-03,\n",
      "       -4.97814454e-03,  1.95277261e-03,  1.36367390e-02,  1.80267950e-03,\n",
      "       -4.36003495e-04, -1.70043623e-03,  4.04190691e-03,  1.62959695e-02,\n",
      "        1.34092038e-02,  1.68422759e-02,  1.99676566e-02,  3.07056098e-03,\n",
      "       -4.94318269e-03, -1.64146852e-02, -1.61944162e-02,  2.83688656e-03,\n",
      "        6.17702864e-03,  2.21581496e-02, -1.68631016e-03, -7.50660058e-03,\n",
      "        3.75067000e-03, -7.83395953e-03,  6.18153065e-03,  6.25837769e-04,\n",
      "       -1.65459793e-02, -1.45675791e-02,  3.69033450e-03, -9.74267256e-03,\n",
      "        4.03055688e-03,  2.59966892e-03,  6.37124060e-03,  6.24645595e-03,\n",
      "       -1.06800308e-05,  9.80223762e-04,  2.13243235e-02,  1.14353299e-02,\n",
      "        2.27611815e-03,  8.20836704e-03, -1.41462823e-02,  1.86716591e-03,\n",
      "        2.18364783e-02, -2.53420044e-02,  7.28644850e-03, -8.00800137e-03,\n",
      "        1.11092171e-02,  4.30293061e-04, -3.74513352e-03,  2.08382285e-03,\n",
      "        3.15527985e-04, -2.00465019e-03, -1.16699552e-02,  1.91685539e-02,\n",
      "        8.18532426e-04,  2.88664103e-02,  1.04385205e-02, -2.10479535e-02,\n",
      "       -7.37028429e-03, -3.15270945e-03, -6.48001907e-03,  1.67113431e-02,\n",
      "       -1.45476288e-03,  2.56362204e-02, -2.03205273e-02,  1.13163572e-02,\n",
      "       -7.31213903e-03, -6.64054416e-03, -4.43319278e-03,  1.40911937e-02,\n",
      "        7.96527136e-04, -5.72237466e-03, -1.66404191e-02,  1.92899667e-02,\n",
      "        6.93671405e-03,  7.40691042e-03, -3.81899439e-03,  4.19505453e-03,\n",
      "        4.85479413e-03,  7.88575690e-03, -1.59821454e-02, -3.93895479e-03,\n",
      "       -5.57343196e-03,  3.50016257e-04, -1.62803084e-02, -2.39265827e-03,\n",
      "        1.14216981e-03,  8.08206853e-03,  1.49924876e-02, -1.86552387e-02,\n",
      "        1.53547004e-02,  4.77504691e-05, -2.36804059e-04,  5.22681512e-03,\n",
      "       -2.12638057e-03, -6.46758545e-03, -1.78287327e-02,  1.04744406e-02,\n",
      "        8.08263139e-04, -8.43969546e-03,  4.04870557e-03, -1.45551795e-02,\n",
      "       -1.74980536e-02, -2.18552630e-02,  1.21253692e-02,  1.30471289e-02,\n",
      "       -1.75493991e-03,  1.67532396e-02,  2.62949821e-02, -9.40068603e-01,\n",
      "       -1.16945233e-03,  3.40094836e-03, -3.20879221e-02,  1.75007357e-04,\n",
      "       -1.74585264e-02, -2.30222731e-03,  1.64869684e-03, -1.20456964e-02,\n",
      "       -1.12778516e-02,  8.33864044e-03,  2.11369456e-03,  7.48571474e-03,\n",
      "        1.63243394e-02, -7.45776808e-03,  3.17353965e-03,  3.88424634e-03,\n",
      "       -2.30637323e-02,  4.39498760e-03, -1.71372537e-02, -1.71790048e-02,\n",
      "       -1.32331653e-02,  8.17315839e-03, -1.03057288e-02,  1.54305045e-02,\n",
      "       -6.06995309e-03, -7.06652820e-04,  9.00493283e-03,  3.60606471e-03,\n",
      "       -5.95141528e-03, -2.75528356e-02,  7.62687903e-03,  1.73749663e-02,\n",
      "        1.92984066e-03,  1.60272728e-04, -7.46867992e-03, -3.92538059e-04,\n",
      "        4.49219486e-03,  2.77154706e-03,  2.17723870e-03, -1.61358230e-02,\n",
      "        1.84240367e-03, -8.46062135e-03, -6.25400152e-03,  2.95716547e-03,\n",
      "       -1.12301130e-02,  2.05220338e-02, -1.10114440e-02, -1.56137496e-02,\n",
      "        5.68078784e-03, -2.96951924e-02,  8.94555449e-03,  1.91712938e-02,\n",
      "       -1.56282273e-03,  3.50584532e-03,  5.40160900e-03, -4.79020737e-03,\n",
      "       -1.34658080e-03,  9.00417566e-04, -8.61578528e-03, -1.18069071e-03,\n",
      "        1.48759689e-02, -2.16556410e-03, -6.50433637e-03,  1.12244720e-02,\n",
      "       -9.53724608e-03, -3.46162636e-03, -1.28220557e-03, -1.04855616e-02,\n",
      "        8.59251618e-03, -2.45821103e-03,  1.72093231e-02, -6.16433192e-03,\n",
      "       -1.86382420e-02, -2.45925132e-02,  2.85023288e-03,  4.14797198e-03,\n",
      "        1.54481689e-02, -1.28553538e-02, -1.60141103e-02, -7.18964497e-03,\n",
      "        7.45710917e-03,  7.30562815e-03, -3.04977782e-03,  1.60854943e-02,\n",
      "       -9.82863363e-03,  2.41120420e-02, -4.37091716e-04,  8.05124873e-05,\n",
      "        2.54597655e-03, -3.50594614e-03, -1.91635545e-02, -1.28725795e-02,\n",
      "        1.55005697e-02,  2.84123234e-04,  6.38070190e-03,  5.21266740e-03,\n",
      "        8.92974250e-03, -2.91319401e-03, -1.63733196e-02,  2.07089912e-03,\n",
      "       -4.07070573e-03, -1.02487542e-02, -2.89468523e-02,  8.15297291e-03,\n",
      "        1.17618097e-02, -9.22525208e-03,  7.57292891e-03, -3.26730348e-02,\n",
      "        1.21073062e-02,  1.75918397e-02, -3.26849543e-03,  2.05299282e-03,\n",
      "        6.90477388e-03, -1.17347785e-03,  2.38625556e-02,  1.00956787e-03,\n",
      "        1.30582019e-03,  5.87410759e-03, -1.04602445e-02, -1.02825658e-02,\n",
      "        1.55120306e-02,  1.26814945e-02,  1.12893367e-02,  8.34616739e-03,\n",
      "       -4.79551760e-04, -7.20465789e-03, -2.09985059e-02,  1.83865149e-03,\n",
      "        1.58955399e-02, -1.94089282e-02, -1.67974811e-02, -3.25468346e-03,\n",
      "       -5.76443691e-03,  3.66740650e-03,  1.97996106e-03, -3.89669556e-03,\n",
      "        6.30691461e-03,  1.53019372e-03, -1.15020666e-02,  4.63118451e-03,\n",
      "        6.80874102e-03,  1.25880064e-02, -8.24951567e-03, -1.70850717e-02,\n",
      "        1.99859515e-02,  1.05670909e-03,  2.50333804e-04,  3.38855106e-03,\n",
      "       -4.54321969e-03,  7.89164286e-03,  2.36176699e-02,  1.16715590e-02,\n",
      "       -1.17905885e-02, -1.27702365e-02,  2.37066410e-02,  1.68376528e-02,\n",
      "       -1.44649222e-02, -1.67653349e-03,  8.87527969e-03,  2.21864495e-04,\n",
      "        2.44446332e-03,  9.61790048e-03,  1.63401663e-02,  3.50256474e-03,\n",
      "        2.89945677e-03, -1.00832032e-02, -6.01541018e-03,  1.12336809e-02,\n",
      "       -1.68052986e-02, -8.96756165e-03,  1.41406208e-02, -1.57722253e-02,\n",
      "        8.71971366e-04, -1.55031281e-02, -6.81720627e-03, -3.69576253e-02,\n",
      "       -1.27655268e-02,  3.43962349e-02, -1.20527027e-02,  9.63951368e-03,\n",
      "        1.06917843e-02,  6.96154358e-03, -2.84781847e-02,  5.55937586e-04,\n",
      "       -2.26415861e-02,  1.64794584e-03, -8.66049342e-03,  9.79893468e-03,\n",
      "       -8.01722240e-03,  1.06434403e-02,  1.27047058e-02,  2.03081463e-02,\n",
      "       -3.16515677e-02, -5.77818789e-03, -7.12428195e-03, -1.42998816e-02,\n",
      "        1.67318247e-02,  1.57476552e-02, -1.01631908e-02,  7.71373091e-03,\n",
      "        1.56567078e-02,  1.02198776e-02,  1.00639043e-02,  7.51837902e-03,\n",
      "        1.13355089e-03,  3.79305333e-03, -4.21314081e-03,  9.18609928e-03,\n",
      "        1.47764934e-02, -2.30805539e-02,  1.43640144e-02,  2.64107715e-02,\n",
      "       -1.47463018e-02, -2.34720926e-03, -3.61800343e-02, -1.65071599e-02,\n",
      "        1.27342166e-02,  6.40563201e-03, -1.70883238e-02,  1.74127519e-02,\n",
      "       -5.53336134e-03, -3.53756896e-03, -1.03717158e-02,  1.41821255e-03,\n",
      "        8.28421582e-03,  9.28517245e-03,  1.16786193e-02, -6.24829717e-03,\n",
      "        1.78590638e-03, -5.16737055e-04, -1.98958181e-02, -1.25667164e-02,\n",
      "        9.26350243e-03, -2.39247712e-03, -1.23449359e-02, -5.99175808e-04,\n",
      "        4.30344325e-03, -1.09086366e-04,  7.59040052e-03,  2.38421839e-02,\n",
      "        7.06100883e-03,  9.33213905e-03, -4.77098674e-03,  1.48024242e-02,\n",
      "        1.77964550e-02, -1.85567851e-03, -1.70576468e-03,  3.37883155e-03,\n",
      "        2.61269622e-02,  1.23407459e-02,  2.17679120e-03, -9.37099569e-03,\n",
      "        1.66776776e-02,  5.50589291e-03,  8.90617911e-03,  2.04355083e-03,\n",
      "       -6.84187142e-03, -2.11148448e-02, -1.39754210e-02, -8.49584676e-03,\n",
      "        1.21848583e-02, -1.77535824e-02, -1.40895676e-02,  1.20689636e-02,\n",
      "       -9.48497618e-04, -3.16839316e-03, -7.58566055e-03, -5.60927961e-04,\n",
      "        7.17618130e-03,  8.91008764e-04,  2.12041494e-02, -3.59756220e-03,\n",
      "       -1.29852360e-02,  1.32026970e-02, -3.88822821e-03, -1.30857350e-02,\n",
      "       -6.10150537e-03,  1.71268042e-02, -3.04542948e-02,  1.65216420e-02,\n",
      "        1.30055016e-02, -1.07219126e-02, -3.89197655e-03,  4.62223589e-03,\n",
      "       -3.78122414e-03,  5.60315698e-03,  3.45621048e-03,  1.09878331e-02,\n",
      "        1.12683484e-02, -2.06197686e-02,  1.64751280e-02,  2.40643718e-03,\n",
      "        7.44161149e-03, -2.96181941e-04,  1.05980122e-02, -1.37372371e-02,\n",
      "       -1.85352508e-02,  1.44530591e-02,  1.50219714e-02,  1.40653667e-03,\n",
      "        7.13452790e-03, -3.62074329e-03,  1.14917587e-02, -1.82343414e-03,\n",
      "       -7.46455463e-03, -1.53870264e-03,  3.77526652e-04,  1.10562006e-02,\n",
      "       -5.38087916e-05, -8.21174216e-03,  2.49256915e-03,  1.86459068e-02,\n",
      "        2.33288556e-02,  1.44693442e-02, -9.07344976e-04, -2.91654305e-03,\n",
      "       -6.62642578e-03,  5.98857226e-03,  1.76597722e-02, -2.11498961e-02,\n",
      "       -1.45136146e-02, -2.56920327e-02,  1.43341729e-02,  4.50676586e-03,\n",
      "       -1.08193206e-02, -1.03285909e-02,  1.77500043e-02,  3.53054586e-03,\n",
      "       -2.41671759e-03, -5.39889588e-05,  1.59762371e-02,  1.79300848e-02,\n",
      "        6.22837048e-04,  1.49531919e-03, -1.85468756e-02,  3.24599358e-04,\n",
      "        2.86993803e-03,  1.35575281e-03,  1.22943679e-02,  1.91406757e-02,\n",
      "        1.51550276e-02,  1.55758308e-02, -9.24469531e-03, -5.49400086e-03,\n",
      "       -9.28653218e-03,  3.53404274e-03,  5.55634173e-03,  1.87368281e-02,\n",
      "        3.09360977e-02, -1.72827691e-02,  1.56960683e-03,  3.95849493e-04,\n",
      "       -1.29883103e-02, -1.19885104e-03,  1.36741493e-02, -6.92014955e-03,\n",
      "       -3.83911247e-04,  7.64652248e-03, -2.64686290e-02,  1.29107467e-03,\n",
      "        6.31418498e-03, -5.70762390e-03, -8.92537646e-03, -6.82429224e-03,\n",
      "       -3.52372881e-03, -3.71359754e-03, -1.62074678e-02, -9.45803337e-03,\n",
      "       -1.43339643e-02,  1.37584992e-02,  1.04307123e-02,  4.38956916e-03,\n",
      "       -1.50477476e-02, -2.44702934e-03,  1.13613077e-03, -8.56872369e-03,\n",
      "       -2.13204343e-02,  1.67497061e-02, -1.54024805e-03,  7.10909301e-03,\n",
      "        6.41256245e-03,  3.08066054e-04,  1.83677282e-02,  3.48769478e-03,\n",
      "        7.89995585e-03,  1.46775944e-02,  1.61078516e-02, -1.02419332e-02,\n",
      "        2.23059760e-04, -1.06266467e-02,  2.27655470e-02,  1.96046177e-02,\n",
      "        2.48669786e-03, -4.81764507e-03,  3.56572354e-03, -6.64619775e-03,\n",
      "       -2.60074949e-03, -1.89807117e-02, -1.03796264e-02,  7.05457199e-03,\n",
      "        1.87657941e-02, -3.00156213e-02,  1.33242328e-02, -9.08468151e-04,\n",
      "        3.58859403e-03, -1.02362689e-02,  5.70777897e-03,  2.08609868e-02,\n",
      "        5.26517071e-03,  1.33301681e-02, -5.75392880e-03, -7.92408455e-03,\n",
      "       -7.01895030e-03,  3.65925692e-02, -3.46653792e-03,  1.02772079e-02,\n",
      "       -8.60836916e-03, -4.95502539e-03,  3.39014307e-02, -2.82907765e-03,\n",
      "        1.88341346e-02, -6.14097202e-03,  2.11156881e-03,  3.52185802e-03,\n",
      "       -2.38578431e-02, -1.88703947e-02, -8.72302055e-03, -3.21200374e-03,\n",
      "       -1.76417008e-02, -1.39786990e-03,  1.94915978e-03, -1.31705962e-02,\n",
      "        1.35925002e-02, -7.21245352e-03, -2.18106154e-02,  1.99736096e-02,\n",
      "       -1.56027172e-02, -2.33216099e-02,  1.57980376e-03,  1.13460151e-02,\n",
      "        7.53455004e-03,  2.78099068e-02, -1.22048371e-02, -8.69495887e-03,\n",
      "       -4.14619781e-03,  2.60398700e-03, -1.36723155e-02, -1.22968331e-02,\n",
      "        1.31354469e-03,  1.31197348e-02,  7.15232082e-03,  3.79969319e-03,\n",
      "        1.04327863e-02, -1.64652150e-02,  1.37368124e-02,  1.06090149e-02,\n",
      "        5.80345374e-03,  1.97578222e-02,  2.39108587e-04, -8.44391435e-03,\n",
      "       -1.01993708e-02,  1.97989517e-03, -4.59281635e-03,  1.77324086e-03,\n",
      "        3.19329975e-03, -4.94447676e-03, -1.31261628e-02,  9.90158226e-03,\n",
      "       -6.17321394e-03, -6.77399058e-03,  5.13996417e-03, -1.41326506e-02,\n",
      "        2.97027435e-02,  2.47059834e-05, -4.73425817e-03,  2.80770636e-03,\n",
      "       -1.94128591e-03,  2.75275465e-02, -8.56101885e-03,  2.48631313e-02,\n",
      "        2.50110086e-02,  1.05406009e-02, -6.29127352e-03, -2.54881661e-02,\n",
      "       -1.58631988e-02,  1.06348852e-02,  7.41935568e-03,  1.32178317e-03,\n",
      "       -8.71076714e-03,  8.19924194e-03,  7.33182859e-03, -5.17645339e-03,\n",
      "        1.94861274e-02, -5.91786858e-03,  1.50610777e-02, -1.02588283e-02,\n",
      "       -5.79085713e-03,  6.99279364e-03, -3.54413176e-03,  2.26902310e-02,\n",
      "       -1.97302122e-02,  1.14577580e-02,  3.96727724e-03, -2.41615227e-04,\n",
      "        9.27683990e-03, -1.85529643e-03,  1.82690786e-03,  8.19442607e-03,\n",
      "        3.21576977e-03,  1.87695737e-03, -1.02975201e-02,  5.47274388e-03,\n",
      "        5.01269649e-04, -1.51163451e-02,  9.83804557e-03, -7.88633944e-04],\n",
      "      dtype=float32)}\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T01:17:41.022311Z",
     "start_time": "2025-08-18T01:17:41.015800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "doc_to_int, int_to_doc = {}, {}\n",
    "next_doc_int = 1\n",
    "\n",
    "ids = []\n",
    "vecs = []\n",
    "\n",
    "for key, vec in sent_embeddings.items():\n",
    "    doc_id, sent_id_str = key.split(\":\", 1)\n",
    "    sent_id = int(sent_id_str)\n",
    "\n",
    "    if doc_id not in doc_to_int:\n",
    "        doc_to_int[doc_id] = next_doc_int\n",
    "        int_to_doc[next_doc_int] = doc_id\n",
    "        next_doc_int += 1\n",
    "\n",
    "    did = np.int64(doc_to_int[doc_id])\n",
    "    fid = (did << np.int64(32)) | np.int64(sent_id)\n",
    "    ids.append(fid)\n",
    "    vecs.append(vec.astype(\"float32\"))\n",
    "\n",
    "X = np.vstack(vecs).astype(\"float32\")\n",
    "\n",
    "# (optional) cosine via inner product\n",
    "faiss.normalize_L2(X)\n",
    "\n",
    "base = faiss.IndexFlatIP(X.shape[1])\n",
    "index = faiss.IndexIDMap2(base)\n",
    "index.add_with_ids(X, np.asarray(ids, dtype=\"int64\"))"
   ],
   "id": "2a175b2f8a75a973",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Evaluation\n",
    "\n",
    "k_list = [1, 5, 10, 20]\n",
    "k_max = max(k_list)\n",
    "\n",
    "hits_at_k = {k:0 for k in k_list}\n",
    "f1_gold, f1_pred = [], []\n",
    "\n",
    "start = 0\n",
    "for rec in tqdm.tqdm(test_records, desc=\"evaluate\"):\n",
    "    end = sent_offsets.pop(0)\n",
    "    doc_sentence_slice = slice(start, end)\n",
    "    start = end\n",
    "\n",
    "    prefix_vec = np.array(\n",
    "        prefix_predictor.predict({\"inputs\": [rec[\"prefix\"]]}),\n",
    "        dtype = \"float32\",\n",
    "    )\n",
    "\n",
    "    # Check this masking because it is not the same exactly\n",
    "    mask_same_sentence = [\n",
    "        sent in rec[\"prefix\"] for sent in rec[\"sentences\"]\n",
    "    ]\n",
    "    mast_same_sentence = np.array(mask_same_sentence, dtype=bool)\n",
    "\n",
    "    # ids of candidates to keep\n",
    "    keep_ids = np.where(~mast_same_sentence)[0] + doc_sentence_slice.start\n",
    "    keep_vecs = all_vecs[keep_ids]\n",
    "\n",
    "    # faiss index\n",
    "    D, I = index.search(prefix_vec, k_max)\n",
    "\n",
    "    # drop candidates with global id not in keep_ids\n",
    "    valid = [i for i in I[0] if i in keep_ids][:k_max]\n",
    "    if len(valid) < k_max:\n",
    "        extra = [i for i in I[0] if i not in keep_ids]\n",
    "        valid.extend(extra[: k_max - len(valid)])\n",
    "\n",
    "    # Compute metrix\n",
    "    for k in k_list:\n",
    "        if any(all_sentences[i] == rec[\"positive\"] for i in valid[:k]):\n",
    "            hits_at_k[k] += 1\n",
    "\n",
    "    # Binary F1\n",
    "    pred1 = [1 if all_sentences[i] == rec[\"positive\"] else 0 for i in valid]\n",
    "    f1_gold.append([1] + [0]*(len(pred1) -1))\n",
    "    f1_pred.append(pred1)\n",
    "\n",
    "# Aggregate metrics\n",
    "n = len(test_records)\n",
    "recall = {k: hits_at_k[k] / n for k in k_list}\n",
    "\n",
    "# macro f1\n",
    "f1_scores = [\n",
    "    f1_score(g, p, zero_division=0) for g, p in zip(f1_gold, f1_pred)\n",
    "]\n",
    "f1_macro = {k: np.mean([f1_scores[i] for i in range(n)]) for k in k_list}\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Macro F1:\", f1_macro)"
   ],
   "id": "f134e1a226764c44"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-08-14T02:56:08.501695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "module_directory = os.path.abspath('code/')\n",
    "\n",
    "# Add the directory to the Python path\n",
    "sys.path.append(module_directory)\n",
    "\n",
    "from inference import model_fn, transform_fn\n",
    "m = model_fn(\"model\")\n",
    "body = json.dumps({\"inputs\": \"A quick test sentence.\"})\n",
    "out, ctype = transform_fn(m, body, \"application/json\", \"application/json\")\n",
    "print(ctype, out[:80], \"...\")"
   ],
   "id": "88e8241c045d9a06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T17:34:38.507894Z",
     "start_time": "2025-08-15T17:34:37.755776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import json, math, sys, re\n",
    "from typing import Any, Iterable, Tuple, Optional\n",
    "\n",
    "# --- core checks ---\n",
    "CONTROL_CHARS_RE = re.compile(r\"[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F]\")  # raw control chars (must be escaped in JSON text)\n",
    "\n",
    "def _check_numbers(x: Any, path: str=\"$\") -> Optional[Tuple[str, float]]:\n",
    "    \"\"\"Return (path, value) if a non-finite number is found anywhere.\"\"\"\n",
    "    if isinstance(x, float):\n",
    "        if not math.isfinite(x):\n",
    "            return (path, x)\n",
    "    elif isinstance(x, (list, tuple)):\n",
    "        for i, v in enumerate(x):\n",
    "            hit = _check_numbers(v, f\"{path}[{i}]\")\n",
    "            if hit: return hit\n",
    "    elif isinstance(x, dict):\n",
    "        for k, v in x.items():\n",
    "            hit = _check_numbers(v, f\"{path}.{k}\")\n",
    "            if hit: return hit\n",
    "    return None\n",
    "\n",
    "def _check_schema(obj: Any) -> str:\n",
    "    \"\"\"Return an error string or '' if OK for schema:\n",
    "       {\"doc_id\": str, \"sent_id\": int, \"inputs\": str}\"\"\"\n",
    "    if not isinstance(obj, dict):\n",
    "        return \"record is not a JSON object\"\n",
    "    for k in (\"docid\", \"sentid\", \"inputs\"):\n",
    "        if k not in obj:\n",
    "            return f\"missing required key: {k}\"\n",
    "    if not isinstance(obj[\"docid\"], str) or not obj[\"docid\"]:\n",
    "        return \"docid must be a non-empty string\"\n",
    "    if not isinstance(obj[\"sentid\"], int):\n",
    "        return \"sentid must be an integer\"\n",
    "    if not isinstance(obj[\"inputs\"], str) or not obj[\"inputs\"]:\n",
    "        return \"inputs must be a non-empty string\"\n",
    "    if CONTROL_CHARS_RE.search(obj[\"docid\"]):\n",
    "        return \"docid contains raw control characters\"\n",
    "    # (inputs may legitimately contain \\n, \\t etc as escaped sequences in JSON; the decoder handles that)\n",
    "    return \"\"\n",
    "\n",
    "def validate_jsonl_lines(lines: Iterable[bytes]) -> None:\n",
    "    \"\"\"Validate a JSONL stream (bytes per line). Prints first problem found and exits(1); otherwise prints OK.\"\"\"\n",
    "    # Detect BOM on very first bytes\n",
    "    first = True\n",
    "    for i, raw in enumerate(lines, 1):\n",
    "        if not raw:\n",
    "            # skip blank lines; JSON Lines allows them but many pipelines don’t expect them\n",
    "            continue\n",
    "        if first:\n",
    "            first = False\n",
    "            if raw.startswith(b\"\\xef\\xbb\\xbf\"):  # UTF-8 BOM\n",
    "                print(f\"Line {i}: UTF-8 BOM detected; prefer UTF-8 without BOM.\", file=sys.stderr)\n",
    "\n",
    "        # Strict UTF-8; fail fast on decoding errors\n",
    "        try:\n",
    "            s = raw.decode(\"utf-8\", \"strict\")\n",
    "        except UnicodeDecodeError as e:\n",
    "            print(f\"Line {i}: UTF-8 decode error: {e}\", file=sys.stderr)\n",
    "            sys.exit(1)\n",
    "\n",
    "        # Must be a single JSON value per line (no trailing commas etc.)\n",
    "        try:\n",
    "            rec = json.loads(s)\n",
    "        except json.JSONDecodeError as e:\n",
    "            head = s[:120].replace(\"\\n\", \"\\\\n\")\n",
    "            print(f\"Line {i}: invalid JSON ({e.msg}) at pos {e.pos}. Head: {head!r}\", file=sys.stderr)\n",
    "            sys.exit(1)\n",
    "\n",
    "        # Schema & numeric sanity\n",
    "        err = _check_schema(rec)\n",
    "        if err:\n",
    "            print(f\"Line {i}: {err}\", file=sys.stderr)\n",
    "            sys.exit(1)\n",
    "\n",
    "        hit = _check_numbers(rec)\n",
    "        if hit:\n",
    "            path, val = hit\n",
    "            print(f\"Line {i}: non-finite number at {path}: {val!r} (JSON forbids NaN/Infinity).\", file=sys.stderr)\n",
    "            sys.exit(1)\n",
    "\n",
    "    print(\"Input looks good: UTF-8 OK, valid JSON Lines, schema OK, no NaN/Infinity found.\")\n",
    "\n",
    "# --- usage examples ---\n",
    "\n",
    "# 1) Local file:\n",
    "# with open(\"your_input.jsonl\", \"rb\") as f:\n",
    "#     validate_jsonl_lines(f)\n",
    "\n",
    "# 2) S3 object:\n",
    "# import boto3\n",
    "# s3 = boto3.client(\"s3\")\n",
    "# obj = s3.get_object(Bucket=\"your-bucket\", Key=\"path/to/input.jsonl\")\n",
    "# validate_jsonl_lines(obj[\"Body\"].iter_lines())\n",
    "\n",
    "\n",
    "import boto3, json\n",
    "\n",
    "key = f\"{prefix}/batch-output/{run_id}.jsonl\"\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "validate_jsonl_lines(obj[\"Body\"].iter_lines())\n",
    "\n"
   ],
   "id": "9ae78ea06edb0f91",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input looks good: UTF-8 OK, valid JSON Lines, schema OK, no NaN/Infinity found.\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d1dc8d47dbdb2840"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legalpacaenv",
   "language": "python",
   "name": "lagalpacaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
