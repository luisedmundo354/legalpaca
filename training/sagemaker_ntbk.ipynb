{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T21:25:33.040462Z",
     "start_time": "2025-07-28T21:25:32.675139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "# 2) Hard‑code (or read from env var) the execution‑role ARN you created\n",
    "role = \"arn:aws:iam::371087393859:role/defaultrole\"\n",
    "bucket = \"ir-sagemaker\"\n",
    "session = boto3.Session(profile_name=\"lprofile\", region_name=\"us-east-1\")\n",
    "\n",
    "sm_session = sagemaker.Session(boto_session=session, default_bucket=bucket)"
   ],
   "id": "6f0f99a1aa518973",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T21:25:33.438145Z",
     "start_time": "2025-07-28T21:25:33.280377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sm_session.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sm_session.boto_region_name}\")\n"
   ],
   "id": "2bb382bdca8243f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::371087393859:role/defaultrole\n",
      "sagemaker bucket: ir-sagemaker\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T21:25:35.085363Z",
     "start_time": "2025-07-28T21:25:35.082184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "bucket = sm_session.default_bucket()\n",
    "prefix = \"modernbert\"\n",
    "\n",
    "train_uri = f\"s3://{bucket}/{prefix}/train/train.jsonl\"\n",
    "val_uri   = f\"s3://{bucket}/{prefix}/val/val.jsonl\"\n",
    "test_uri  = f\"s3://{bucket}/{prefix}/test/test.jsonl\""
   ],
   "id": "da15a52c29c320e1",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T22:13:04.293995Z",
     "start_time": "2025-07-23T22:13:04.278233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_uri = S3Uploader.upload(\"modernbert/data/train/train.jsonl\", f\"s3://{bucket}/{prefix}/train\")\n",
    "val_uri = S3Uploader.upload(\"modernbert/data/val/val.jsonl\",   f\"s3://{bucket}/{prefix}/val\")\n",
    "test_uri = S3Uploader.upload(\"modernbert/data/test/test.jsonl\", f\"s3://{bucket}/{prefix}/test\")"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[38;2;255;0;0m╭─\u001B[0m\u001B[38;2;255;0;0m──────────────────────────────\u001B[0m\u001B[38;2;255;0;0m \u001B[0m\u001B[1;38;2;255;0;0mTraceback \u001B[0m\u001B[1;2;38;2;255;0;0m(most recent call last)\u001B[0m\u001B[38;2;255;0;0m \u001B[0m\u001B[38;2;255;0;0m───────────────────────────────\u001B[0m\u001B[38;2;255;0;0m─╮\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m in <module>:2                                                                                    \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m                                                                                                  \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m1 \u001B[0m\u001B[94mfrom\u001B[0m\u001B[90m \u001B[0m\u001B[4;96msagemaker\u001B[0m\u001B[4;96m.\u001B[0m\u001B[4;96ms3\u001B[0m\u001B[90m \u001B[0m\u001B[94mimport\u001B[0m S3Uploader                                                          \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m \u001B[31m❱ \u001B[0m2 train_uri = S3Uploader.upload(\u001B[33m\"\u001B[0m\u001B[33mmodernbert/data/train/train.jsonl\u001B[0m\u001B[33m\"\u001B[0m, \u001B[33mf\u001B[0m\u001B[33m\"\u001B[0m\u001B[33ms3://\u001B[0m\u001B[33m{\u001B[0mbucket\u001B[33m}\u001B[0m\u001B[33m/\u001B[0m\u001B[33m{\u001B[0mpref     \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m3 \u001B[0mval_uri = S3Uploader.upload(\u001B[33m\"\u001B[0m\u001B[33mmodernbert/data/val/val.jsonl\u001B[0m\u001B[33m\"\u001B[0m,   \u001B[33mf\u001B[0m\u001B[33m\"\u001B[0m\u001B[33ms3://\u001B[0m\u001B[33m{\u001B[0mbucket\u001B[33m}\u001B[0m\u001B[33m/\u001B[0m\u001B[33m{\u001B[0mprefix\u001B[33m}\u001B[0m\u001B[33m/\u001B[0m     \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m4 \u001B[0mtest_uri = S3Uploader.upload(\u001B[33m\"\u001B[0m\u001B[33mmodernbert/data/test/test.jsonl\u001B[0m\u001B[33m\"\u001B[0m, \u001B[33mf\u001B[0m\u001B[33m\"\u001B[0m\u001B[33ms3://\u001B[0m\u001B[33m{\u001B[0mbucket\u001B[33m}\u001B[0m\u001B[33m/\u001B[0m\u001B[33m{\u001B[0mprefix\u001B[33m}\u001B[0m     \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m5 \u001B[0m                                                                                             \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n",
       "\u001B[1;91mNameError: \u001B[0mname \u001B[38;2;0;135;0m'prefix'\u001B[0m is not defined\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">╭─────────────────────────────── </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Traceback </span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> in &lt;module&gt;:2                                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">sagemaker.s3</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> S3Uploader                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2 train_uri = S3Uploader.upload(<span style=\"color: #808000; text-decoration-color: #808000\">\"modernbert/data/train/train.jsonl\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">f\"s3://{</span>bucket<span style=\"color: #808000; text-decoration-color: #808000\">}/{</span>pref     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>val_uri = S3Uploader.upload(<span style=\"color: #808000; text-decoration-color: #808000\">\"modernbert/data/val/val.jsonl\"</span>,   <span style=\"color: #808000; text-decoration-color: #808000\">f\"s3://{</span>bucket<span style=\"color: #808000; text-decoration-color: #808000\">}/{</span>prefix<span style=\"color: #808000; text-decoration-color: #808000\">}/</span>     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>test_uri = S3Uploader.upload(<span style=\"color: #808000; text-decoration-color: #808000\">\"modernbert/data/test/test.jsonl\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">f\"s3://{</span>bucket<span style=\"color: #808000; text-decoration-color: #808000\">}/{</span>prefix<span style=\"color: #808000; text-decoration-color: #808000\">}</span>     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 </span>                                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008700; text-decoration-color: #008700\">'prefix'</span> is not defined\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T22:30:42.751945Z",
     "start_time": "2025-07-28T22:30:42.725199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "hyper = {\"learning_rate\":3e-5,\n",
    "         \"num_train_epochs\":3,\n",
    "         \"temperature\":0.05,\n",
    "         \"deepspeed\": \"ds_zero3.json\"}\n",
    "est = HuggingFace(\n",
    "    entry_point=\"train_sm.py\",\n",
    "    source_dir=\"modernbert\",\n",
    "    role=role,\n",
    "    instance_type=\"ml.g5.12xlarge\",\n",
    "    instance_count=1,\n",
    "    distribution={\"mpi\": {\"enabled\": True}},\n",
    "    transformers_version=\"4.54.0\", pytorch_version=\"2.5.1\", py_version=\"py311\",\n",
    "    hyperparameters=hyper,\n",
    "    environment={\n",
    "        \"PYTORCH_CUDA_ALLOC_CONF\": \"expandable_segments:True\",\n",
    "        \"NCCL_DEBUG\": \"INFO\"\n",
    "    },\n",
    "    output_path=f\"s3://{bucket}/{prefix}/outputs\"\n",
    ")"
   ],
   "id": "f2ea6d1b5bdecbf2",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T22:57:47.135399Z",
     "start_time": "2025-07-28T22:30:43.207719Z"
    }
   },
   "cell_type": "code",
   "source": "est.fit({\"train\": train_uri, \"val\": val_uri, \"test\": test_uri})",
   "id": "f43f69a1cd6ff444",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-pytorch-training-2025-07-28-22-30-43-226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-28 22:30:47 Starting - Starting the training job\n",
      "2025-07-28 22:30:47 Pending - Training job waiting for capacity...\n",
      "2025-07-28 22:31:17 Pending - Preparing the instances for training......\n",
      "2025-07-28 22:32:03 Downloading - Downloading the training image........................\n",
      "2025-07-28 22:36:00 Training - Training image download completed. Training in progress....\u001B[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001B[0m\n",
      "\u001B[34mbash: no job control in this shell\u001B[0m\n",
      "\u001B[34mCUDA compat package should be installed for NVIDIA driver smaller than 550.163.01\u001B[0m\n",
      "\u001B[34mCurrent installed NVIDIA driver version is 550.163.01\u001B[0m\n",
      "\u001B[34mSkipping CUDA compat setup as newer NVIDIA driver is installed\u001B[0m\n",
      "\u001B[34m2025-07-28 22:36:39,572 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001B[0m\n",
      "\u001B[34m2025-07-28 22:36:39,608 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001B[0m\n",
      "\u001B[34m2025-07-28 22:36:39,618 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001B[0m\n",
      "\u001B[34m2025-07-28 22:36:39,619 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001B[0m\n",
      "\u001B[34m2025-07-28 22:36:41,082 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: torch==2.5.1 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (2.5.1+cu124)\u001B[0m\n",
      "\u001B[34mCollecting deepspeed==0.17.1 (from -r requirements.txt (line 2))\u001B[0m\n",
      "\u001B[34mDownloading deepspeed-0.17.1.tar.gz (1.5 MB)\u001B[0m\n",
      "\u001B[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 63.9 MB/s eta 0:00:00\u001B[0m\n",
      "\u001B[34mPreparing metadata (setup.py): started\u001B[0m\n",
      "\u001B[34mPreparing metadata (setup.py): finished with status 'done'\u001B[0m\n",
      "\u001B[34mCollecting transformers==4.54.0 (from -r requirements.txt (line 3))\u001B[0m\n",
      "\u001B[34mDownloading transformers-4.54.0-py3-none-any.whl.metadata (41 kB)\u001B[0m\n",
      "\u001B[34mCollecting flash-attn==2.7.4.post1 (from -r requirements.txt (line 6))\u001B[0m\n",
      "\u001B[34mDownloading flash_attn-2.7.4.post1.tar.gz (6.0 MB)\u001B[0m\n",
      "\u001B[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.0/6.0 MB 137.2 MB/s eta 0:00:00\u001B[0m\n",
      "\u001B[34mPreparing metadata (setup.py): started\u001B[0m\n",
      "\u001B[34mPreparing metadata (setup.py): finished with status 'done'\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: triton>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (3.1.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (1.11.1.3)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (24.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (3.18.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (4.14.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (3.5)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (3.1.6)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (2024.12.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (1.13.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: einops in /opt/conda/lib/python3.11/site-packages (from deepspeed==0.17.1->-r requirements.txt (line 2)) (0.8.1)\u001B[0m\n",
      "\u001B[34mCollecting hjson (from deepspeed==0.17.1->-r requirements.txt (line 2))\u001B[0m\n",
      "\u001B[34mDownloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: msgpack in /opt/conda/lib/python3.11/site-packages (from deepspeed==0.17.1->-r requirements.txt (line 2)) (1.1.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from deepspeed==0.17.1->-r requirements.txt (line 2)) (1.26.4)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from deepspeed==0.17.1->-r requirements.txt (line 2)) (7.0.0)\u001B[0m\n",
      "\u001B[34mCollecting py-cpuinfo (from deepspeed==0.17.1->-r requirements.txt (line 2))\u001B[0m\n",
      "\u001B[34mDownloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pydantic>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from deepspeed==0.17.1->-r requirements.txt (line 2)) (2.11.7)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from deepspeed==0.17.1->-r requirements.txt (line 2)) (4.66.5)\u001B[0m\n",
      "\u001B[34mCollecting nvidia-ml-py (from deepspeed==0.17.1->-r requirements.txt (line 2))\u001B[0m\n",
      "\u001B[34mDownloading nvidia_ml_py-12.575.51-py3-none-any.whl.metadata (9.3 kB)\u001B[0m\n",
      "\u001B[34mCollecting huggingface-hub<1.0,>=0.34.0 (from transformers==4.54.0->-r requirements.txt (line 3))\u001B[0m\n",
      "\u001B[34mDownloading huggingface_hub-0.34.2-py3-none-any.whl.metadata (14 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers==4.54.0->-r requirements.txt (line 3)) (6.0.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers==4.54.0->-r requirements.txt (line 3)) (2024.11.6)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers==4.54.0->-r requirements.txt (line 3)) (2.32.4)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers==4.54.0->-r requirements.txt (line 3)) (0.21.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from transformers==4.54.0->-r requirements.txt (line 3)) (0.5.3)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch==2.5.1->-r requirements.txt (line 1)) (1.3.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.54.0->-r requirements.txt (line 3)) (1.1.5)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic>=2.0.0->deepspeed==0.17.1->-r requirements.txt (line 2)) (0.7.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pydantic-core==2.33.2 in /opt/conda/lib/python3.11/site-packages (from pydantic>=2.0.0->deepspeed==0.17.1->-r requirements.txt (line 2)) (2.33.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic>=2.0.0->deepspeed==0.17.1->-r requirements.txt (line 2)) (0.4.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch==2.5.1->-r requirements.txt (line 1)) (3.0.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.54.0->-r requirements.txt (line 3)) (3.4.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.54.0->-r requirements.txt (line 3)) (3.10)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.54.0->-r requirements.txt (line 3)) (2.5.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.54.0->-r requirements.txt (line 3)) (2025.7.14)\u001B[0m\n",
      "\u001B[34mDownloading transformers-4.54.0-py3-none-any.whl (11.2 MB)\u001B[0m\n",
      "\u001B[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.2/11.2 MB 113.4 MB/s eta 0:00:00\u001B[0m\n",
      "\u001B[34mDownloading huggingface_hub-0.34.2-py3-none-any.whl (558 kB)\u001B[0m\n",
      "\u001B[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 558.8/558.8 kB 59.4 MB/s eta 0:00:00\u001B[0m\n",
      "\u001B[34mDownloading hjson-3.1.0-py3-none-any.whl (54 kB)\u001B[0m\n",
      "\u001B[34mDownloading nvidia_ml_py-12.575.51-py3-none-any.whl (47 kB)\u001B[0m\n",
      "\u001B[34mDownloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\u001B[0m\n",
      "\u001B[34mBuilding wheels for collected packages: deepspeed, flash-attn\u001B[0m\n",
      "\u001B[34mDEPRECATION: Building 'deepspeed' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'deepspeed'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001B[0m\n",
      "\u001B[34mBuilding wheel for deepspeed (setup.py): started\u001B[0m\n",
      "\u001B[34mBuilding wheel for deepspeed (setup.py): finished with status 'done'\u001B[0m\n",
      "\u001B[34mCreated wheel for deepspeed: filename=deepspeed-0.17.1-py3-none-any.whl size=1690874 sha256=67772d6a7583dbf5dab3b0e0abbab602f6af6a35cd8fd50da41a645a09cb5253\u001B[0m\n",
      "\u001B[34mStored in directory: /root/.cache/pip/wheels/34/86/36/22db26525829160fd1c4add33d8a834ec046b90abf45cd363b\u001B[0m\n",
      "\u001B[34mDEPRECATION: Building 'flash-attn' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'flash-attn'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001B[0m\n",
      "\u001B[34mBuilding wheel for flash-attn (setup.py): started\u001B[0m\n",
      "\u001B[34mBuilding wheel for flash-attn (setup.py): finished with status 'done'\u001B[0m\n",
      "\u001B[34mCreated wheel for flash-attn: filename=flash_attn-2.7.4.post1-cp311-cp311-linux_x86_64.whl size=187815463 sha256=d944fc7d2f962bce83fc4708c2fc0c21eaf8255962a0b350ae919362a51b7ef2\u001B[0m\n",
      "\u001B[34mStored in directory: /root/.cache/pip/wheels/3d/88/d8/284b89f56af7d5bf366b10d6b8e251ac8a7c7bf3f04203fb4f\u001B[0m\n",
      "\u001B[34mSuccessfully built deepspeed flash-attn\u001B[0m\n",
      "\u001B[34mInstalling collected packages: py-cpuinfo, nvidia-ml-py, hjson, huggingface-hub, flash-attn, deepspeed, transformers\u001B[0m\n",
      "\u001B[34mAttempting uninstall: huggingface-hub\u001B[0m\n",
      "\u001B[34mFound existing installation: huggingface-hub 0.29.1\u001B[0m\n",
      "\u001B[34mUninstalling huggingface-hub-0.29.1:\u001B[0m\n",
      "\u001B[34mSuccessfully uninstalled huggingface-hub-0.29.1\u001B[0m\n",
      "\u001B[34mAttempting uninstall: flash-attn\u001B[0m\n",
      "\u001B[34mFound existing installation: flash-attn 2.7.3\u001B[0m\n",
      "\u001B[34mUninstalling flash-attn-2.7.3:\u001B[0m\n",
      "\u001B[34mSuccessfully uninstalled flash-attn-2.7.3\u001B[0m\n",
      "\u001B[34mAttempting uninstall: transformers\u001B[0m\n",
      "\u001B[34mFound existing installation: transformers 4.49.0\u001B[0m\n",
      "\u001B[34mUninstalling transformers-4.49.0:\u001B[0m\n",
      "\u001B[34mSuccessfully uninstalled transformers-4.49.0\u001B[0m\n",
      "\u001B[34mSuccessfully installed deepspeed-0.17.1 flash-attn-2.7.4.post1 hjson-3.1.0 huggingface-hub-0.34.2 nvidia-ml-py-12.575.51 py-cpuinfo-9.0.0 transformers-4.54.0\u001B[0m\n",
      "\u001B[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001B[0m\n",
      "\u001B[34m2025-07-28 22:37:07,961 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001B[0m\n",
      "\u001B[34m2025-07-28 22:37:07,961 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001B[0m\n",
      "\u001B[34m2025-07-28 22:37:08,021 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001B[0m\n",
      "\u001B[34m2025-07-28 22:37:08,068 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001B[0m\n",
      "\u001B[34m2025-07-28 22:37:08,077 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001B[0m\n",
      "\u001B[34m2025-07-28 22:37:08,077 sagemaker-training-toolkit INFO     Creating SSH daemon.\u001B[0m\n",
      "\u001B[34m2025-07-28 22:37:08,078 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\u001B[0m\n",
      "\u001B[34m2025-07-28 22:37:08,078 sagemaker-training-toolkit INFO     Env Hosts: ['algo-1'] Hosts: ['algo-1:4'] process_per_hosts: 4 num_processes: 4\u001B[0m\n",
      "\u001B[34m2025-07-28 22:37:08,078 sagemaker-training-toolkit INFO     Network interface name: eth0\u001B[0m\n",
      "\u001B[34m2025-07-28 22:37:08,117 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001B[0m\n",
      "\u001B[34m2025-07-28 22:37:08,164 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001B[0m\n",
      "\u001B[34m2025-07-28 22:37:08,175 sagemaker-training-toolkit INFO     Invoking user script\u001B[0m\n",
      "\u001B[34mTraining Env:\u001B[0m\n",
      "\u001B[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_mpi_custom_mpi_options\": \"\",\n",
      "        \"sagemaker_mpi_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"val\": \"/opt/ml/input/data/val\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.12xlarge\",\n",
      "    \"distribution_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"distribution_instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"deepspeed\": \"ds_zero3.json\",\n",
      "        \"learning_rate\": 3e-05,\n",
      "        \"num_train_epochs\": 3,\n",
      "        \"temperature\": 0.05\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"val\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.12xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-pytorch-training-2025-07-28-22-30-43-226\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://ir-sagemaker/huggingface-pytorch-training-2025-07-28-22-30-43-226/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_sm\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 48,\n",
      "    \"num_gpus\": 4,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.12xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.12xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"topology\": null\n",
      "    },\n",
      "    \"user_entry_point\": \"train_sm.py\"\u001B[0m\n",
      "\u001B[34m}\u001B[0m\n",
      "\u001B[34mEnvironment variables:\u001B[0m\n",
      "\u001B[34mSM_HOSTS=[\"algo-1\"]\u001B[0m\n",
      "\u001B[34mSM_NETWORK_INTERFACE_NAME=eth0\u001B[0m\n",
      "\u001B[34mSM_HPS={\"deepspeed\":\"ds_zero3.json\",\"learning_rate\":3e-05,\"num_train_epochs\":3,\"temperature\":0.05}\u001B[0m\n",
      "\u001B[34mSM_USER_ENTRY_POINT=train_sm.py\u001B[0m\n",
      "\u001B[34mSM_FRAMEWORK_PARAMS={\"sagemaker_mpi_custom_mpi_options\":\"\",\"sagemaker_mpi_enabled\":true}\u001B[0m\n",
      "\u001B[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.12xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null}\u001B[0m\n",
      "\u001B[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001B[0m\n",
      "\u001B[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001B[0m\n",
      "\u001B[34mSM_CHANNELS=[\"test\",\"train\",\"val\"]\u001B[0m\n",
      "\u001B[34mSM_CURRENT_HOST=algo-1\u001B[0m\n",
      "\u001B[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.12xlarge\u001B[0m\n",
      "\u001B[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001B[0m\n",
      "\u001B[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001B[0m\n",
      "\u001B[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001B[0m\n",
      "\u001B[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}}\u001B[0m\n",
      "\u001B[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001B[0m\n",
      "\u001B[34mSM_IS_HETERO=false\u001B[0m\n",
      "\u001B[34mSM_MODULE_NAME=train_sm\u001B[0m\n",
      "\u001B[34mSM_LOG_LEVEL=20\u001B[0m\n",
      "\u001B[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001B[0m\n",
      "\u001B[34mSM_INPUT_DIR=/opt/ml/input\u001B[0m\n",
      "\u001B[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001B[0m\n",
      "\u001B[34mSM_OUTPUT_DIR=/opt/ml/output\u001B[0m\n",
      "\u001B[34mSM_NUM_CPUS=48\u001B[0m\n",
      "\u001B[34mSM_NUM_GPUS=4\u001B[0m\n",
      "\u001B[34mSM_NUM_NEURONS=0\u001B[0m\n",
      "\u001B[34mSM_MODEL_DIR=/opt/ml/model\u001B[0m\n",
      "\u001B[34mSM_MODULE_DIR=s3://ir-sagemaker/huggingface-pytorch-training-2025-07-28-22-30-43-226/source/sourcedir.tar.gz\u001B[0m\n",
      "\u001B[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_mpi_custom_mpi_options\":\"\",\"sagemaker_mpi_enabled\":true},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"val\":\"/opt/ml/input/data/val\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.12xlarge\",\"distribution_hosts\":[\"algo-1\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"deepspeed\":\"ds_zero3.json\",\"learning_rate\":3e-05,\"num_train_epochs\":3,\"temperature\":0.05},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":true,\"job_name\":\"huggingface-pytorch-training-2025-07-28-22-30-43-226\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://ir-sagemaker/huggingface-pytorch-training-2025-07-28-22-30-43-226/source/sourcedir.tar.gz\",\"module_name\":\"train_sm\",\"network_interface_name\":\"eth0\",\"num_cpus\":48,\"num_gpus\":4,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.12xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"user_entry_point\":\"train_sm.py\"}\u001B[0m\n",
      "\u001B[34mSM_USER_ARGS=[\"--deepspeed\",\"ds_zero3.json\",\"--learning_rate\",\"3e-05\",\"--num_train_epochs\",\"3\",\"--temperature\",\"0.05\"]\u001B[0m\n",
      "\u001B[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001B[0m\n",
      "\u001B[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001B[0m\n",
      "\u001B[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001B[0m\n",
      "\u001B[34mSM_CHANNEL_VAL=/opt/ml/input/data/val\u001B[0m\n",
      "\u001B[34mSM_HP_DEEPSPEED=ds_zero3.json\u001B[0m\n",
      "\u001B[34mSM_HP_LEARNING_RATE=3e-05\u001B[0m\n",
      "\u001B[34mSM_HP_NUM_TRAIN_EPOCHS=3\u001B[0m\n",
      "\u001B[34mSM_HP_TEMPERATURE=0.05\u001B[0m\n",
      "\u001B[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python311.zip:/opt/conda/lib/python3.11:/opt/conda/lib/python3.11/lib-dynload:/opt/conda/lib/python3.11/site-packages\u001B[0m\n",
      "\u001B[34mInvoking script with the following command:\u001B[0m\n",
      "\u001B[34mmpirun --host algo-1:4 -np 4 --allow-run-as-root --display-map --tag-output -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -bind-to none -map-by slot -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -x NCCL_MIN_NRINGS=4 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x LD_PRELOAD=/opt/conda/lib/python3.11/site-packages/gethostname.cpython-311-x86_64-linux-gnu.so -x SM_HOSTS -x SM_NETWORK_INTERFACE_NAME -x SM_HPS -x SM_USER_ENTRY_POINT -x SM_FRAMEWORK_PARAMS -x SM_RESOURCE_CONFIG -x SM_INPUT_DATA_CONFIG -x SM_OUTPUT_DATA_DIR -x SM_CHANNELS -x SM_CURRENT_HOST -x SM_CURRENT_INSTANCE_TYPE -x SM_CURRENT_INSTANCE_GROUP -x SM_CURRENT_INSTANCE_GROUP_HOSTS -x SM_INSTANCE_GROUPS -x SM_INSTANCE_GROUPS_DICT -x SM_DISTRIBUTION_INSTANCE_GROUPS -x SM_IS_HETERO -x SM_MODULE_NAME -x SM_LOG_LEVEL -x SM_FRAMEWORK_MODULE -x SM_INPUT_DIR -x SM_INPUT_CONFIG_DIR -x SM_OUTPUT_DIR -x SM_NUM_CPUS -x SM_NUM_GPUS -x SM_NUM_NEURONS -x SM_MODEL_DIR -x SM_MODULE_DIR -x SM_TRAINING_ENV -x SM_USER_ARGS -x SM_OUTPUT_INTERMEDIATE_DIR -x SM_CHANNEL_TEST -x SM_CHANNEL_TRAIN -x SM_CHANNEL_VAL -x SM_HP_DEEPSPEED -x SM_HP_LEARNING_RATE -x SM_HP_NUM_TRAIN_EPOCHS -x SM_HP_TEMPERATURE -x PYTHONPATH /opt/conda/bin/python3.11 -m mpi4py train_sm.py --deepspeed ds_zero3.json --learning_rate 3e-05 --num_train_epochs 3 --temperature 0.05\u001B[0m\n",
      "\u001B[34m2025-07-28 22:37:08,213 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001B[0m\n",
      "\u001B[34m2025-07-28 22:37:08,224 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001B[0m\n",
      "\u001B[34m2025-07-28 22:37:08,224 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001B[0m\n",
      "\u001B[34m2025-07-28 22:37:08,225 sagemaker-training-toolkit INFO     smdistributed.dataparallel not found or using an older version without custom exceptions.SM training toolkit will track user script error only\u001B[0m\n",
      "\u001B[34mData for JOB [41262,1] offset 0 Total slots allocated 4\n",
      " ========================   JOB MAP   ========================\n",
      " Data for node: algo-1#011Num slots: 4#011Max slots: 0#011Num procs: 4\n",
      " #011Process OMPI jobid: [41262,1] App: 0 Process rank: 0 Bound: N/A\n",
      " #011Process OMPI jobid: [41262,1] App: 0 Process rank: 1 Bound: N/A\n",
      " #011Process OMPI jobid: [41262,1] App: 0 Process rank: 2 Bound: N/A\n",
      " #011Process OMPI jobid: [41262,1] App: 0 Process rank: 3 Bound: N/A\n",
      " =============================================================\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:[2025-07-28 22:37:11,616] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:[2025-07-28 22:37:11,619] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:[2025-07-28 22:37:11,623] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:[2025-07-28 22:37:11,624] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:df: /root/.triton/autotune: No such file or directory\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:df: /root/.triton/autotune[1,mpirank:1,algo-1]<stderr>:: No such file or directory\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:[2025-07-28 22:37:13,677] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:[2025-07-28 22:37:13,677] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:[2025-07-28 22:37:13,686] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:[2025-07-28 22:37:13,713] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:/opt/conda/lib/python3.11/site-packages/accelerate/state.py:247: UserWarning: OMP_NUM_THREADS/MKL_NUM_THREADS unset, we set it at 6 to improve oob performance.\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:  warnings.warn(\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:/opt/conda/lib/python3.11/site-packages/accelerate/state.py:247: UserWarning: OMP_NUM_THREADS/MKL_NUM_THREADS unset, we set it at 6 to improve oob performance.\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:  warnings.warn(\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:/opt/conda/lib/python3.11/site-packages/accelerate/state.py:247: UserWarning: OMP_NUM_THREADS/MKL_NUM_THREADS unset, we set it at 6 to improve oob performance.\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:  warnings.warn(\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:/opt/conda/lib/python3.11/site-packages/accelerate/state.py:247: UserWarning: OMP_NUM_THREADS/MKL_NUM_THREADS unset, we set it at 6 to improve oob performance.\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:  warnings.warn(\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Parameter Offload - Persistent parameters statistics: param_count = 184, numel = 66231680\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2033\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1960\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  0%|          | 0/345 [00:00<?, ?it/s]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1606\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2027\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0728 22:37:29.371000 460 site-packages/torch/_dynamo/convert_frame.py:844] [3/8] torch._dynamo hit config.cache_size_limit (8)\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0728 22:37:29.371000 460 site-packages/torch/_dynamo/convert_frame.py:844] [3/8]    function: 'post_sub_module_forward_function' (/opt/conda/lib/python3.11/site-packages/deepspeed/runtime/zero/parameter_offload.py:477)\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0728 22:37:29.371000 460 site-packages/torch/_dynamo/convert_frame.py:844] [3/8]    last reason: 3/0: ___check_type_id(L['sub_module'], 93919270396400)           \u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0728 22:37:29.371000 460 site-packages/torch/_dynamo/convert_frame.py:844] [3/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0728 22:37:29.371000 460 site-packages/torch/_dynamo/convert_frame.py:844] [3/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0728 22:37:29.372000 460 site-packages/torch/_dynamo/convert_frame.py:844] [11/8] torch._dynamo hit config.cache_size_limit (8)\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0728 22:37:29.372000 460 site-packages/torch/_dynamo/convert_frame.py:844] [11/8]    function: '_pre_backward_module_hook' (/opt/conda/lib/python3.11/site-packages/deepspeed/runtime/zero/parameter_offload.py:348)\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0728 22:37:29.372000 460 site-packages/torch/_dynamo/convert_frame.py:844] [11/8]    last reason: 11/0: ___check_type_id(L['module'], 93919270396400)               \u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0728 22:37:29.372000 460 site-packages/torch/_dynamo/convert_frame.py:844] [11/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0728 22:37:29.372000 460 site-packages/torch/_dynamo/convert_frame.py:844] [11/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0728 22:37:29.372000 462 site-packages/torch/_dynamo/convert_frame.py:844] [3/8] torch._dynamo hit config.cache_size_limit (8)\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0728 22:37:29.372000 462 site-packages/torch/_dynamo/convert_frame.py:844] [3/8]    function: 'post_sub_module_forward_function' (/opt/conda/lib/python3.11/site-packages/deepspeed/runtime/zero/parameter_offload.py:477)\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0728 22:37:29.372000 462 site-packages/torch/_dynamo/convert_frame.py:844] [3/8]    last reason: 3/0: ___check_type_id(L['sub_module'], 94619310642000)           \u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0728 22:37:29.372000 462 site-packages/torch/_dynamo/convert_frame.py:844] [3/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0728 22:37:29.372000 462 site-packages/torch/_dynamo/convert_frame.py:844] [3/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0728 22:37:29.373000 462 site-packages/torch/_dynamo/convert_frame.py:844] [11/8] torch._dynamo hit config.cache_size_limit (8)\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0728 22:37:29.373000 462 site-packages/torch/_dynamo/convert_frame.py:844] [11/8]    function: '_pre_backward_module_hook' (/opt/conda/lib/python3.11/site-packages/deepspeed/runtime/zero/parameter_offload.py:348)\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0728 22:37:29.373000 462 site-packages/torch/_dynamo/convert_frame.py:844] [11/8]    last reason: 11/0: ___check_type_id(L['module'], 94619310642000)               \u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0728 22:37:29.373000 462 site-packages/torch/_dynamo/convert_frame.py:844] [11/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0728 22:37:29.373000 462 site-packages/torch/_dynamo/convert_frame.py:844] [11/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0728 22:37:29.375000 463 site-packages/torch/_dynamo/convert_frame.py:844] [3/8] torch._dynamo hit config.cache_size_limit (8)\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0728 22:37:29.375000 463 site-packages/torch/_dynamo/convert_frame.py:844] [3/8]    function: 'post_sub_module_forward_function' (/opt/conda/lib/python3.11/site-packages/deepspeed/runtime/zero/parameter_offload.py:477)\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0728 22:37:29.375000 463 site-packages/torch/_dynamo/convert_frame.py:844] [3/8]    last reason: 3/0: ___check_type_id(L['sub_module'], 94539685704480)           \u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0728 22:37:29.375000 463 site-packages/torch/_dynamo/convert_frame.py:844] [3/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0728 22:37:29.375000 463 site-packages/torch/_dynamo/convert_frame.py:844] [3/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0728 22:37:29.376000 463 site-packages/torch/_dynamo/convert_frame.py:844] [11/8] torch._dynamo hit config.cache_size_limit (8)\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0728 22:37:29.376000 463 site-packages/torch/_dynamo/convert_frame.py:844] [11/8]    function: '_pre_backward_module_hook' (/opt/conda/lib/python3.11/site-packages/deepspeed/runtime/zero/parameter_offload.py:348)\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0728 22:37:29.376000 463 site-packages/torch/_dynamo/convert_frame.py:844] [11/8]    last reason: 11/0: ___check_type_id(L['module'], 94539685704480)               \u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0728 22:37:29.376000 463 site-packages/torch/_dynamo/convert_frame.py:844] [11/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0728 22:37:29.376000 463 site-packages/torch/_dynamo/convert_frame.py:844] [11/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0728 22:37:29.376000 461 site-packages/torch/_dynamo/convert_frame.py:844] [3/8] torch._dynamo hit config.cache_size_limit (8)\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0728 22:37:29.376000 461 site-packages/torch/_dynamo/convert_frame.py:844] [3/8]    function: 'post_sub_module_forward_function' (/opt/conda/lib/python3.11/site-packages/deepspeed/runtime/zero/parameter_offload.py:477)\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0728 22:37:29.376000 461 site-packages/torch/_dynamo/convert_frame.py:844] [3/8]    last reason: 3/0: ___check_type_id(L['sub_module'], 94234965567680)           \u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0728 22:37:29.376000 461 site-packages/torch/_dynamo/convert_frame.py:844] [3/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0728 22:37:29.376000 461 site-packages/torch/_dynamo/convert_frame.py:844] [3/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0728 22:37:29.377000 461 site-packages/torch/_dynamo/convert_frame.py:844] [11/8] torch._dynamo hit config.cache_size_limit (8)\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0728 22:37:29.377000 461 site-packages/torch/_dynamo/convert_frame.py:844] [11/8]    function: '_pre_backward_module_hook' (/opt/conda/lib/python3.11/site-packages/deepspeed/runtime/zero/parameter_offload.py:348)\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0728 22:37:29.377000 461 site-packages/torch/_dynamo/convert_frame.py:844] [11/8]    last reason: 11/0: ___check_type_id(L['module'], 94234965567680)               \u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0728 22:37:29.377000 461 site-packages/torch/_dynamo/convert_frame.py:844] [11/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0728 22:37:29.377000 461 site-packages/torch/_dynamo/convert_frame.py:844] [11/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0728 22:37:30.982000 460 site-packages/torch/_dynamo/convert_frame.py:844] [2/8] torch._dynamo hit config.cache_size_limit (8)\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0728 22:37:30.982000 460 site-packages/torch/_dynamo/convert_frame.py:844] [2/8]    function: '_post_forward_module_hook' (/opt/conda/lib/python3.11/site-packages/deepspeed/runtime/zero/parameter_offload.py:300)\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0728 22:37:30.982000 460 site-packages/torch/_dynamo/convert_frame.py:844] [2/8]    last reason: 2/0: ___check_type_id(L['module'], 93919270396400)               \u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0728 22:37:30.982000 460 site-packages/torch/_dynamo/convert_frame.py:844] [2/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:[rank0]:W0728 22:37:30.982000 460 site-packages/torch/_dynamo/convert_frame.py:844] [2/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0728 22:37:30.984000 461 site-packages/torch/_dynamo/convert_frame.py:844] [2/8] torch._dynamo hit config.cache_size_limit (8)\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0728 22:37:30.984000 461 site-packages/torch/_dynamo/convert_frame.py:844] [2/8]    function: '_post_forward_module_hook' (/opt/conda/lib/python3.11/site-packages/deepspeed/runtime/zero/parameter_offload.py:300)\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0728 22:37:30.984000 461 site-packages/torch/_dynamo/convert_frame.py:844] [2/8]    last reason: 2/0: ___check_type_id(L['module'], 94234965567680)               \u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0728 22:37:30.984000 461 site-packages/torch/_dynamo/convert_frame.py:844] [2/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>:[rank1]:W0728 22:37:30.984000 461 site-packages/torch/_dynamo/convert_frame.py:844] [2/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0728 22:37:30.984000 462 site-packages/torch/_dynamo/convert_frame.py:844] [2/8] torch._dynamo hit config.cache_size_limit (8)\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0728 22:37:30.984000 462 site-packages/torch/_dynamo/convert_frame.py:844] [2/8]    function: '_post_forward_module_hook' (/opt/conda/lib/python3.11/site-packages/deepspeed/runtime/zero/parameter_offload.py:300)\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0728 22:37:30.984000 462 site-packages/torch/_dynamo/convert_frame.py:844] [2/8]    last reason: 2/0: ___check_type_id(L['module'], 94619310642000)               \u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0728 22:37:30.984000 462 site-packages/torch/_dynamo/convert_frame.py:844] [2/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>:[rank2]:W0728 22:37:30.984000 462 site-packages/torch/_dynamo/convert_frame.py:844] [2/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0728 22:37:30.985000 463 site-packages/torch/_dynamo/convert_frame.py:844] [2/8] torch._dynamo hit config.cache_size_limit (8)\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0728 22:37:30.985000 463 site-packages/torch/_dynamo/convert_frame.py:844] [2/8]    function: '_post_forward_module_hook' (/opt/conda/lib/python3.11/site-packages/deepspeed/runtime/zero/parameter_offload.py:300)\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0728 22:37:30.985000 463 site-packages/torch/_dynamo/convert_frame.py:844] [2/8]    last reason: 2/0: ___check_type_id(L['module'], 94539685704480)               \u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0728 22:37:30.985000 463 site-packages/torch/_dynamo/convert_frame.py:844] [2/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>:[rank3]:W0728 22:37:30.985000 463 site-packages/torch/_dynamo/convert_frame.py:844] [2/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device:[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes:[1,mpirank:0,algo-1]<stdout>: torch.Size([32, 768])[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:[1,mpirank:0,algo-1]<stdout>: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1[1,mpirank:1,algo-1]<stdout>: Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  0%|          | 1/345 [00:12<1:11:52, 12.54s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1419\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1384\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2083\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1970\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  1%|          | 2/345 [00:15<39:54,  6.98s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2180\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2355\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1946\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1633\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:2,algo-1]<stdout>: Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: [1,mpirank:3,algo-1]<stdout>:Logits device: [1,mpirank:3,algo-1]<stdout>:cuda:3 [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device:[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  1%|          | 3/345 [00:18<29:39,  5.20s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1884\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1762\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1371\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2030\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device:[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device:[1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 [1,mpirank:2,algo-1]<stdout>: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 [1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  1%|          | 4/345 [00:21<24:56,  4.39s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2104\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2226\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1882\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2496\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: [1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:0,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:[1,mpirank:3,algo-1]<stdout>: cuda:3 Logits_t device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  1%|▏         | 5/345 [00:24<22:09,  3.91s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2356\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2081\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2271\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2008\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1[1,mpirank:1,algo-1]<stdout>: Logits_t device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:[1,mpirank:3,algo-1]<stdout>: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  2%|▏         | 6/345 [00:28<20:46,  3.68s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1970\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1800\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1705\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1578\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 [1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  2%|▏         | 7/345 [00:31<19:35,  3.48s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2615\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2223\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1483\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2133\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: [1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:[1,mpirank:2,algo-1]<stdout>: torch.Size([8])[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3 Logits device:[1,mpirank:3,algo-1]<stdout>: cuda:3[1,mpirank:1,algo-1]<stdout>:Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device:[1,mpirank:3,algo-1]<stdout>: Logits_t device: cuda:3[1,mpirank:0,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: Logits_t device:[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  2%|▏         | 8/345 [00:34<18:56,  3.37s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2012\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1868\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1106\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1897\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:[1,mpirank:3,algo-1]<stdout>: [1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  3%|▎         | 9/345 [00:37<18:28,  3.30s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1804\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2582\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2539\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1777\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 [1,mpirank:1,algo-1]<stdout>:Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  3%|▎         | 10/345 [00:40<18:04,  3.24s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2160\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2218\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1539\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1924\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes:[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  3%|▎         | 11/345 [00:43<17:50,  3.21s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1401\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1699\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2022\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2183\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Pos device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 [1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0 [1,mpirank:3,algo-1]<stdout>:Logits device: cuda:3 Logits_t device: cuda:3[1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 [1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:[1,mpirank:2,algo-1]<stdout>: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device:[1,mpirank:2,algo-1]<stdout>: cuda:2 [1,mpirank:2,algo-1]<stdout>:Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  3%|▎         | 12/345 [00:46<17:43,  3.19s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2100\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2455\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2424\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2905\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0[1,mpirank:0,algo-1]<stdout>: Logits_t device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  4%|▍         | 13/345 [00:49<17:24,  3.15s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2036\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1462\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1588\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2053\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1[1,mpirank:1,algo-1]<stdout>: Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  4%|▍         | 14/345 [00:53<17:22,  3.15s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2400\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2048\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1484\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2255\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 [1,mpirank:2,algo-1]<stdout>:Logits device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device:[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  4%|▍         | 15/345 [00:56<17:18,  3.15s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2460\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1685\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1922\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1440\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device:[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  5%|▍         | 16/345 [00:59<17:11,  3.14s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1592\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 780\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1881\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2305\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: [1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>:cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape:[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 [1,mpirank:3,algo-1]<stdout>:Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: [1,mpirank:3,algo-1]<stdout>:Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes:[1,mpirank:1,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device:[1,mpirank:2,algo-1]<stdout>: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:1,algo-1]<stdout>: cuda:1 [1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2[1,mpirank:1,algo-1]<stdout>:Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits_t device:[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  5%|▍         | 17/345 [01:02<17:04,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1784\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2166\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2186\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1680\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits device: cuda:2 [1,mpirank:2,algo-1]<stdout>:Logits_t device: cuda:2[1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  5%|▌         | 18/345 [01:05<16:56,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1826\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2802\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1783\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2004\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes:[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 [1,mpirank:2,algo-1]<stdout>: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 [1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0 Logits_t device: [1,mpirank:2,algo-1]<stdout>:Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  6%|▌         | 19/345 [01:08<16:47,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2751\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2722\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2083\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2088\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>: Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 32])[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3[1,mpirank:3,algo-1]<stdout>: Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  6%|▌         | 20/345 [01:11<16:50,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1997\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2734\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1442\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2157\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device:[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device:[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 32])[1,mpirank:3,algo-1]<stdout>: [1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  6%|▌         | 21/345 [01:14<16:49,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2383\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1128\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1777\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1581\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device:[1,mpirank:2,algo-1]<stdout>: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits_t device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  6%|▋         | 22/345 [01:17<16:40,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2866\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2213\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2287\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1983\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0[1,mpirank:0,algo-1]<stdout>: Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device:[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device:[1,mpirank:2,algo-1]<stdout>: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: Logits_t device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  7%|▋         | 23/345 [01:21<16:39,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1904\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1934\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2161\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2200\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: [1,mpirank:0,algo-1]<stdout>:cuda:0 [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:2,algo-1]<stdout>:DEBUG shapes:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:2,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  7%|▋         | 24/345 [01:24<16:38,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2610\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2378\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1399\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2032\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: [1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device:[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:0,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:3,algo-1]<stdout>: Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  7%|▋         | 25/345 [01:27<16:30,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1767\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 854\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1756\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1586\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3[1,mpirank:1,algo-1]<stdout>:DEBUG shapes:[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:1,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device:[1,mpirank:1,algo-1]<stdout>: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  8%|▊         | 26/345 [01:30<16:26,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1469\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2383\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2104\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2018\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0[1,mpirank:3,algo-1]<stdout>: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  8%|▊         | 27/345 [01:33<16:24,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1660\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2010\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1658\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1314\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3[1,mpirank:3,algo-1]<stdout>: Logits device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes:[1,mpirank:2,algo-1]<stdout>: torch.Size([32, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>: torch.Size([8, 32]) [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device:[1,mpirank:0,algo-1]<stdout>: cuda:0 [1,mpirank:1,algo-1]<stdout>:Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits_t device:[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  8%|▊         | 28/345 [01:36<16:25,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1712\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2408\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1829\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1679\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device:[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:3,algo-1]<stdout>:Logits device: cuda:3 [1,mpirank:2,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device:[1,mpirank:2,algo-1]<stdout>: cuda:2 [1,mpirank:2,algo-1]<stdout>:Logits_t device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  8%|▊         | 29/345 [01:39<16:30,  3.13s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2125\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1329\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2061\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1061\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device:[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device:[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2[1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits device: [1,mpirank:3,algo-1]<stdout>: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  9%|▊         | 30/345 [01:42<16:22,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2650\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1215\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1774\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1404\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  9%|▉         | 31/345 [01:45<16:19,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1734\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2119\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1674\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1556\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 [1,mpirank:0,algo-1]<stdout>:Logits_t device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  9%|▉         | 32/345 [01:49<16:14,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1738\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1812\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1814\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1936\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device:[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3[1,mpirank:2,algo-1]<stdout>: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 10%|▉         | 33/345 [01:52<16:12,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1776\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1367\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2373\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1831\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits device:[1,mpirank:1,algo-1]<stdout>: cuda:1 Logits_t device:[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 10%|▉         | 34/345 [01:55<16:06,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1626\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2685\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1958\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1932\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:0,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0[1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 10%|█         | 35/345 [01:58<15:55,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2239\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2157\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2490\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1319\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 [1,mpirank:1,algo-1]<stdout>:Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 10%|█         | 36/345 [02:01<15:56,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1796\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1905\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2263\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1600\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device:[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 11%|█         | 37/345 [02:04<15:53,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2365\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2447\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2216\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1625\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes:[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: [1,mpirank:0,algo-1]<stdout>: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device:[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 [1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: [1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: [1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0 Logits_t device:[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 11%|█         | 38/345 [02:07<15:49,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1796\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1836\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2280\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1628\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: [1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: [1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2[1,mpirank:0,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:[1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 11%|█▏        | 39/345 [02:10<15:55,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1823\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1870\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1698\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1140\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3[1,mpirank:1,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: Logits device: cuda:1 Logits_t device:[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device:[1,mpirank:0,algo-1]<stdout>: cuda:0 [1,mpirank:2,algo-1]<stdout>: Logits_t device: [1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 12%|█▏        | 40/345 [02:13<15:55,  3.13s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2136\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2454\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2070\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1812\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 [1,mpirank:2,algo-1]<stdout>:Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 12%|█▏        | 41/345 [02:17<15:52,  3.13s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2089\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1948\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2065\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1947\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device:[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: [1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:cuda:2[1,mpirank:2,algo-1]<stdout>: [1,mpirank:3,algo-1]<stdout>:cuda:3[1,mpirank:2,algo-1]<stdout>:Logits device:[1,mpirank:3,algo-1]<stdout>: Logits device: cuda:3[1,mpirank:2,algo-1]<stdout>: cuda:2 Logits_t device: [1,mpirank:3,algo-1]<stdout>: Logits_t device: cuda:3[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 12%|█▏        | 42/345 [02:20<15:44,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2368\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1882\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2150\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1897\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: [1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0 Logits_t device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 12%|█▏        | 43/345 [02:23<15:44,  3.13s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1844\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1451\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2089\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1940\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])[1,mpirank:1,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:1,algo-1]<stdout>: Logits device: cuda:1 Logits_t device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0[1,mpirank:3,algo-1]<stdout>: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: [1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 13%|█▎        | 44/345 [02:26<15:42,  3.13s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2352\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2032\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1762\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2453\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:cuda:0 [1,mpirank:2,algo-1]<stdout>: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1 Logits_t device: cuda:1[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 13%|█▎        | 45/345 [02:29<15:36,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1740\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1679\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1876\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1193\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 [1,mpirank:0,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: [1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 13%|█▎        | 46/345 [02:32<15:30,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2155\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1892\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2157\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1302\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 [1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device:[1,mpirank:2,algo-1]<stdout>:Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0 Logits_t device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 14%|█▎        | 47/345 [02:35<15:26,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1513\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2583\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1653\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2387\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>: cuda:2 [1,mpirank:2,algo-1]<stdout>:Logits_t device: [1,mpirank:0,algo-1]<stdout>:cuda:0 [1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0 Logits_t device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 14%|█▍        | 48/345 [02:38<15:25,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2191\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1549\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2205\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1780\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 14%|█▍        | 49/345 [02:41<15:16,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2591\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1952\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2091\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2276\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device:[1,mpirank:3,algo-1]<stdout>: [1,mpirank:2,algo-1]<stdout>: cuda:2 Logits_t device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 14%|█▍        | 50/345 [02:45<15:17,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1753\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1632\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1817\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1974\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 [1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1 Logits_t device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 15%|█▍        | 51/345 [02:48<15:16,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1883\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1958\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2394\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1876\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1[1,mpirank:1,algo-1]<stdout>: Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device:[1,mpirank:2,algo-1]<stdout>: [1,mpirank:2,algo-1]<stdout>:cuda:2 [1,mpirank:2,algo-1]<stdout>:Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 15%|█▌        | 52/345 [02:51<15:12,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1753\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1915\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2047\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2102\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device:[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 [1,mpirank:2,algo-1]<stdout>:Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 32]) [1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 15%|█▌        | 53/345 [02:54<15:10,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2504\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2432\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1633\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2224\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device:[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:1,algo-1]<stdout>: Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2[1,mpirank:2,algo-1]<stdout>: Logits device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device:[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 16%|█▌        | 54/345 [02:57<15:02,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1993\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2144\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2594\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1700\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:1,algo-1]<stdout>:Logits_t device: [1,mpirank:2,algo-1]<stdout>: Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3[1,mpirank:0,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>: Logits device: cuda:3 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0[1,mpirank:3,algo-1]<stdout>: cuda:3[1,mpirank:0,algo-1]<stdout>: Logits device:[1,mpirank:0,algo-1]<stdout>: [1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device:[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 16%|█▌        | 55/345 [03:00<15:01,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1782\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2459\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1955\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1966\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device:[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Pos device:[1,mpirank:3,algo-1]<stdout>: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 16%|█▌        | 56/345 [03:03<14:57,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1550\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1452\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2422\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1724\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:1,algo-1]<stdout>: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2[1,mpirank:3,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: [1,mpirank:2,algo-1]<stdout>: Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 17%|█▋        | 57/345 [03:06<14:50,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1821\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1690\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1578\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1636\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 17%|█▋        | 58/345 [03:09<14:48,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1979\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2162\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2544\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2238\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 [1,mpirank:3,algo-1]<stdout>:Pos device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3[1,mpirank:1,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0[1,mpirank:0,algo-1]<stdout>: Logits_t device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 17%|█▋        | 59/345 [03:12<14:48,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1805\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1869\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1600\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1953\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 [1,mpirank:3,algo-1]<stdout>:Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device:[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 17%|█▋        | 60/345 [03:16<14:42,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1659\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1989\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2293\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2243\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1[1,mpirank:3,algo-1]<stdout>: cuda:3 [1,mpirank:3,algo-1]<stdout>:Logits_t device: [1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0 [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0[1,mpirank:0,algo-1]<stdout>: Logits_t device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 18%|█▊        | 61/345 [03:19<14:35,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1970\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2109\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2080\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1508\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device:[1,mpirank:1,algo-1]<stdout>: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0 Logits_t device:[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1[1,mpirank:1,algo-1]<stdout>: Logits_t device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 18%|█▊        | 62/345 [03:22<14:31,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1795\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1630\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2092\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1415\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device:[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2[1,mpirank:2,algo-1]<stdout>: Logits device: cuda:2[1,mpirank:1,algo-1]<stdout>:Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 18%|█▊        | 63/345 [03:25<14:28,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1172\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1524\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2019\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2230\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device:[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>: cuda:2[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 19%|█▊        | 64/345 [03:28<14:30,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2202\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1935\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2370\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2048\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 19%|█▉        | 65/345 [03:31<14:29,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1767\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2071\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1770\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2529\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1[1,mpirank:1,algo-1]<stdout>: Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 [1,mpirank:2,algo-1]<stdout>:Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: cuda:2 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 [1,mpirank:1,algo-1]<stdout>:Logits_t device:[1,mpirank:0,algo-1]<stdout>: [1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 [1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 19%|█▉        | 66/345 [03:34<14:27,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1182\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1798\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2188\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2499\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 [1,mpirank:0,algo-1]<stdout>:Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits device: cuda:3 Logits_t device:[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device:[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:0,algo-1]<stdout>: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 19%|█▉        | 67/345 [03:37<14:26,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1932\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1807\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2015\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2035\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 [1,mpirank:0,algo-1]<stdout>:Pos device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits device: cuda:2 Logits_t device: cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 20%|█▉        | 68/345 [03:40<14:24,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1568\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1639\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2189\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1719\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: cuda:2 Logits device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device:[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 20%|██        | 69/345 [03:44<14:21,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1829\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1675\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1736\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1665\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 20%|██        | 70/345 [03:47<14:17,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1832\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1705\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2111\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2148\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device:[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0[1,mpirank:3,algo-1]<stdout>: Logits_t device: [1,mpirank:0,algo-1]<stdout>: Logits_t device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 21%|██        | 71/345 [03:50<14:12,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1843\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2370\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2110\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1992\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes:[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: [1,mpirank:2,algo-1]<stdout>: torch.Size([32, 768]) [1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 21%|██        | 72/345 [03:53<14:09,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2469\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2800\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1471\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1852\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes:[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0 [1,mpirank:3,algo-1]<stdout>:DEBUG shapes:[1,mpirank:2,algo-1]<stdout>: torch.Size([32, 768]) [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device:[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 21%|██        | 73/345 [03:56<14:05,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2102\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1468\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1560\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2604\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:1,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2[1,mpirank:1,algo-1]<stdout>:cuda:1 [1,mpirank:3,algo-1]<stdout>:DEBUG shapes:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:1,algo-1]<stdout>:Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 21%|██▏       | 74/345 [03:59<14:02,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1818\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1457\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1683\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1354\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 [1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 22%|██▏       | 75/345 [04:02<14:00,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1566\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2042\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1941\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2054\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 [1,mpirank:2,algo-1]<stdout>:Logits_t device: [1,mpirank:3,algo-1]<stdout>: Logits_t device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 22%|██▏       | 76/345 [04:05<14:00,  3.13s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2305\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1628\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2124\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1320\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device:[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device:[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 22%|██▏       | 77/345 [04:08<14:00,  3.14s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2132\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1874\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1817\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1655\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:[1,mpirank:0,algo-1]<stdout>: cuda:0 Logits device: cuda:0[1,mpirank:0,algo-1]<stdout>: Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:[1,mpirank:3,algo-1]<stdout>: [1,mpirank:1,algo-1]<stdout>:torch.Size([32, 768]) [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 32]) [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3[1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 [1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1 Logits_t device:[1,mpirank:2,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2[1,mpirank:2,algo-1]<stdout>: Logits_t device: [1,mpirank:3,algo-1]<stdout>: Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 23%|██▎       | 78/345 [04:12<14:14,  3.20s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2160\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1755\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1856\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1523\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 [1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 23%|██▎       | 79/345 [04:15<14:05,  3.18s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1593\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2134\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2454\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1438\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2[1,mpirank:1,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 23%|██▎       | 80/345 [04:18<13:55,  3.15s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1415\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2418\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2122\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1882\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device:[1,mpirank:1,algo-1]<stdout>: Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:1,algo-1]<stdout>: Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 23%|██▎       | 81/345 [04:21<13:50,  3.14s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1898\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2604\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2519\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2361\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits_t device: [1,mpirank:0,algo-1]<stdout>: [1,mpirank:2,algo-1]<stdout>:cuda:2[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 24%|██▍       | 82/345 [04:24<13:39,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1751\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2354\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2121\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1967\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: cuda:2 [1,mpirank:3,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 24%|██▍       | 83/345 [04:27<13:37,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2177\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1392\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2032\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1766\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: [1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 [1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: [1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2 Logits_t device:[1,mpirank:2,algo-1]<stdout>: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 24%|██▍       | 84/345 [04:31<13:35,  3.13s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2082\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2463\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1475\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1762\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 25%|██▍       | 85/345 [04:34<13:31,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2131\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2074\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1773\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1371\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device:[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits_t device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:[1,mpirank:3,algo-1]<stdout>: cuda:3[1,mpirank:3,algo-1]<stdout>: Logits_t device: [1,mpirank:3,algo-1]<stdout>:cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 25%|██▍       | 86/345 [04:37<13:21,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2369\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2021[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1104\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1338\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: [1,mpirank:3,algo-1]<stdout>:cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0 [1,mpirank:1,algo-1]<stdout>: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: [1,mpirank:2,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: [1,mpirank:2,algo-1]<stdout>:Logits device: [1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 25%|██▌       | 87/345 [04:40<13:19,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1636\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1876\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1398\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1605\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2[1,mpirank:2,algo-1]<stdout>: Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: [1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 26%|██▌       | 88/345 [04:43<13:22,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2146\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1726\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2048\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2092\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0 Logits_t device: cuda:0[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:3,algo-1]<stdout>: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 26%|██▌       | 89/345 [04:46<13:19,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1907\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2576\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1755\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2428\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 26%|██▌       | 90/345 [04:49<13:12,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1590\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1408\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1572\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1301\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 26%|██▋       | 91/345 [04:52<13:09,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1387\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2422\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1970\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 946\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:[1,mpirank:3,algo-1]<stdout>: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0 [1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0 [1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 27%|██▋       | 92/345 [04:55<13:10,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2333\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1490\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2336\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1670\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 [1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: Logits_t device:[1,mpirank:3,algo-1]<stdout>: [1,mpirank:3,algo-1]<stdout>:cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 27%|██▋       | 93/345 [04:59<13:09,  3.13s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2792\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2399\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1345\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1729\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:2,algo-1]<stdout>:Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device:[1,mpirank:3,algo-1]<stdout>: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 27%|██▋       | 94/345 [05:02<13:11,  3.15s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1696\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1943\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1973\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2054\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: [1,mpirank:2,algo-1]<stdout>:cuda:2[1,mpirank:2,algo-1]<stdout>: [1,mpirank:2,algo-1]<stdout>:Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: [1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device:[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 28%|██▊       | 95/345 [05:05<13:09,  3.16s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1829\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2062\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1738\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1496\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: cuda:2 [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:[1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 [1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 28%|██▊       | 96/345 [05:08<13:07,  3.16s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1674\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2274\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1873\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2281\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1 [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: [1,mpirank:2,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:3,algo-1]<stdout>: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: [1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 28%|██▊       | 97/345 [05:11<13:01,  3.15s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1865\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1637\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2197\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1697\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 28%|██▊       | 98/345 [05:14<12:54,  3.14s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1619\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1588\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2091\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2249\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: [1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 [1,mpirank:1,algo-1]<stdout>:Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0 Logits_t device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 29%|██▊       | 99/345 [05:17<12:47,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2040\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2636\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1539\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2239\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: Logits device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: [1,mpirank:2,algo-1]<stdout>: torch.Size([8, 32])[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: [1,mpirank:1,algo-1]<stdout>:cuda:1 [1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768])[1,mpirank:2,algo-1]<stdout>: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits_t device: cuda:1[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: [1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device:[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 29%|██▉       | 100/345 [05:21<12:44,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:{'loss': 2.8942, 'grad_norm': 9.2515821277898, 'learning_rate': 2.1391304347826088e-05, 'epoch': 0.87}\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 29%|██▉       | 100/345 [05:21<12:44,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2276\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2150\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2621\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1514\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 [1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device:[1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 29%|██▉       | 101/345 [05:24<12:37,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2587\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1440\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2442\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1635\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 30%|██▉       | 102/345 [05:27<12:31,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1869\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1936\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2673\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1705\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: [1,mpirank:1,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0 [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: [1,mpirank:0,algo-1]<stdout>:Logits device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: [1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 30%|██▉       | 103/345 [05:30<12:29,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1761\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2334\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1682\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2415\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2[1,mpirank:2,algo-1]<stdout>: Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:[1,mpirank:1,algo-1]<stdout>: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device:[1,mpirank:1,algo-1]<stdout>: cuda:1 [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:1,algo-1]<stdout>:Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: [1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 30%|███       | 104/345 [05:33<12:28,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1441\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2177\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1577\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1581\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:1,algo-1]<stdout>: Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 30%|███       | 105/345 [05:36<12:29,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1536\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1834\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1222\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1730\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0[1,mpirank:3,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 31%|███       | 106/345 [05:39<12:20,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2121\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2170\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1425\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2114\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 31%|███       | 107/345 [05:42<12:18,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2171\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1842\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2188\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1648\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 [1,mpirank:0,algo-1]<stdout>: Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2 [1,mpirank:3,algo-1]<stdout>: Logits_t device: cuda:3[1,mpirank:2,algo-1]<stdout>:Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 31%|███▏      | 108/345 [05:46<12:31,  3.17s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1807\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1318\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1161\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2766\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: [1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1 Logits_t device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 32%|███▏      | 109/345 [05:49<12:21,  3.14s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2157\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1540\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2569\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1677\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 [1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: [1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 32%|███▏      | 110/345 [05:52<12:15,  3.13s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2585\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2029\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1821\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1632\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0[1,mpirank:1,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: [1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 32%|███▏      | 111/345 [05:55<12:09,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2237\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1186\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2111\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1449\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 [1,mpirank:2,algo-1]<stdout>:DEBUG shapes:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2[1,mpirank:3,algo-1]<stdout>:Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 32%|███▏      | 112/345 [05:58<12:02,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1405\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1920\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2322\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1850\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1 [1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:0,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: [1,mpirank:1,algo-1]<stdout>:Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 33%|███▎      | 113/345 [06:01<12:07,  3.14s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2169\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1385\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2004\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1898\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 [1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Pos device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:1,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device:[1,mpirank:2,algo-1]<stdout>: cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 33%|███▎      | 114/345 [06:04<11:58,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1875\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1626\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1714\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2377\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 [1,mpirank:1,algo-1]<stdout>: Logits_t device: [1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:Logits device: cuda:3[1,mpirank:2,algo-1]<stdout>:cuda:2[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits device: cuda:2 Logits_t device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 33%|███▎      | 115/345 [06:07<11:48,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  0%|          | 0/15 [00:00<?, ?it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 13%|█▎        | 2/15 [00:00<00:01,  7.64it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 20%|██        | 3/15 [00:00<00:02,  5.66it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 27%|██▋       | 4/15 [00:00<00:02,  4.61it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 33%|███▎      | 5/15 [00:00<00:02,  4.94it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 40%|████      | 6/15 [00:01<00:01,  5.04it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 47%|████▋     | 7/15 [00:01<00:01,  5.24it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 60%|██████    | 9/15 [00:01<00:00,  7.50it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 80%|████████  | 12/15 [00:01<00:00,  9.50it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 87%|████████▋ | 13/15 [00:01<00:00,  7.97it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 93%|█████████▎| 14/15 [00:02<00:00,  7.37it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015                                                 #015\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015                                               #015#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:{'eval_runtime': 2.6316, 'eval_samples_per_second': 183.54, 'eval_steps_per_second': 6.08, 'epoch': 1.0}\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 33%|███▎      | 115/345 [06:10<11:48,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 15/15 [00:02<00:00,  7.37it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015                                               #033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>: stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>: stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>: stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>: stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2124\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2302\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2033\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2028\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:2,algo-1]<stdout>:Labels device:[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>: cuda:2 Logits device: cuda:2 [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 34%|███▎      | 116/345 [06:19<22:00,  5.77s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2370\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2299\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1918\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1933\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 34%|███▍      | 117/345 [06:22<18:50,  4.96s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1877\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1242\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1801\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2285\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:cuda:3[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:3,algo-1]<stdout>: Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0[1,mpirank:0,algo-1]<stdout>: Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 34%|███▍      | 118/345 [06:25<16:38,  4.40s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2084\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2081\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1789\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1477\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: Pos device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 [1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: [1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 34%|███▍      | 119/345 [06:28<15:04,  4.00s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1463\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1750\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1626\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1736\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 [1,mpirank:3,algo-1]<stdout>:Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device:[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device:[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 [1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1[1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 35%|███▍      | 120/345 [06:31<13:55,  3.71s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1459\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1893\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1662\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1666\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:0,algo-1]<stdout>:DEBUG shapes:[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>: torch.Size([32, 768]) [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: Logits device: [1,mpirank:0,algo-1]<stdout>:cuda:0[1,mpirank:0,algo-1]<stdout>: Logits_t device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 35%|███▌      | 121/345 [06:34<13:05,  3.51s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2193\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2392\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1893\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1942\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1[1,mpirank:1,algo-1]<stdout>: Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:3,algo-1]<stdout>:DEBUG shapes:[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: torch.Size([32, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 35%|███▌      | 122/345 [06:38<12:35,  3.39s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2010\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1826\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1557\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2308\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 [1,mpirank:0,algo-1]<stdout>: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits_t device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 36%|███▌      | 123/345 [06:41<12:12,  3.30s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2405\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1911\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1548\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2032\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 36%|███▌      | 124/345 [06:44<11:53,  3.23s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1762\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1917\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1100\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2406\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>: Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0[1,mpirank:0,algo-1]<stdout>: Pos device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: [1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: [1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 36%|███▌      | 125/345 [06:47<11:37,  3.17s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2714\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1449\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2722\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2002\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0[1,mpirank:0,algo-1]<stdout>: Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 37%|███▋      | 126/345 [06:50<11:29,  3.15s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1936\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1976\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2007\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2141\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:[1,mpirank:1,algo-1]<stdout>: [1,mpirank:2,algo-1]<stdout>: [1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 37%|███▋      | 127/345 [06:53<11:19,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1804\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1849\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1936\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1479\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device:[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: [1,mpirank:0,algo-1]<stdout>: [1,mpirank:1,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 37%|███▋      | 128/345 [06:56<11:12,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1978\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1951\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2041\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2055\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 32]) [1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device:[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 37%|███▋      | 129/345 [06:59<11:02,  3.07s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1614\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2245\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1620\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1766\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 [1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: [1,mpirank:0,algo-1]<stdout>: Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1 [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits_t device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 38%|███▊      | 130/345 [07:02<10:58,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1704\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1569\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2235\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2492\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 38%|███▊      | 131/345 [07:05<10:54,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1671\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1872\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1938\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1843\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 38%|███▊      | 132/345 [07:08<10:45,  3.03s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2428\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1888\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1972\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1959\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device:[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 39%|███▊      | 133/345 [07:11<10:46,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2154\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1827\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1880\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2185\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 [1,mpirank:2,algo-1]<stdout>:Logits_t device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1[1,mpirank:1,algo-1]<stdout>: Logits device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 39%|███▉      | 134/345 [07:14<10:40,  3.04s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1413\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1977\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2191\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1771\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 [1,mpirank:2,algo-1]<stdout>: [1,mpirank:0,algo-1]<stdout>:Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 39%|███▉      | 135/345 [07:17<10:38,  3.04s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2107\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1480\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1795\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1927\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: [1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:2,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 [1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 39%|███▉      | 136/345 [07:20<10:39,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1892\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1514\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1218\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2140\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 [1,mpirank:2,algo-1]<stdout>:Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 [1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits device: cuda:3[1,mpirank:3,algo-1]<stdout>: Logits_t device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 40%|███▉      | 137/345 [07:23<10:35,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2289\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2103\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1260\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1164\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device:[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device:[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device:[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:1,algo-1]<stdout>: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:[1,mpirank:0,algo-1]<stdout>: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device:[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 40%|████      | 138/345 [07:26<10:29,  3.04s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1609\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2470\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1792\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1504\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device:[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 40%|████      | 139/345 [07:29<10:28,  3.05s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2282\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2068\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2132\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2053\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device:[1,mpirank:0,algo-1]<stdout>: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 41%|████      | 140/345 [07:33<10:28,  3.07s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2490\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2031\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1253\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1596\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:[1,mpirank:1,algo-1]<stdout>: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: [1,mpirank:3,algo-1]<stdout>: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device:[1,mpirank:0,algo-1]<stdout>: cuda:0[1,mpirank:0,algo-1]<stdout>: Logits_t device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 41%|████      | 141/345 [07:36<10:24,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1937\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2138\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1068\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2083\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits device: cuda:3 [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 32]) [1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:2,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:1,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 41%|████      | 142/345 [07:39<10:25,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2196\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2524\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1783\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1420\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device:[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 41%|████▏     | 143/345 [07:42<10:21,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2225\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1993\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1965\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1779\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device:[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 42%|████▏     | 144/345 [07:45<10:19,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1550\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2820\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1829\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2121\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: Logits_t device:[1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device:[1,mpirank:2,algo-1]<stdout>: cuda:2 Logits_t device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 42%|████▏     | 145/345 [07:48<10:17,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1386\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1848\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2738\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1361\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 [1,mpirank:1,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 42%|████▏     | 146/345 [07:51<10:12,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2004\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1800\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2211\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2283\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1[1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: Logits_t device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 43%|████▎     | 147/345 [07:54<10:08,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2131\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1946\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2148\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1990\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device:[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device:[1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1[1,mpirank:0,algo-1]<stdout>: [1,mpirank:1,algo-1]<stdout>: Logits_t device:[1,mpirank:0,algo-1]<stdout>:cuda:0 [1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 43%|████▎     | 148/345 [07:57<10:05,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1691\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2216\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1735\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2386\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device:[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: [1,mpirank:0,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 43%|████▎     | 149/345 [08:00<10:08,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2634\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1415\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2348\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2192\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 [1,mpirank:1,algo-1]<stdout>:cuda:1 [1,mpirank:1,algo-1]<stdout>:Logits device: [1,mpirank:0,algo-1]<stdout>:Logits device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 43%|████▎     | 150/345 [08:03<10:04,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2121\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1214\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2530\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2602\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:0,algo-1]<stdout>: [1,mpirank:3,algo-1]<stdout>: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 [1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits_t device:[1,mpirank:0,algo-1]<stdout>: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 44%|████▍     | 151/345 [08:07<10:02,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1708\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1558\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1719\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1763\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 [1,mpirank:3,algo-1]<stdout>:Logits_t device:[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device:[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: [1,mpirank:0,algo-1]<stdout>: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 44%|████▍     | 152/345 [08:10<09:57,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2294\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2127\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1843\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2132\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 [1,mpirank:2,algo-1]<stdout>:Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0[1,mpirank:0,algo-1]<stdout>: Pos device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:[1,mpirank:3,algo-1]<stdout>:DEBUG shapes:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:[1,mpirank:1,algo-1]<stdout>: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0 Logits device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 44%|████▍     | 153/345 [08:13<09:49,  3.07s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2719\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1820\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1921\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2386\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device:[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 45%|████▍     | 154/345 [08:16<09:47,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2064\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1603\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2072\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2924\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1[1,mpirank:1,algo-1]<stdout>: Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 45%|████▍     | 155/345 [08:19<09:49,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2401\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2026\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1463\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2405\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: [1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device:[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 45%|████▌     | 156/345 [08:22<09:46,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1725\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1748\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1586\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2285\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1[1,mpirank:1,algo-1]<stdout>: Logits device: cuda:1 Logits_t device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 [1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2 Logits_t device:[1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device:[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device:[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 46%|████▌     | 157/345 [08:25<09:40,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1838\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1946\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1679\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1040\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes:[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2[1,mpirank:1,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1[1,mpirank:2,algo-1]<stdout>: Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: Logits device: cuda:3 Logits_t device: [1,mpirank:1,algo-1]<stdout>: Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 46%|████▌     | 158/345 [08:28<09:40,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1788\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1897\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1802\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1730\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device:[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 [1,mpirank:1,algo-1]<stdout>:Pos device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 32]) [1,mpirank:1,algo-1]<stdout>: cuda:1 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1[1,mpirank:0,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: [1,mpirank:1,algo-1]<stdout>: Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:[1,mpirank:3,algo-1]<stdout>: cuda:3[1,mpirank:3,algo-1]<stdout>: Logits device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 46%|████▌     | 159/345 [08:31<09:37,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1353\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2190\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2137\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 986\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device:[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0[1,mpirank:0,algo-1]<stdout>: Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 46%|████▋     | 160/345 [08:34<09:33,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2540\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1908\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1600\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2047\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3 Logits device: cuda:3 Logits_t device: [1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device:[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:0,algo-1]<stdout>: cuda:0 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 [1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 47%|████▋     | 161/345 [08:38<09:33,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1806\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1981\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2201\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2311\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device:[1,mpirank:2,algo-1]<stdout>: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 47%|████▋     | 162/345 [08:41<09:26,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2099\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1884\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2072\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1783\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 47%|████▋     | 163/345 [08:44<09:20,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1834\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2143\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2157\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2721\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 48%|████▊     | 164/345 [08:47<09:19,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2370\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2306\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2295\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2340\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 [1,mpirank:1,algo-1]<stdout>:Logits_t device:[1,mpirank:1,algo-1]<stdout>: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 48%|████▊     | 165/345 [08:50<09:22,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2068\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1546\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2053\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1649\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 48%|████▊     | 166/345 [08:53<09:15,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2430\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1516\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2107\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2291\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1 Logits device: cuda:1 Logits_t device:[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 48%|████▊     | 167/345 [08:56<09:17,  3.13s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1629\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2230\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1592\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1480\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device:[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:2,algo-1]<stdout>:cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 49%|████▊     | 168/345 [08:59<09:08,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2204\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2043\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2543\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2175\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device:[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 [1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 49%|████▉     | 169/345 [09:02<09:06,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1265\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1953\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2015\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2000\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:[1,mpirank:2,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device:[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 49%|████▉     | 170/345 [09:05<09:04,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2155\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2035\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1965\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1904\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device:[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 50%|████▉     | 171/345 [09:09<09:02,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1759\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1857\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1763\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2045\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0[1,mpirank:2,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: Logits_t device: [1,mpirank:3,algo-1]<stdout>: cuda:3 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 50%|████▉     | 172/345 [09:12<09:00,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2430\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1167\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1848\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1794\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: [1,mpirank:0,algo-1]<stdout>:Logits device: [1,mpirank:2,algo-1]<stdout>:Logits device: [1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device:[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device:[1,mpirank:1,algo-1]<stdout>: cuda:1 Logits_t device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 50%|█████     | 173/345 [09:15<08:56,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2106\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1942\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1879\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2042\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device:[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device:[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 50%|█████     | 174/345 [09:18<08:54,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1685\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1692\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1663\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1354\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:3,algo-1]<stdout>: Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: [1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:torch.Size([32, 768])[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 51%|█████     | 175/345 [09:21<08:49,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2556\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2671\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2037\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1815\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device:[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: Logits device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 51%|█████     | 176/345 [09:24<08:42,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1429\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2482\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1615\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2341\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device:[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0 Pos device:[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 [1,mpirank:2,algo-1]<stdout>:Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device:[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device:[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 51%|█████▏    | 177/345 [09:27<08:37,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2138\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2423\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2081\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2546\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:2,algo-1]<stdout>: [1,mpirank:1,algo-1]<stdout>: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device:[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device:[1,mpirank:2,algo-1]<stdout>: [1,mpirank:1,algo-1]<stdout>: cuda:1 [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device:[1,mpirank:1,algo-1]<stdout>:Logits_t device:[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 52%|█████▏    | 178/345 [09:30<08:36,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1700\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1745\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2176\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2763\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:0,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 52%|█████▏    | 179/345 [09:33<08:32,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2025\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1747\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1849\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1813\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:[1,mpirank:3,algo-1]<stdout>: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 52%|█████▏    | 180/345 [09:36<08:31,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1743\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2025\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2103\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1900\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2[1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 52%|█████▏    | 181/345 [09:40<08:30,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2149\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2192\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1659\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2103\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device:[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 53%|█████▎    | 182/345 [09:43<08:25,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1786\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1756\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1652\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2271\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits_t device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 53%|█████▎    | 183/345 [09:46<08:21,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2094\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2385\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2053\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2245\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 53%|█████▎    | 184/345 [09:49<08:16,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1706\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1166\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1290\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2518\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 [1,mpirank:0,algo-1]<stdout>:Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:[1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: [1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: [1,mpirank:3,algo-1]<stdout>:cuda:3[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: [1,mpirank:3,algo-1]<stdout>: Logits device: cuda:3 [1,mpirank:2,algo-1]<stdout>:torch.Size([32, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 54%|█████▎    | 185/345 [09:52<08:14,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1727\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2140\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1128\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2206\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device:[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2[1,mpirank:2,algo-1]<stdout>: Logits device: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 32])[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 [1,mpirank:1,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 54%|█████▍    | 186/345 [09:55<08:11,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1663\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2191\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1547\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1438\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device:[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:[1,mpirank:0,algo-1]<stdout>: cuda:0 [1,mpirank:2,algo-1]<stdout>: Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 54%|█████▍    | 187/345 [09:58<08:18,  3.15s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2082\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2042\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1947\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1561\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3[1,mpirank:2,algo-1]<stdout>: Logits_t device: cuda:2[1,mpirank:3,algo-1]<stdout>: Logits device: cuda:3 Logits_t device:[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 54%|█████▍    | 188/345 [10:01<08:12,  3.14s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1649\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1979\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1533\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2205\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device:[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0 Pos device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 55%|█████▍    | 189/345 [10:05<08:07,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2385\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1886\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1223\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1881\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device:[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 [1,mpirank:1,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 55%|█████▌    | 190/345 [10:08<08:03,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1404\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1966\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2047\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2315\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:0,algo-1]<stdout>:Logits device:[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 55%|█████▌    | 191/345 [10:11<07:59,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1315\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1898\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1520\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1663\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device:[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3 [1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 56%|█████▌    | 192/345 [10:14<07:55,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2649\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1609\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2045\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1749\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: [1,mpirank:2,algo-1]<stdout>:Logits_t device: cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 56%|█████▌    | 193/345 [10:17<07:49,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1415\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2034\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2217\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1691\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1 Logits device: [1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: [1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0[1,mpirank:0,algo-1]<stdout>: Logits_t device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 56%|█████▌    | 194/345 [10:20<07:47,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1663\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1446\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1424\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1260\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device:[1,mpirank:3,algo-1]<stdout>:DEBUG shapes:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:0,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 [1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])[1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0 Logits_t device:[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 57%|█████▋    | 195/345 [10:23<07:42,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1198\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2033\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2153\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2046\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2[1,mpirank:2,algo-1]<stdout>: Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:0,algo-1]<stdout>: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: [1,mpirank:3,algo-1]<stdout>:Logits device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 57%|█████▋    | 196/345 [10:26<07:38,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1520\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2062\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1753\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2149\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: [1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 57%|█████▋    | 197/345 [10:29<07:36,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1951\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2252\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1829\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2384\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 [1,mpirank:2,algo-1]<stdout>: cuda:2[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:1,algo-1]<stdout>: [1,mpirank:0,algo-1]<stdout>:Logits_t device: [1,mpirank:2,algo-1]<stdout>: Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: Logits device: cuda:1[1,mpirank:1,algo-1]<stdout>: Logits_t device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 57%|█████▋    | 198/345 [10:32<07:33,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2118\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2045\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1676\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2165\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 58%|█████▊    | 199/345 [10:35<07:29,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1360\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2285\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2450\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1454\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 58%|█████▊    | 200/345 [10:38<07:24,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015                                                 #015[1,mpirank:0,algo-1]<stderr>:#015 58%|█████▊    | 200/345 [10:38<07:24,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:{'loss': 1.3139, 'grad_norm': 7.632816676771298, 'learning_rate': 1.2695652173913043e-05, 'epoch': 1.74}\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2261\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2008\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1547\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2112\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: [1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:3,algo-1]<stdout>: Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:2,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0[1,mpirank:2,algo-1]<stdout>: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: [1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2[1,mpirank:2,algo-1]<stdout>: Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 58%|█████▊    | 201/345 [10:41<07:22,  3.07s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1942\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2112\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2168\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1775\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device:[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes:[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 [1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device:[1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device:[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 59%|█████▊    | 202/345 [10:44<07:16,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1343\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1743\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1988\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1458\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0 Logits device: cuda:0 Logits_t device:[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 59%|█████▉    | 203/345 [10:48<07:14,  3.06s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1588\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1718\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1964\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1618\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0[1,mpirank:3,algo-1]<stdout>: Logits_t device: cuda:3[1,mpirank:0,algo-1]<stdout>: Logits_t device: [1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 59%|█████▉    | 204/345 [10:51<07:13,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1979\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1302\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2152\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1988\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 59%|█████▉    | 205/345 [10:54<07:11,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1512\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2553\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1440\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1421\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2[1,mpirank:3,algo-1]<stdout>:Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0 [1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 [1,mpirank:1,algo-1]<stdout>:Logits device:[1,mpirank:1,algo-1]<stdout>: cuda:1 Logits_t device:[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 60%|█████▉    | 206/345 [10:57<07:08,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2149\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2185\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2190\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1870\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2[1,mpirank:2,algo-1]<stdout>: Logits device: cuda:2 Logits_t device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 60%|██████    | 207/345 [11:00<07:04,  3.07s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2189\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1873\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2297\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2648\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: [1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes:[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:3,algo-1]<stdout>: torch.Size([32, 768])[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 32]) [1,mpirank:3,algo-1]<stdout>: torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 60%|██████    | 208/345 [11:03<07:02,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1413\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2044\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1980\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1830\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: Logits device: cuda:1 [1,mpirank:1,algo-1]<stdout>:Logits_t device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 61%|██████    | 209/345 [11:06<06:59,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1258\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2194\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1550\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1713\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:0,algo-1]<stdout>:cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1[1,mpirank:3,algo-1]<stdout>: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1 Logits_t device:[1,mpirank:1,algo-1]<stdout>: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 61%|██████    | 210/345 [11:09<06:59,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1607\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2151\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2466\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2103\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device:[1,mpirank:0,algo-1]<stdout>: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1[1,mpirank:1,algo-1]<stdout>: Pos device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device:[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device:[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 [1,mpirank:1,algo-1]<stdout>: Logits_t device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits device: cuda:3[1,mpirank:3,algo-1]<stdout>: Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 61%|██████    | 211/345 [11:12<06:54,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2103\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1560\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1352\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1694\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:1,algo-1]<stdout>: cuda:1 Logits device: cuda:1 [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: [1,mpirank:3,algo-1]<stdout>: cuda:3 Logits_t device:[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 61%|██████▏   | 212/345 [11:15<06:52,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2004\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1370\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1935\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2443\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device:[1,mpirank:3,algo-1]<stdout>: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: [1,mpirank:3,algo-1]<stdout>:Logits device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:2,algo-1]<stdout>: Logits device: cuda:2 Logits_t device: [1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 [1,mpirank:0,algo-1]<stdout>:Logits_t device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 62%|██████▏   | 213/345 [11:19<06:49,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1889\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1703\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2060\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1427\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2[1,mpirank:2,algo-1]<stdout>: Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device:[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 [1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device:[1,mpirank:1,algo-1]<stdout>:Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:[1,mpirank:0,algo-1]<stdout>: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 62%|██████▏   | 214/345 [11:22<06:54,  3.16s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2273\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1760\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2891\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1986\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3[1,mpirank:3,algo-1]<stdout>: Pos device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:2,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:3,algo-1]<stdout>: Logits device: cuda:3 Logits_t device: [1,mpirank:0,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 62%|██████▏   | 215/345 [11:25<06:48,  3.14s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1988\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1830\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1304\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2113\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2[1,mpirank:2,algo-1]<stdout>: Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 [1,mpirank:1,algo-1]<stdout>:Logits_t device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3[1,mpirank:3,algo-1]<stdout>: Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 63%|██████▎   | 216/345 [11:28<06:43,  3.13s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1870\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1848\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2379\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1570\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device:[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:0,algo-1]<stdout>: Logits_t device: cuda:0[1,mpirank:1,algo-1]<stdout>:Logits device: [1,mpirank:3,algo-1]<stdout>: Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 [1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 63%|██████▎   | 217/345 [11:31<06:39,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2031\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1950\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1995\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2145\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:[1,mpirank:3,algo-1]<stdout>: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 63%|██████▎   | 218/345 [11:34<06:34,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1627\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1962\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2238\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2308\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 63%|██████▎   | 219/345 [11:37<06:29,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1698\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2035\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2746\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1654\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1[1,mpirank:1,algo-1]<stdout>: Pos device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 [1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0 [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 64%|██████▍   | 220/345 [11:40<06:23,  3.07s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1534\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1955\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1735\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2116\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: Pos device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 32]) [1,mpirank:0,algo-1]<stdout>: Logits device: [1,mpirank:2,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device:[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 64%|██████▍   | 221/345 [11:43<06:24,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2254\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1461\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1073\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2406\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device:[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:[1,mpirank:3,algo-1]<stdout>:DEBUG shapes:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:[1,mpirank:0,algo-1]<stdout>: cuda:0 Logits device: cuda:0 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: [1,mpirank:3,algo-1]<stdout>:cuda:3 [1,mpirank:3,algo-1]<stdout>:Logits_t device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 64%|██████▍   | 222/345 [11:47<06:19,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1513\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2286\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1119\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1483\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device:[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 65%|██████▍   | 223/345 [11:50<06:17,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2092\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1775\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2218\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1511\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 32]) [1,mpirank:1,algo-1]<stdout>: Logits device: [1,mpirank:2,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 65%|██████▍   | 224/345 [11:53<06:15,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1727\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2392\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1962\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1878\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:0,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: [1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 65%|██████▌   | 225/345 [11:56<06:11,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1737\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2356\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2187\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2144\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 [1,mpirank:2,algo-1]<stdout>:Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits_t device: [1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes:[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: [1,mpirank:1,algo-1]<stdout>:cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 66%|██████▌   | 226/345 [11:59<06:09,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1615\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1621\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2382\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1640\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device:[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 66%|██████▌   | 227/345 [12:02<06:06,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2194\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1993\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2255\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1890\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0[1,mpirank:0,algo-1]<stdout>: Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1[1,mpirank:1,algo-1]<stdout>: Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3[1,mpirank:3,algo-1]<stdout>: Logits_t device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 66%|██████▌   | 228/345 [12:05<06:02,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2822\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1904\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2348\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1764\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits device:[1,mpirank:2,algo-1]<stdout>: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:[1,mpirank:1,algo-1]<stdout>: cuda:1 [1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 66%|██████▋   | 229/345 [12:08<06:00,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2317\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1691\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1533\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2139\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits device: [1,mpirank:3,algo-1]<stdout>:Logits_t device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 67%|██████▋   | 230/345 [12:11<05:52,  3.07s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  0%|          | 0/15 [00:00<?, ?it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 13%|█▎        | 2/15 [00:00<00:01,  7.56it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 20%|██        | 3/15 [00:00<00:02,  5.76it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 27%|██▋       | 4/15 [00:00<00:02,  4.70it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 33%|███▎      | 5/15 [00:00<00:02,  4.88it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 40%|████      | 6/15 [00:01<00:01,  5.16it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 47%|████▋     | 7/15 [00:01<00:01,  5.35it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 60%|██████    | 9/15 [00:01<00:00,  7.66it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 80%|████████  | 12/15 [00:01<00:00,  9.43it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 87%|████████▋ | 13/15 [00:01<00:00,  8.12it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 93%|█████████▎| 14/15 [00:02<00:00,  7.43it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015                                                 #015\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:{'eval_runtime': 2.6243, 'eval_samples_per_second': 184.051, 'eval_steps_per_second': 6.097, 'epoch': 2.0}\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 67%|██████▋   | 230/345 [12:14<05:52,  3.07s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 15/15 [00:02<00:00,  7.43it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015                                               #033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>: stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>: stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>: stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>: stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2281\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1552\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1739\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2071\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Pos device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2[1,mpirank:2,algo-1]<stdout>: Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: [1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 67%|██████▋   | 231/345 [12:23<10:53,  5.73s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1360\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1621\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1894\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1739\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 32]) [1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 [1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:3,algo-1]<stdout>:Logits device: cuda:3 Logits_t device: [1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: [1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0 [1,mpirank:0,algo-1]<stdout>:Logits_t device:[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:[1,mpirank:1,algo-1]<stdout>: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 67%|██████▋   | 232/345 [12:26<09:19,  4.95s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1876\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1272\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1918\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1304\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: Logits_t device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 68%|██████▊   | 233/345 [12:29<08:14,  4.41s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2366\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2194\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1535\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1916\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits device: cuda:2[1,mpirank:2,algo-1]<stdout>: Logits_t device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 68%|██████▊   | 234/345 [12:33<07:27,  4.03s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1754\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2484\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1772\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1875\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3[1,mpirank:3,algo-1]<stdout>: Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device:[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device:[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 68%|██████▊   | 235/345 [12:36<06:55,  3.78s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1556\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1563\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1959\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1765\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device:[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:0,algo-1]<stdout>: cuda:0 [1,mpirank:3,algo-1]<stdout>:Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 [1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 68%|██████▊   | 236/345 [12:39<06:30,  3.58s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2220\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2113\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1730\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1836\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 69%|██████▊   | 237/345 [12:42<06:11,  3.44s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2090\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2374\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2148\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2085\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device:[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 [1,mpirank:2,algo-1]<stdout>: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0 Logits_t device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 69%|██████▉   | 238/345 [12:45<05:56,  3.33s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2161\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2233\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1879\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1735\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: [1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0[1,mpirank:2,algo-1]<stdout>:Logits device:[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 [1,mpirank:2,algo-1]<stdout>: cuda:2 Logits_t device:[1,mpirank:2,algo-1]<stdout>: cuda:2[1,mpirank:3,algo-1]<stdout>:Logits device: cuda:3[1,mpirank:3,algo-1]<stdout>: [1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 69%|██████▉   | 239/345 [12:48<05:46,  3.26s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1573\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1710\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2319\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2270\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3[1,mpirank:3,algo-1]<stdout>: Logits device: cuda:3[1,mpirank:3,algo-1]<stdout>: Logits_t device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 70%|██████▉   | 240/345 [12:51<05:35,  3.20s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2221\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1971\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1760\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1637\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 [1,mpirank:1,algo-1]<stdout>:Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 [1,mpirank:0,algo-1]<stdout>:Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 70%|██████▉   | 241/345 [12:54<05:27,  3.15s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1774\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1508\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1608\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2098\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 [1,mpirank:1,algo-1]<stdout>:Pos device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device:[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 32]) [1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:2,algo-1]<stdout>: cuda:2 Logits device:[1,mpirank:2,algo-1]<stdout>: [1,mpirank:0,algo-1]<stdout>: torch.Size([8, 32]) [1,mpirank:0,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 [1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0 Logits_t device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 70%|███████   | 242/345 [12:57<05:23,  3.14s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2522\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1849\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1451\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1546\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2 Logits_t device: cuda:2[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0[1,mpirank:0,algo-1]<stdout>: Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 70%|███████   | 243/345 [13:00<05:18,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1719\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1984\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1397\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2273\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device:[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>: [1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: [1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 71%|███████   | 244/345 [13:04<05:14,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2252\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1421\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2162\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1767\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device:[1,mpirank:1,algo-1]<stdout>:Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:cuda:3 [1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits device: cuda:3 [1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 71%|███████   | 245/345 [13:07<05:11,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1734\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1967\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2017\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2325\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device:[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: [1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2[1,mpirank:2,algo-1]<stdout>: Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 71%|███████▏  | 246/345 [13:10<05:07,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1834\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2393\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2067\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1927\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:Prefix device: [1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([32, 768]) [1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 [1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0[1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 72%|███████▏  | 247/345 [13:13<05:03,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2512\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2662\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2278\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1700\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2[1,mpirank:2,algo-1]<stdout>: Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 [1,mpirank:3,algo-1]<stdout>: Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes:[1,mpirank:0,algo-1]<stdout>:Logits_t device:[1,mpirank:1,algo-1]<stdout>: [1,mpirank:0,algo-1]<stdout>: cuda:0[1,mpirank:1,algo-1]<stdout>:torch.Size([32, 768]) [1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device:[1,mpirank:1,algo-1]<stdout>: cuda:1 Logits_t device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 72%|███████▏  | 248/345 [13:16<04:58,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1749\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1357\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2226\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1611\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:cuda:3[1,mpirank:1,algo-1]<stdout>:Logits device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: [1,mpirank:3,algo-1]<stdout>: [1,mpirank:1,algo-1]<stdout>:cuda:1[1,mpirank:2,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:[1,mpirank:3,algo-1]<stdout>:Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: [1,mpirank:2,algo-1]<stdout>:cuda:2[1,mpirank:2,algo-1]<stdout>: Logits device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 72%|███████▏  | 249/345 [13:19<04:54,  3.07s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1564\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2149\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1421\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1599\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device:[1,mpirank:1,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2[1,mpirank:2,algo-1]<stdout>: [1,mpirank:3,algo-1]<stdout>: torch.Size([8])[1,mpirank:2,algo-1]<stdout>:Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3[1,mpirank:3,algo-1]<stdout>: Logits_t device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 72%|███████▏  | 250/345 [13:22<04:52,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2438\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1912\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2066\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1975\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3 [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 73%|███████▎  | 251/345 [13:25<04:52,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2286\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1185\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2301\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1705\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 73%|███████▎  | 252/345 [13:28<04:47,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2135\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1741\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2296\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1950\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device:[1,mpirank:1,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2[1,mpirank:3,algo-1]<stdout>: cuda:3 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 73%|███████▎  | 253/345 [13:31<04:44,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1566\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2316\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2104\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1773\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2[1,mpirank:2,algo-1]<stdout>: Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device:[1,mpirank:1,algo-1]<stdout>: cuda:1 Logits_t device:[1,mpirank:1,algo-1]<stdout>: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 74%|███████▎  | 254/345 [13:34<04:40,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1706\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2264\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1853\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2901\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:[1,mpirank:2,algo-1]<stdout>: Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 74%|███████▍  | 255/345 [13:38<04:40,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1649\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2149\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1931\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1937\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([32, 768]) [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 32]) [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 [1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 [1,mpirank:2,algo-1]<stdout>:Logits_t device:[1,mpirank:1,algo-1]<stdout>:Logits_t device:[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 74%|███████▍  | 256/345 [13:41<04:37,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1799\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1400\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1506\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2122\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device:[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: [1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 32]) [1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 74%|███████▍  | 257/345 [13:44<04:35,  3.13s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2118\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1347\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1827\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2348\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([32, 768]) [1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:cuda:0[1,mpirank:1,algo-1]<stdout>:cuda:1[1,mpirank:1,algo-1]<stdout>: Logits device: [1,mpirank:0,algo-1]<stdout>: Logits_t device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 75%|███████▍  | 258/345 [13:47<04:32,  3.14s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1725\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1836\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1934\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1728\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 [1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3[1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:[1,mpirank:3,algo-1]<stdout>: Logits device: [1,mpirank:2,algo-1]<stdout>: cuda:2 Logits device: cuda:2 Logits_t device:[1,mpirank:0,algo-1]<stdout>: Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 75%|███████▌  | 259/345 [13:50<04:29,  3.13s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1924\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2292\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1641\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1771\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device:[1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768]) [1,mpirank:2,algo-1]<stdout>:cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 [1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 75%|███████▌  | 260/345 [13:53<04:26,  3.13s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2174\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1833\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2159\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1916\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: [1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0[1,mpirank:2,algo-1]<stdout>:Logits_t device:[1,mpirank:2,algo-1]<stdout>: [1,mpirank:0,algo-1]<stdout>: [1,mpirank:1,algo-1]<stdout>:torch.Size([32, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 [1,mpirank:0,algo-1]<stdout>: Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1 Logits_t device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 76%|███████▌  | 261/345 [13:56<04:20,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1517\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1758\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1500\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1831\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: [1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 76%|███████▌  | 262/345 [13:59<04:18,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2008\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2036\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1973\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1691\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: [1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device:[1,mpirank:3,algo-1]<stdout>: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 76%|███████▌  | 263/345 [14:03<04:15,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1867\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1648\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2203\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1802\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 77%|███████▋  | 264/345 [14:06<04:11,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2011\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1672\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1930\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2168\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device:[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 77%|███████▋  | 265/345 [14:09<04:08,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1849\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2302\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1650\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2119\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1[1,mpirank:2,algo-1]<stdout>: Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 [1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 77%|███████▋  | 266/345 [14:12<04:05,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2197\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1602\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1592\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2321\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device:[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 77%|███████▋  | 267/345 [14:15<04:01,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1915\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2228\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2517\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2673\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 78%|███████▊  | 268/345 [14:18<03:56,  3.07s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1959\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1991\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1984\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1822\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device:[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:2,algo-1]<stdout>: cuda:2 Logits_t device:[1,mpirank:1,algo-1]<stdout>:Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: [1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits_t device:[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 78%|███████▊  | 269/345 [14:21<03:54,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1857\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2144\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1526\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2274\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device:[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device:[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: [1,mpirank:3,algo-1]<stdout>: Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits device: [1,mpirank:2,algo-1]<stdout>:Logits device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device:[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device:[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 78%|███████▊  | 270/345 [14:24<03:52,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1959\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1664\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2052\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1421\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3[1,mpirank:3,algo-1]<stdout>: Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2[1,mpirank:0,algo-1]<stdout>: cuda:0 Logits device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits device: cuda:2 Logits_t device: cuda:2[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: [1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 79%|███████▊  | 271/345 [14:27<03:50,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1576\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2181\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1671\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1351\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: [1,mpirank:1,algo-1]<stdout>:Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 79%|███████▉  | 272/345 [14:31<03:48,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1545\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2158\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1535\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1529\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 79%|███████▉  | 273/345 [14:34<03:44,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1344\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1464\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2147\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1317\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: [1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device:[1,mpirank:2,algo-1]<stdout>: cuda:2 Logits_t device: [1,mpirank:2,algo-1]<stdout>:cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 79%|███████▉  | 274/345 [14:37<03:41,  3.13s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1974\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1677\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2456\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2330\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device:[1,mpirank:0,algo-1]<stdout>:Logits_t device:[1,mpirank:2,algo-1]<stdout>: Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: [1,mpirank:3,algo-1]<stdout>:cuda:3[1,mpirank:3,algo-1]<stdout>: Logits_t device: [1,mpirank:3,algo-1]<stdout>:cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 80%|███████▉  | 275/345 [14:40<03:40,  3.14s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2532\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2140\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2213\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2299\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: cuda:2 Logits device: cuda:2 Logits_t device:[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 80%|████████  | 276/345 [14:43<03:34,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1754\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1947\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1761\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1517\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: [1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 80%|████████  | 277/345 [14:46<03:30,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1649\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2179\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1491\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1749\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: [1,mpirank:0,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768]) [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: [1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 81%|████████  | 278/345 [14:49<03:27,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1768\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2399\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1910\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1856\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: Pos device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:2,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:[1,mpirank:3,algo-1]<stdout>: [1,mpirank:2,algo-1]<stdout>: cuda:2 Logits_t device: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits device:[1,mpirank:0,algo-1]<stdout>: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 81%|████████  | 279/345 [14:52<03:25,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2106\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2076\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2116\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1857\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: [1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 81%|████████  | 280/345 [14:55<03:20,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1881\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1386\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1593\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2611\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0[1,mpirank:0,algo-1]<stdout>: Pos device:[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:3,algo-1]<stdout>: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 81%|████████▏ | 281/345 [14:58<03:17,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2418\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1596\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2157\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1667\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device:[1,mpirank:2,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device:[1,mpirank:3,algo-1]<stdout>: [1,mpirank:0,algo-1]<stdout>: cuda:0[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 82%|████████▏ | 282/345 [15:02<03:18,  3.14s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2554\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2155\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1546\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1830\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 [1,mpirank:2,algo-1]<stdout>:Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 [1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 82%|████████▏ | 283/345 [15:05<03:13,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1396\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1428\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2202\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1957\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device:[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:[1,mpirank:2,algo-1]<stdout>:cuda:2 [1,mpirank:3,algo-1]<stdout>: cuda:3 Logits device: cuda:3[1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2 Logits_t device:[1,mpirank:3,algo-1]<stdout>: Logits_t device: [1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 82%|████████▏ | 284/345 [15:08<03:08,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1948\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 3080\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1380\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1872\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768]) [1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 [1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3[1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 83%|████████▎ | 285/345 [15:11<03:04,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2149\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1859\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2502\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1985\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device:[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device:[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 83%|████████▎ | 286/345 [15:14<03:01,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1698\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1668\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1705\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2153\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:1,algo-1]<stdout>: cuda:1 Logits device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 [1,mpirank:3,algo-1]<stdout>:Logits_t device: [1,mpirank:2,algo-1]<stdout>: cuda:2 [1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2 [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits_t device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 83%|████████▎ | 287/345 [15:17<02:58,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1984\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1493\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2081\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1561\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: Logits device: cuda:3 Logits_t device: [1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 83%|████████▎ | 288/345 [15:20<02:55,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1534\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2447\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2131\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1286\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 84%|████████▍ | 289/345 [15:23<02:52,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2095\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1730\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2112\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2098\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device:[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3[1,mpirank:2,algo-1]<stdout>: cuda:2 Logits_t device: [1,mpirank:3,algo-1]<stdout>: Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 84%|████████▍ | 290/345 [15:26<02:49,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2428\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2530\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2121\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2634\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device:[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0[1,mpirank:0,algo-1]<stdout>: Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: [1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1[1,mpirank:0,algo-1]<stdout>:Logits_t device: [1,mpirank:1,algo-1]<stdout>: Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 [1,mpirank:2,algo-1]<stdout>: Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 84%|████████▍ | 291/345 [15:29<02:47,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2185\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1463\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1594\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1941\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: [1,mpirank:0,algo-1]<stdout>:cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 [1,mpirank:1,algo-1]<stdout>:Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 85%|████████▍ | 292/345 [15:32<02:43,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1884\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1858\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2174\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2049\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device:[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: cuda:2 Logits device: cuda:2[1,mpirank:2,algo-1]<stdout>: Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 85%|████████▍ | 293/345 [15:36<02:40,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1778\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2043\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2193\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1880\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2[1,mpirank:2,algo-1]<stdout>: Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:0,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 [1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: [1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2 [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: [1,mpirank:2,algo-1]<stdout>:Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 85%|████████▌ | 294/345 [15:39<02:37,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1882\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1986\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1643\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1803\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device:[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3[1,mpirank:3,algo-1]<stdout>: Logits device:[1,mpirank:2,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: [1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 86%|████████▌ | 295/345 [15:42<02:34,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1861\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2173\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1856\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2213\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2[1,mpirank:2,algo-1]<stdout>: Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 86%|████████▌ | 296/345 [15:45<02:31,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1744\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2032\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2114\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2085\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device:[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: cuda:2 Logits_t device: cuda:2[1,mpirank:3,algo-1]<stdout>:cuda:3 [1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 86%|████████▌ | 297/345 [15:48<02:29,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1429\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1903\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2101\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1904\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: [1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device:[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 32]) [1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: [1,mpirank:3,algo-1]<stdout>:cuda:3 [1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 86%|████████▋ | 298/345 [15:51<02:26,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2600\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1618\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1876\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1930\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device:[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3 Logits_t device:[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 [1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1[1,mpirank:2,algo-1]<stdout>:cuda:2 [1,mpirank:1,algo-1]<stdout>: Logits_t device:[1,mpirank:2,algo-1]<stdout>:Logits device:[1,mpirank:1,algo-1]<stdout>: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: cuda:2 [1,mpirank:2,algo-1]<stdout>:Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 87%|████████▋ | 299/345 [15:54<02:22,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 3012\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1648\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1795\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2200\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device:[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2[1,mpirank:2,algo-1]<stdout>: Logits device: cuda:2 Logits_t device: [1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 87%|████████▋ | 300/345 [15:57<02:20,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:{'loss': 0.8366, 'grad_norm': 27.087366436745786, 'learning_rate': 4e-06, 'epoch': 2.61}\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 87%|████████▋ | 300/345 [15:57<02:20,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1530\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1667\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1497\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2514\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1[1,mpirank:1,algo-1]<stdout>: Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:[1,mpirank:3,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits device: cuda:2 Logits_t device:[1,mpirank:1,algo-1]<stdout>: cuda:1 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1[1,mpirank:2,algo-1]<stdout>: cuda:2[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>: Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 87%|████████▋ | 301/345 [16:00<02:17,  3.14s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1858\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1489\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1755\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1872\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device:[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 [1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device:[1,mpirank:0,algo-1]<stdout>:cuda:0 [1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits device: cuda:0 [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 88%|████████▊ | 302/345 [16:04<02:13,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2038\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2001\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1566\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2194\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape:[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 88%|████████▊ | 303/345 [16:07<02:11,  3.13s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1688\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2591\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1682\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2158\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: [1,mpirank:1,algo-1]<stdout>: Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 88%|████████▊ | 304/345 [16:10<02:08,  3.13s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1667\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2564\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1529\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1761\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device:[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device:[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: [1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device:[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits_t device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 88%|████████▊ | 305/345 [16:13<02:05,  3.13s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1531\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2237\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1545\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1658\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2 Logits_t device:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device:[1,mpirank:3,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 89%|████████▊ | 306/345 [16:16<02:01,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2035\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1521\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2226\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1787\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: [1,mpirank:3,algo-1]<stdout>:Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1[1,mpirank:1,algo-1]<stdout>: Logits device: cuda:1[1,mpirank:1,algo-1]<stdout>: Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 89%|████████▉ | 307/345 [16:19<01:58,  3.13s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2410\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1744\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1434\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2222\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: [1,mpirank:3,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 89%|████████▉ | 308/345 [16:22<01:55,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2013\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1826\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2124\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2069\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0[1,mpirank:0,algo-1]<stdout>: Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device:[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 90%|████████▉ | 309/345 [16:25<01:51,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1931\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1741\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2134\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2343\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 [1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:2,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 [1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 [1,mpirank:3,algo-1]<stdout>:Logits device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 90%|████████▉ | 310/345 [16:28<01:48,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1734\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1683\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1918\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1284\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 90%|█████████ | 311/345 [16:32<01:45,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2179\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2169\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1949\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2453\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device:[1,mpirank:0,algo-1]<stdout>: [1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])[1,mpirank:0,algo-1]<stdout>:cuda:0[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 90%|█████████ | 312/345 [16:35<01:42,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1541\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2204\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1524\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1469\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device:[1,mpirank:0,algo-1]<stdout>: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device:[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 91%|█████████ | 313/345 [16:38<01:39,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1903\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1749\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1590\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2657\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 [1,mpirank:1,algo-1]<stdout>:Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Pos device:[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device:[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:[1,mpirank:3,algo-1]<stdout>: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 91%|█████████ | 314/345 [16:41<01:36,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1154\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1553\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1936\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1372\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device:[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 [1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 [1,mpirank:0,algo-1]<stdout>:Logits device: [1,mpirank:3,algo-1]<stdout>:Logits device: cuda:3[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 91%|█████████▏| 315/345 [16:44<01:33,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2225\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1792\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1893\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2071\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3 Logits_t device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 92%|█████████▏| 316/345 [16:47<01:29,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2208\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2407\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2423\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2409\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 [1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device:[1,mpirank:3,algo-1]<stdout>: cuda:3 Logits_t device:[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 92%|█████████▏| 317/345 [16:50<01:26,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2168\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1239\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2488\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2123\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device:[1,mpirank:1,algo-1]<stdout>: Logits device: cuda:1 Logits_t device: [1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3 Logits device: cuda:3 [1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits_t device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 92%|█████████▏| 318/345 [16:53<01:23,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1528\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1769\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1485\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1661\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 [1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1[1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 92%|█████████▏| 319/345 [16:56<01:20,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1350\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1832\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2017\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1754\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: [1,mpirank:3,algo-1]<stdout>: Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:2,algo-1]<stdout>:Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: [1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1[1,mpirank:0,algo-1]<stdout>:cuda:0 [1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 93%|█████████▎| 320/345 [16:59<01:17,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2119\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2361\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1798\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1587\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device:[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:3,algo-1]<stdout>: Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: cuda:2 Logits_t device:[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 93%|█████████▎| 321/345 [17:03<01:14,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2134\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1798\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1850\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2165\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device:[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2[1,mpirank:2,algo-1]<stdout>: [1,mpirank:2,algo-1]<stdout>:Logits_t device:[1,mpirank:2,algo-1]<stdout>: cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 93%|█████████▎| 322/345 [17:06<01:11,  3.09s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1618\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2277\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1722\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1805\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3[1,mpirank:3,algo-1]<stdout>: Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 94%|█████████▎| 323/345 [17:09<01:08,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1990\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1996\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2324\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1827\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Pos device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device:[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:1,algo-1]<stdout>: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device:[1,mpirank:2,algo-1]<stdout>: Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device:[1,mpirank:0,algo-1]<stdout>: cuda:0[1,mpirank:3,algo-1]<stdout>: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 94%|█████████▍| 324/345 [17:12<01:05,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2317\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1640\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2134\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2479\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: [1,mpirank:3,algo-1]<stdout>:Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 94%|█████████▍| 325/345 [17:15<01:02,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2072\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2008\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1950\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2179\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device:[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1 Logits device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: Logits_t device: cuda:1[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device:[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:[1,mpirank:2,algo-1]<stdout>: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 94%|█████████▍| 326/345 [17:18<00:58,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1945\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1938\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1740\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2325\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits_t device:[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 95%|█████████▍| 327/345 [17:21<00:55,  3.10s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2925\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2322\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2288\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1472\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:1,algo-1]<stdout>:Gathered pos_all device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device:[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: Logits_t device: cuda:0[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 [1,mpirank:1,algo-1]<stdout>:Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:[1,mpirank:2,algo-1]<stdout>: [1,mpirank:2,algo-1]<stdout>:cuda:2[1,mpirank:2,algo-1]<stdout>: Logits device: cuda:2[1,mpirank:2,algo-1]<stdout>: Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 95%|█████████▌| 328/345 [17:24<00:53,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2124\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1754\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1831\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2403\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3[1,mpirank:3,algo-1]<stdout>: Logits device: cuda:3[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 [1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 95%|█████████▌| 329/345 [17:27<00:49,  3.12s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1828\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1657\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1476\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2030\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) [1,mpirank:3,algo-1]<stdout>: torch.Size([32, 768])[1,mpirank:0,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:[1,mpirank:0,algo-1]<stdout>: cuda:0 Logits device: [1,mpirank:3,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 96%|█████████▌| 330/345 [17:31<00:47,  3.15s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2039\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1500\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1875\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2108\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 96%|█████████▌| 331/345 [17:34<00:43,  3.14s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2528\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2329\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2399\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1546\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 [1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 96%|█████████▌| 332/345 [17:37<00:40,  3.13s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1971\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1944\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1825\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2354\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits device: [1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([32, 768]) torch.Size([8, 32])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:[1,mpirank:3,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: [1,mpirank:0,algo-1]<stdout>: cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 97%|█████████▋| 333/345 [17:40<00:37,  3.13s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2094\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2014\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1662\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2088\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 97%|█████████▋| 334/345 [17:43<00:35,  3.20s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1576\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2207\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1771\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1548\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape:[1,mpirank:1,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device:[1,mpirank:1,algo-1]<stdout>: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device:[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3[1,mpirank:2,algo-1]<stdout>: Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Logits device:[1,mpirank:3,algo-1]<stdout>: [1,mpirank:3,algo-1]<stdout>:cuda:3[1,mpirank:3,algo-1]<stdout>: Logits_t device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 97%|█████████▋| 335/345 [17:47<00:32,  3.23s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2399\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1467\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2228\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2458\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32])[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 97%|█████████▋| 336/345 [17:50<00:28,  3.18s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2142\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1781\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2222\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2204\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 98%|█████████▊| 337/345 [17:53<00:25,  3.16s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1663\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2197\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1520\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2424\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Logits_t device: [1,mpirank:2,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device:[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) [1,mpirank:3,algo-1]<stdout>:torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2 [1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2[1,mpirank:3,algo-1]<stdout>:cuda:3 [1,mpirank:2,algo-1]<stdout>: Logits_t device:[1,mpirank:3,algo-1]<stdout>:Logits device: cuda:3[1,mpirank:3,algo-1]<stdout>: Logits_t device: [1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 98%|█████████▊| 338/345 [17:56<00:21,  3.14s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 2282\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1420\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1904\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1313\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device:[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: [1,mpirank:1,algo-1]<stdout>:cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 98%|█████████▊| 339/345 [17:59<00:18,  3.13s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1920\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1958\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2528\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1787\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device:[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device:[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device:[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: [1,mpirank:1,algo-1]<stdout>: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: cuda:2 [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 99%|█████████▊| 340/345 [18:02<00:15,  3.14s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2301\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1625\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1906\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1399\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: [1,mpirank:3,algo-1]<stdout>:cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:[1,mpirank:0,algo-1]<stdout>: [1,mpirank:0,algo-1]<stdout>:cuda:0[1,mpirank:0,algo-1]<stdout>: Logits device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits_t device:[1,mpirank:0,algo-1]<stdout>: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 99%|█████████▉| 341/345 [18:05<00:12,  3.14s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1906\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1752\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1809\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2243\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:2,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: [1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3 Logits device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])[1,mpirank:1,algo-1]<stdout>:Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Logits_t device:[1,mpirank:2,algo-1]<stdout>: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: [1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 99%|█████████▉| 342/345 [18:08<00:09,  3.13s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1863\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 1787\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1624\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 2129\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:3,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: [1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device: cuda:0 Logits_t device: cuda:0[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 99%|█████████▉| 343/345 [18:12<00:06,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1773\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2693\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1603\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 1404\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:1,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 512, 768])[1,mpirank:2,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device: cuda:0 Logits device:[1,mpirank:0,algo-1]<stdout>: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: cuda:3[1,mpirank:3,algo-1]<stdout>: Logits device: [1,mpirank:3,algo-1]<stdout>:cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015100%|█████████▉| 344/345 [18:15<00:03,  3.11s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Sum attention masks: 1498\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Sum attention masks: 1582\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Sum attention masks: 2229\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([8, 512]), torch.Size([8, 512])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Sum attention masks: 2210\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Prefix device: cuda:2 Pos device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:1,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Prefix device: cuda:1 Pos device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])[1,mpirank:3,algo-1]<stdout>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Suffix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Prefix device: cuda:3 Pos device:[1,mpirank:3,algo-1]<stdout>: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_p.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG out_s.hidden_states shape: 23\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix hidden_states[-1].shape: torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Suffix hidden_states[-1].shape: [1,mpirank:0,algo-1]<stdout>:torch.Size([8, 512, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DBG emb_p/emb_s shapes: torch.Size([8, 768]), torch.Size([8, 768])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Prefix device: cuda:0 Pos device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Gathered pos_all device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Gathered pos_all device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Gathered pos_all device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Gathered pos_all device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:Labels device: cuda:1 Logits device: [1,mpirank:3,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:Labels device: [1,mpirank:2,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768]) torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>:Labels device: cuda:2 [1,mpirank:2,algo-1]<stdout>:Logits device: cuda:2 Logits_t device: cuda:2\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>:cuda:1 Logits_t device: cuda:1\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>:cuda:3 Logits device: cuda:3 Logits_t device: cuda:3\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:DEBUG shapes: torch.Size([32, 768])[1,mpirank:0,algo-1]<stdout>: torch.Size([8, 32]) torch.Size([8])\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:Labels device:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:cuda:0 Logits device: cuda:0 Logits_t device: cuda:0\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 345/345 [18:18<00:00,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015  0%|          | 0/15 [00:00<?, ?it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 13%|█▎        | 2/15 [00:00<00:01,  7.57it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 20%|██        | 3/15 [00:00<00:02,  5.50it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 27%|██▋       | 4/15 [00:00<00:02,  4.50it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 33%|███▎      | 5/15 [00:00<00:02,  4.81it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 40%|████      | 6/15 [00:01<00:01,  5.06it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 47%|████▋     | 7/15 [00:01<00:01,  5.26it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 60%|██████    | 9/15 [00:01<00:00,  7.54it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 80%|████████  | 12/15 [00:01<00:00,  9.14it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 87%|████████▋ | 13/15 [00:01<00:00,  7.94it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015 93%|█████████▎| 14/15 [00:02<00:00,  7.29it/s]#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015                                                 #015\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:{'eval_runtime': 2.6644, 'eval_samples_per_second': 181.281, 'eval_steps_per_second': 6.005, 'epoch': 3.0}\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 345/345 [18:20<00:00,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 15/15 [00:02<00:00,  7.29it/s]#033[A[1,mpirank:0,algo-1]<stderr>:\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015                                               #033[A\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>: stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stdout>: stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stdout>: stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stdout>: stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights\u001B[0m\n",
      "\u001B[34m[1,mpirank:1,algo-1]<stderr>: stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>: stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights\u001B[0m\n",
      "\u001B[34m[1,mpirank:3,algo-1]<stderr>: stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights\u001B[0m\n",
      "\u001B[34m[1,mpirank:2,algo-1]<stderr>: stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stdout>:{'train_runtime': 1107.0992, 'train_samples_per_second': 9.996, 'train_steps_per_second': 0.312, 'train_loss': 1.5488153872282608, 'epoch': 3.0}\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015                                                 #015[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 345/345 [18:27<00:00,  3.08s/it]\u001B[0m\n",
      "\u001B[34m[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 345/345 [18:27<00:00,  3.21s/it]\u001B[0m\n",
      "\u001B[34m2025-07-28 22:55:53,182 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001B[0m\n",
      "\u001B[34m2025-07-28 22:55:53,182 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001B[0m\n",
      "\u001B[34m2025-07-28 22:55:53,182 sagemaker-training-toolkit INFO     Begin writing status file from leader node to worker nodes (if any)\u001B[0m\n",
      "\n",
      "2025-07-28 22:56:30 Uploading - Uploading generated training model\u001B[34m2025-07-28 22:56:23,182 sagemaker-training-toolkit INFO     Finished writing status file from leader node to worker nodes (if any)\u001B[0m\n",
      "\u001B[34m2025-07-28 22:56:23,182 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001B[0m\n",
      "\n",
      "2025-07-28 22:57:13 Completed - Training job completed\n",
      "Training seconds: 1521\n",
      "Billable seconds: 1521\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "model = HuggingFaceModel(model_data=est.model_data, role=role,\n",
    "                         transformers_version=\"4.42\", pytorch_version=\"2.2\", py_version=\"py39\")\n",
    "predictor = model.deploy(1, \"ml.m5.xlarge\")"
   ],
   "id": "1b65b20af226c80b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predictor.predict({\"inputs\":\"Example prefix …\"})\n",
    "predictor.delete_endpoint()    # stop billing"
   ],
   "id": "ed2726b955e0932"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T00:19:05.249024Z",
     "start_time": "2025-07-25T00:19:05.244078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, torch\n",
    "alloc_conf = os.getenv(\"PYTORCH_CUDA_ALLOC_CONF\")\n",
    "print(\"Allocator setting:\", alloc_conf)"
   ],
   "id": "22aa3f1dfe580a17",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocator setting: None\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8d55b008d723c371"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legalpacaenv",
   "language": "python",
   "name": "lagalpacaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
